experiment: "experiment_distributions"

seed: null
start_state: (6, 1)
terminal_states:
  "(6, 7)": 1.0
rows: 10 
cols: 11
# walls: ['(4, 4)','(7, 4)','(2, 4)','(0, 4)','(3, 4)','(8, 4)','(5, 4)','(6, 4)','(9, 4)']
episode_length_limit: 2000
p_success: 1
num_steps: 40_000
train_max_iterations: 60
neural_fit_mode: "max"
algorithm: "default"
randomize_starting_position: True

agent_params:
  agent: AgentDQN
  args_:
    gamma: 0.9
    train_step_cnt: 4_000
    validation_enabled: False
    validation_step_cnt: 500
    validation_epsilon: 0.001
    
    replay_start_size: 1_000
    
    batch_size: 32
    training_freq: 4
    target_model_update_freq: 50
    loss_fcn: mse_loss

    epsilon:
      start: 1.0
      end: 0.01
      decay: 80_000 # train_max_iterations * train_step_cnt * 0.33
 
optim:
  name: Adam
  args_:
    lr: 0.001
    eps: 0.0003125

replay_buffer:
  type: "ReplayBuffer"
  max_size: 10_000
  n_step: 0

experiment: "experiment_distributions"

seed: null
start_state: (6, 1)
terminal_states:
  "(8, 18)": 1.0
rows: 10 
cols: 21
walls: ['(0, 15)', '(2, 15)', '(3, 15)', '(4, 15)', '(5, 15)', '(6, 15)', '(7, 15)', '(8, 15)', '(9, 15)']
episode_length_limit: 4000
p_success: 1
num_steps: 40_000
train_max_iterations: 60
neural_fit_mode: "max"
algorithm: "default"
randomize_starting_position: True

agent_params:
  agent: AgentDQN
  args_:
    gamma: 0.9
    train_step_cnt: 8_000
    validation_enabled: False
    validation_step_cnt: 4_000
    validation_epsilon: 0.001
    
    replay_start_size: 1_000
    
    hidden_size: 128
    batch_size: 32
    training_freq: 4
    target_model_update_freq: 50
    loss_fcn: mse_loss

    epsilon:
      start: 1.0
      end: 0.01
      decay: 240_000 # train_max_iterations * train_step_cnt * 0.5
 
optim:
  name: Adam
  args_:
    lr: 0.001
    eps: 0.0003125

replay_buffer:
  type: "ReplayBuffer"
  max_size: 10_000
  n_step: 0

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import random\n",
    "import pandas as pd\n",
    "import yaml\n",
    "\n",
    "from argparse import Namespace\n",
    "\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\", {'axes.grid' : False})\n",
    "\n",
    "root_dir = os.path.dirname(\n",
    "        os.path.dirname(os.path.realpath(\".\")))\n",
    "\n",
    "sys.path.append(root_dir)\n",
    "\n",
    "\n",
    "import logging\n",
    "\n",
    "from rl_envs_forge.envs.grid_world.grid_world import GridWorld\n",
    "from common.src.distribution_src import ( \n",
    "                                         make_env, \n",
    "                                        randomize_walls_positions, \n",
    "                                        generate_train_test_split_with_valid_path,\n",
    "                                        run_distribution_correction_experiment,\n",
    "                                        compute_validation_bellmans_error,\n",
    "                                        setup_dqn_agent\n",
    "                                        )\n",
    "from common.src.simple_dqn_agent import AgentDQN\n",
    "from scipy.stats import entropy\n",
    "\n",
    "\n",
    "from common.src.experiment_utils import (\n",
    "    setup_logger,\n",
    "    namespace_to_dict,\n",
    ")\n",
    "\n",
    "from common.src.distribution_src import run_dqn_distribution_correction_experiment\n",
    "\n",
    "\n",
    "from argparse import Namespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(2, 0), (1, 2)]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "terminal_states = {(2, 2): 1}\n",
    "start_state = (2, 1)\n",
    "rows = 5\n",
    "cols = 5\n",
    "seed = 2\n",
    "\n",
    "# random_walls = randomize_walls_positions(rows, cols, start_state, terminal_states, 0.2, seed=seed)\n",
    "random_walls = [(2, 0), (1, 2)]\n",
    "print(random_walls)\n",
    "env = make_env(\n",
    "    rows,\n",
    "    cols,\n",
    "    start_state=start_state,\n",
    "    p_success=1,\n",
    "    terminal_states=terminal_states,\n",
    "    seed=seed,\n",
    "    walls=random_walls,\n",
    ")\n",
    "env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_observation_space_shape(observation_space):\n",
    "    \"\"\"Extract a shape-like tuple from a tuple of discrete spaces.\"\"\"\n",
    "    return tuple(space.n for space in observation_space.spaces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tuple(Discrete(5), Discrete(5))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 0],\n",
       "       [1, 3, 2, 0, 0],\n",
       "       [0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def state_to_matrix(state, env):\n",
    "    import numpy as np\n",
    "\n",
    "    # Extract the environment size from walls and terminal states\n",
    "    max_rows = env.rows\n",
    "    max_cols = env.cols\n",
    "\n",
    "    # Create the matrix\n",
    "    matrix = np.zeros((max_rows, max_cols), dtype=int)\n",
    "\n",
    "    # Mark walls in the matrix\n",
    "    for wall in env.walls:\n",
    "        matrix[wall[0], wall[1]] = 1  # Use 1 to indicate walls\n",
    "\n",
    "    # Mark terminal states in the matrix\n",
    "    for terminal, value in env.terminal_states.items():\n",
    "        matrix[terminal[0], terminal[1]] = 2\n",
    "\n",
    "    pos = state\n",
    "    matrix[pos[0], pos[1]] = 3  # Use 3 to indicate the agent's position\n",
    "\n",
    "    return matrix\n",
    "\n",
    "\n",
    "state_to_matrix(env.state, env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 5)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_shape = get_observation_space_shape(env.observation_space)\n",
    "state_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# env.mdp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ts = next(iter(terminal_states))\n",
    "\n",
    "# for trial in range(100000):\n",
    "#     random_walls = randomize_walls_positions(rows, cols, start_state, terminal_states, 0.2, seed=trial)\n",
    "\n",
    "#     if (start_state in random_walls) or (ts in random_walls):\n",
    "#         raise ValueError(\"start state or terminal state in walls\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "transitions_list = [(key[0], key[1], *value[0]) for key, value in env.mdp.items()]\n",
    "\n",
    "transitions_train, transitions_val = generate_train_test_split_with_valid_path(\n",
    "    transitions_list=transitions_list,\n",
    "    start_state=start_state,\n",
    "    terminal_states=terminal_states,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'agent_params': {'agent': 'AgentDQN',\n",
       "  'args_': {'batch_size': 32,\n",
       "   'epsilon': {'decay': 5000, 'end': 0.01, 'start': 1.0},\n",
       "   'gamma': 0.9,\n",
       "   'loss_fcn': 'mse_loss',\n",
       "   'replay_start_size': 50,\n",
       "   'target_model_update_freq': 40,\n",
       "   'train_step_cnt': 500,\n",
       "   'training_freq': 4,\n",
       "   'validation_enabled': False,\n",
       "   'validation_epsilon': 0.001,\n",
       "   'validation_step_cnt': 250}},\n",
       " 'algorithm': 'default',\n",
       " 'cfg_id': 0,\n",
       " 'cols': 10,\n",
       " 'experiment': 'experiment_distributions',\n",
       " 'experiment_arguments': {'algorithm': 'default'},\n",
       " 'full_title': '2024Jun05-180814_configs_algorithm=default',\n",
       " 'neural_fit_mode': 'max',\n",
       " 'num_steps': 40000,\n",
       " 'optim': {'args_': {'eps': 0.0003125, 'lr': 0.1}, 'name': 'Adam'},\n",
       " 'out_dir': '.\\\\results\\\\2024Jun05-180814_configs\\\\0000_algorithm_default\\\\0',\n",
       " 'p_success': 1,\n",
       " 'replay_buffer': {'action_dim': 1, 'max_size': 1000, 'n_step': 0},\n",
       " 'rows': 10,\n",
       " 'run_id': 0,\n",
       " 'seed': 3363169239,\n",
       " 'start_state': (1, 1),\n",
       " 'terminal_states': {(8, 8): 1.0},\n",
       " 'title': 'algorithm=default',\n",
       " 'train_max_iterations': 30}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Load up a config\n",
    "\n",
    "file_path = r\"D:\\Work\\repos\\phd-research\\experiments\\dqn\\results\\2024Jun05-180814_configs\\0000_algorithm_default\\0\\cfg.yaml\"\n",
    "\n",
    "# Open the YAML file and load its content into a dictionary\n",
    "with open(file_path, \"r\") as file:\n",
    "    data = yaml.safe_load(file)\n",
    "\n",
    "opts = Namespace(**data)\n",
    "\n",
    "logger = setup_logger(opts.full_title)\n",
    "\n",
    "opts.seed = random.randint(0, 2**32 - 1) if opts.seed is None else opts.seed\n",
    "opts_dict = namespace_to_dict(opts)\n",
    "# opts_dict = vars(opts)\n",
    "\n",
    "opts_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Namespace(agent_params={'agent': 'AgentDQN', 'args_': {'batch_size': 32, 'epsilon': {'decay': 5000, 'end': 0.01, 'start': 1.0}, 'gamma': 0.9, 'loss_fcn': 'mse_loss', 'replay_start_size': 50, 'target_model_update_freq': 40, 'train_step_cnt': 500, 'training_freq': 4, 'validation_enabled': False, 'validation_epsilon': 0.001, 'validation_step_cnt': 250}}, algorithm='default', cfg_id=0, cols=10, experiment='experiment_distributions', experiment_arguments={'algorithm': 'default'}, full_title='2024Jun05-180814_configs_algorithm=default', neural_fit_mode='max', num_steps=40000, optim={'args_': {'eps': 0.0003125, 'lr': 0.1}, 'name': 'Adam'}, out_dir='.\\\\results\\\\2024Jun05-180814_configs\\\\0000_algorithm_default\\\\0', p_success=1, replay_buffer={'action_dim': 1, 'max_size': 1000, 'n_step': 0}, rows=10, run_id=0, seed=3363169239, start_state='(1, 1)', terminal_states={'(8, 8)': 1.0}, title='algorithm=default', train_max_iterations=30)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opts_dict[\"start_state\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(8, 8): 1.0}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opts_dict[\"terminal_states\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-06-05 18:31:19,723 - 2024Jun05-180814_configs_algorithm=default - INFO - Starting experiment: 2024Jun05-180814_configs_algorithm=default\n",
      "2024-06-05 18:31:19,724 - 2024Jun05-180814_configs_algorithm=default - INFO - Starting experiment: 2024Jun05-180814_configs_algorithm=default\n",
      "2024-06-05 18:31:19,730 - 2024Jun05-180814_configs_algorithm=default - INFO - Loaded configuration settings.\n",
      "2024-06-05 18:31:20,331 - 2024Jun05-180814_configs_algorithm=default - INFO - Initialized newtworks and optimizer.\n",
      "2024-06-05 18:31:20,332 - 2024Jun05-180814_configs_algorithm=default - INFO - Starting training session at: 0\n",
      "2024-06-05 18:31:20,333 - 2024Jun05-180814_configs_algorithm=default - INFO - Starting training epoch at t = 0\n",
      "2024-06-05 18:31:20,488 - 2024Jun05-180814_configs_algorithm=default - INFO - TRAINING STATS | Frames seen: 500 | Episode: 1 | Max reward: 1.0 | Avg reward: 1.0 | Avg frames (episode): 363.0 | Avg max Q: 0.3261683077684471 | Epsilon: 0.9109 | Train epoch time: 0:00:00.155807\n",
      "2024-06-05 18:31:20,489 - 2024Jun05-180814_configs_algorithm=default - INFO - Saving checkpoint at t = 500 ...\n",
      "2024-06-05 18:31:20,490 - 2024Jun05-180814_configs_algorithm=default - INFO - Checkpoint saved at t = 500\n",
      "2024-06-05 18:31:20,491 - 2024Jun05-180814_configs_algorithm=default - INFO - Epoch 0 completed in 0:00:00.158808\n",
      "2024-06-05 18:31:20,491 - 2024Jun05-180814_configs_algorithm=default - INFO - \n",
      "\n",
      "2024-06-05 18:31:20,491 - 2024Jun05-180814_configs_algorithm=default - INFO - Ended training session after 1 epochs at t = 500\n",
      "2024-06-05 18:31:20,577 - 2024Jun05-180814_configs_algorithm=default - INFO - Resuming training session at: 500 (1 epochs left)\n",
      "2024-06-05 18:31:20,577 - 2024Jun05-180814_configs_algorithm=default - INFO - Starting training epoch at t = 500\n",
      "2024-06-05 18:31:20,744 - 2024Jun05-180814_configs_algorithm=default - INFO - TRAINING STATS | Frames seen: 1000 | Episode: 2 | Max reward: 1.0 | Avg reward: 1.0 | Avg frames (episode): 276.0 | Avg max Q: 0.09397119050845504 | Epsilon: 0.8119000000000001 | Train epoch time: 0:00:00.164846\n",
      "2024-06-05 18:31:20,744 - 2024Jun05-180814_configs_algorithm=default - INFO - Saving checkpoint at t = 1000 ...\n",
      "2024-06-05 18:31:20,745 - 2024Jun05-180814_configs_algorithm=default - INFO - Checkpoint saved at t = 1000\n",
      "2024-06-05 18:31:20,745 - 2024Jun05-180814_configs_algorithm=default - INFO - Epoch 0 completed in 0:00:00.168152\n",
      "2024-06-05 18:31:20,746 - 2024Jun05-180814_configs_algorithm=default - INFO - \n",
      "\n",
      "2024-06-05 18:31:20,746 - 2024Jun05-180814_configs_algorithm=default - INFO - Ended training session after 1 epochs at t = 1000\n",
      "2024-06-05 18:31:20,899 - 2024Jun05-180814_configs_algorithm=default - INFO - Resuming training session at: 1000 (1 epochs left)\n",
      "2024-06-05 18:31:20,900 - 2024Jun05-180814_configs_algorithm=default - INFO - Starting training epoch at t = 1000\n",
      "2024-06-05 18:31:21,070 - 2024Jun05-180814_configs_algorithm=default - INFO - TRAINING STATS | Frames seen: 1500 | Episode: 3 | Max reward: 1.0 | Avg reward: 1.0 | Avg frames (episode): 387.0 | Avg max Q: 0.11769101487578086 | Epsilon: 0.7129000000000001 | Train epoch time: 0:00:00.169220\n",
      "2024-06-05 18:31:21,070 - 2024Jun05-180814_configs_algorithm=default - INFO - Saving checkpoint at t = 1500 ...\n",
      "2024-06-05 18:31:21,071 - 2024Jun05-180814_configs_algorithm=default - INFO - Checkpoint saved at t = 1500\n",
      "2024-06-05 18:31:21,072 - 2024Jun05-180814_configs_algorithm=default - INFO - Epoch 0 completed in 0:00:00.172220\n",
      "2024-06-05 18:31:21,072 - 2024Jun05-180814_configs_algorithm=default - INFO - \n",
      "\n",
      "2024-06-05 18:31:21,072 - 2024Jun05-180814_configs_algorithm=default - INFO - Ended training session after 1 epochs at t = 1500\n",
      "2024-06-05 18:31:21,224 - 2024Jun05-180814_configs_algorithm=default - INFO - Resuming training session at: 1500 (1 epochs left)\n",
      "2024-06-05 18:31:21,224 - 2024Jun05-180814_configs_algorithm=default - INFO - Starting training epoch at t = 1500\n",
      "2024-06-05 18:31:21,404 - 2024Jun05-180814_configs_algorithm=default - INFO - TRAINING STATS | Frames seen: 2000 | Episode: 3 | Max reward: None | Avg reward: None | Avg frames (episode): None | Avg max Q: None | Epsilon: 0.6139 | Train epoch time: 0:00:00.178872\n",
      "2024-06-05 18:31:21,405 - 2024Jun05-180814_configs_algorithm=default - INFO - Saving checkpoint at t = 2000 ...\n",
      "2024-06-05 18:31:21,405 - 2024Jun05-180814_configs_algorithm=default - INFO - Checkpoint saved at t = 2000\n",
      "2024-06-05 18:31:21,406 - 2024Jun05-180814_configs_algorithm=default - INFO - Epoch 0 completed in 0:00:00.181873\n",
      "2024-06-05 18:31:21,406 - 2024Jun05-180814_configs_algorithm=default - INFO - \n",
      "\n",
      "2024-06-05 18:31:21,407 - 2024Jun05-180814_configs_algorithm=default - INFO - Ended training session after 1 epochs at t = 2000\n",
      "2024-06-05 18:31:21,561 - 2024Jun05-180814_configs_algorithm=default - INFO - Resuming training session at: 2000 (1 epochs left)\n",
      "2024-06-05 18:31:21,561 - 2024Jun05-180814_configs_algorithm=default - INFO - Starting training epoch at t = 2000\n",
      "2024-06-05 18:31:21,735 - 2024Jun05-180814_configs_algorithm=default - INFO - TRAINING STATS | Frames seen: 2500 | Episode: 3 | Max reward: None | Avg reward: None | Avg frames (episode): None | Avg max Q: None | Epsilon: 0.5149 | Train epoch time: 0:00:00.174558\n",
      "2024-06-05 18:31:21,736 - 2024Jun05-180814_configs_algorithm=default - INFO - Saving checkpoint at t = 2500 ...\n",
      "2024-06-05 18:31:21,737 - 2024Jun05-180814_configs_algorithm=default - INFO - Checkpoint saved at t = 2500\n",
      "2024-06-05 18:31:21,737 - 2024Jun05-180814_configs_algorithm=default - INFO - Epoch 0 completed in 0:00:00.176558\n",
      "2024-06-05 18:31:21,737 - 2024Jun05-180814_configs_algorithm=default - INFO - \n",
      "\n",
      "2024-06-05 18:31:21,738 - 2024Jun05-180814_configs_algorithm=default - INFO - Ended training session after 1 epochs at t = 2500\n",
      "2024-06-05 18:31:21,884 - 2024Jun05-180814_configs_algorithm=default - INFO - Resuming training session at: 2500 (1 epochs left)\n",
      "2024-06-05 18:31:21,884 - 2024Jun05-180814_configs_algorithm=default - INFO - Starting training epoch at t = 2500\n",
      "2024-06-05 18:31:22,065 - 2024Jun05-180814_configs_algorithm=default - INFO - TRAINING STATS | Frames seen: 3000 | Episode: 3 | Max reward: None | Avg reward: None | Avg frames (episode): None | Avg max Q: None | Epsilon: 0.41590000000000005 | Train epoch time: 0:00:00.180930\n",
      "2024-06-05 18:31:22,066 - 2024Jun05-180814_configs_algorithm=default - INFO - Saving checkpoint at t = 3000 ...\n",
      "2024-06-05 18:31:22,067 - 2024Jun05-180814_configs_algorithm=default - INFO - Checkpoint saved at t = 3000\n",
      "2024-06-05 18:31:22,067 - 2024Jun05-180814_configs_algorithm=default - INFO - Epoch 0 completed in 0:00:00.182931\n",
      "2024-06-05 18:31:22,068 - 2024Jun05-180814_configs_algorithm=default - INFO - \n",
      "\n",
      "2024-06-05 18:31:22,068 - 2024Jun05-180814_configs_algorithm=default - INFO - Ended training session after 1 epochs at t = 3000\n",
      "2024-06-05 18:31:22,218 - 2024Jun05-180814_configs_algorithm=default - INFO - Resuming training session at: 3000 (1 epochs left)\n",
      "2024-06-05 18:31:22,219 - 2024Jun05-180814_configs_algorithm=default - INFO - Starting training epoch at t = 3000\n",
      "2024-06-05 18:31:22,430 - 2024Jun05-180814_configs_algorithm=default - INFO - TRAINING STATS | Frames seen: 3500 | Episode: 4 | Max reward: 1.0 | Avg reward: 1.0 | Avg frames (episode): 2027.0 | Avg max Q: 0.21496366393127972 | Epsilon: 0.31690000000000007 | Train epoch time: 0:00:00.209553\n",
      "2024-06-05 18:31:22,430 - 2024Jun05-180814_configs_algorithm=default - INFO - Saving checkpoint at t = 3500 ...\n",
      "2024-06-05 18:31:22,431 - 2024Jun05-180814_configs_algorithm=default - INFO - Checkpoint saved at t = 3500\n",
      "2024-06-05 18:31:22,431 - 2024Jun05-180814_configs_algorithm=default - INFO - Epoch 0 completed in 0:00:00.212205\n",
      "2024-06-05 18:31:22,432 - 2024Jun05-180814_configs_algorithm=default - INFO - \n",
      "\n",
      "2024-06-05 18:31:22,432 - 2024Jun05-180814_configs_algorithm=default - INFO - Ended training session after 1 epochs at t = 3500\n",
      "2024-06-05 18:31:22,583 - 2024Jun05-180814_configs_algorithm=default - INFO - Resuming training session at: 3500 (1 epochs left)\n",
      "2024-06-05 18:31:22,583 - 2024Jun05-180814_configs_algorithm=default - INFO - Starting training epoch at t = 3500\n",
      "2024-06-05 18:31:22,794 - 2024Jun05-180814_configs_algorithm=default - INFO - TRAINING STATS | Frames seen: 4000 | Episode: 4 | Max reward: None | Avg reward: None | Avg frames (episode): None | Avg max Q: None | Epsilon: 0.21789999999999998 | Train epoch time: 0:00:00.211250\n",
      "2024-06-05 18:31:22,794 - 2024Jun05-180814_configs_algorithm=default - INFO - Saving checkpoint at t = 4000 ...\n",
      "2024-06-05 18:31:22,795 - 2024Jun05-180814_configs_algorithm=default - INFO - Checkpoint saved at t = 4000\n",
      "2024-06-05 18:31:22,796 - 2024Jun05-180814_configs_algorithm=default - INFO - Epoch 0 completed in 0:00:00.213250\n",
      "2024-06-05 18:31:22,796 - 2024Jun05-180814_configs_algorithm=default - INFO - \n",
      "\n",
      "2024-06-05 18:31:22,797 - 2024Jun05-180814_configs_algorithm=default - INFO - Ended training session after 1 epochs at t = 4000\n",
      "2024-06-05 18:31:22,939 - 2024Jun05-180814_configs_algorithm=default - INFO - Resuming training session at: 4000 (1 epochs left)\n",
      "2024-06-05 18:31:22,940 - 2024Jun05-180814_configs_algorithm=default - INFO - Starting training epoch at t = 4000\n",
      "2024-06-05 18:31:23,167 - 2024Jun05-180814_configs_algorithm=default - INFO - TRAINING STATS | Frames seen: 4500 | Episode: 4 | Max reward: None | Avg reward: None | Avg frames (episode): None | Avg max Q: None | Epsilon: 0.1189 | Train epoch time: 0:00:00.226802\n",
      "2024-06-05 18:31:23,167 - 2024Jun05-180814_configs_algorithm=default - INFO - Saving checkpoint at t = 4500 ...\n",
      "2024-06-05 18:31:23,168 - 2024Jun05-180814_configs_algorithm=default - INFO - Checkpoint saved at t = 4500\n",
      "2024-06-05 18:31:23,169 - 2024Jun05-180814_configs_algorithm=default - INFO - Epoch 0 completed in 0:00:00.228802\n",
      "2024-06-05 18:31:23,169 - 2024Jun05-180814_configs_algorithm=default - INFO - \n",
      "\n",
      "2024-06-05 18:31:23,169 - 2024Jun05-180814_configs_algorithm=default - INFO - Ended training session after 1 epochs at t = 4500\n",
      "2024-06-05 18:31:23,315 - 2024Jun05-180814_configs_algorithm=default - INFO - Resuming training session at: 4500 (1 epochs left)\n",
      "2024-06-05 18:31:23,316 - 2024Jun05-180814_configs_algorithm=default - INFO - Starting training epoch at t = 4500\n",
      "2024-06-05 18:31:23,549 - 2024Jun05-180814_configs_algorithm=default - INFO - TRAINING STATS | Frames seen: 5000 | Episode: 8 | Max reward: 1.0 | Avg reward: 1.0 | Avg frames (episode): 464.0 | Avg max Q: 0.14121567817092026 | Epsilon: 0.01990000000000003 | Train epoch time: 0:00:00.232046\n",
      "2024-06-05 18:31:23,550 - 2024Jun05-180814_configs_algorithm=default - INFO - Saving checkpoint at t = 5000 ...\n",
      "2024-06-05 18:31:23,551 - 2024Jun05-180814_configs_algorithm=default - INFO - Checkpoint saved at t = 5000\n",
      "2024-06-05 18:31:23,551 - 2024Jun05-180814_configs_algorithm=default - INFO - Epoch 0 completed in 0:00:00.235046\n",
      "2024-06-05 18:31:23,551 - 2024Jun05-180814_configs_algorithm=default - INFO - \n",
      "\n",
      "2024-06-05 18:31:23,551 - 2024Jun05-180814_configs_algorithm=default - INFO - Ended training session after 1 epochs at t = 5000\n",
      "2024-06-05 18:31:23,689 - 2024Jun05-180814_configs_algorithm=default - INFO - Resuming training session at: 5000 (1 epochs left)\n",
      "2024-06-05 18:31:23,689 - 2024Jun05-180814_configs_algorithm=default - INFO - Starting training epoch at t = 5000\n",
      "2024-06-05 18:31:23,929 - 2024Jun05-180814_configs_algorithm=default - INFO - TRAINING STATS | Frames seen: 5500 | Episode: 9 | Max reward: 1.0 | Avg reward: 1.0 | Avg frames (episode): 145.0 | Avg max Q: 0.16231007999056704 | Epsilon: 0.01 | Train epoch time: 0:00:00.240404\n",
      "2024-06-05 18:31:23,930 - 2024Jun05-180814_configs_algorithm=default - INFO - Saving checkpoint at t = 5500 ...\n",
      "2024-06-05 18:31:23,931 - 2024Jun05-180814_configs_algorithm=default - INFO - Checkpoint saved at t = 5500\n",
      "2024-06-05 18:31:23,931 - 2024Jun05-180814_configs_algorithm=default - INFO - Epoch 0 completed in 0:00:00.242409\n",
      "2024-06-05 18:31:23,931 - 2024Jun05-180814_configs_algorithm=default - INFO - \n",
      "\n",
      "2024-06-05 18:31:23,931 - 2024Jun05-180814_configs_algorithm=default - INFO - Ended training session after 1 epochs at t = 5500\n",
      "2024-06-05 18:31:24,079 - 2024Jun05-180814_configs_algorithm=default - INFO - Resuming training session at: 5500 (1 epochs left)\n",
      "2024-06-05 18:31:24,080 - 2024Jun05-180814_configs_algorithm=default - INFO - Starting training epoch at t = 5500\n",
      "2024-06-05 18:31:24,312 - 2024Jun05-180814_configs_algorithm=default - INFO - TRAINING STATS | Frames seen: 6000 | Episode: 10 | Max reward: 1.0 | Avg reward: 1.0 | Avg frames (episode): 464.0 | Avg max Q: 0.2191536739436251 | Epsilon: 0.01 | Train epoch time: 0:00:00.231073\n",
      "2024-06-05 18:31:24,312 - 2024Jun05-180814_configs_algorithm=default - INFO - Saving checkpoint at t = 6000 ...\n",
      "2024-06-05 18:31:24,313 - 2024Jun05-180814_configs_algorithm=default - INFO - Checkpoint saved at t = 6000\n",
      "2024-06-05 18:31:24,313 - 2024Jun05-180814_configs_algorithm=default - INFO - Epoch 0 completed in 0:00:00.233071\n",
      "2024-06-05 18:31:24,314 - 2024Jun05-180814_configs_algorithm=default - INFO - \n",
      "\n",
      "2024-06-05 18:31:24,314 - 2024Jun05-180814_configs_algorithm=default - INFO - Ended training session after 1 epochs at t = 6000\n",
      "2024-06-05 18:31:24,465 - 2024Jun05-180814_configs_algorithm=default - INFO - Resuming training session at: 6000 (1 epochs left)\n",
      "2024-06-05 18:31:24,466 - 2024Jun05-180814_configs_algorithm=default - INFO - Starting training epoch at t = 6000\n",
      "2024-06-05 18:31:24,682 - 2024Jun05-180814_configs_algorithm=default - INFO - TRAINING STATS | Frames seen: 6500 | Episode: 10 | Max reward: None | Avg reward: None | Avg frames (episode): None | Avg max Q: None | Epsilon: 0.01 | Train epoch time: 0:00:00.216498\n",
      "2024-06-05 18:31:24,683 - 2024Jun05-180814_configs_algorithm=default - INFO - Saving checkpoint at t = 6500 ...\n",
      "2024-06-05 18:31:24,684 - 2024Jun05-180814_configs_algorithm=default - INFO - Checkpoint saved at t = 6500\n",
      "2024-06-05 18:31:24,684 - 2024Jun05-180814_configs_algorithm=default - INFO - Epoch 0 completed in 0:00:00.218644\n",
      "2024-06-05 18:31:24,684 - 2024Jun05-180814_configs_algorithm=default - INFO - \n",
      "\n",
      "2024-06-05 18:31:24,685 - 2024Jun05-180814_configs_algorithm=default - INFO - Ended training session after 1 epochs at t = 6500\n",
      "2024-06-05 18:31:24,831 - 2024Jun05-180814_configs_algorithm=default - INFO - Resuming training session at: 6500 (1 epochs left)\n",
      "2024-06-05 18:31:24,831 - 2024Jun05-180814_configs_algorithm=default - INFO - Starting training epoch at t = 6500\n",
      "2024-06-05 18:31:25,052 - 2024Jun05-180814_configs_algorithm=default - INFO - TRAINING STATS | Frames seen: 7000 | Episode: 10 | Max reward: None | Avg reward: None | Avg frames (episode): None | Avg max Q: None | Epsilon: 0.01 | Train epoch time: 0:00:00.220568\n",
      "2024-06-05 18:31:25,052 - 2024Jun05-180814_configs_algorithm=default - INFO - Saving checkpoint at t = 7000 ...\n",
      "2024-06-05 18:31:25,053 - 2024Jun05-180814_configs_algorithm=default - INFO - Checkpoint saved at t = 7000\n",
      "2024-06-05 18:31:25,053 - 2024Jun05-180814_configs_algorithm=default - INFO - Epoch 0 completed in 0:00:00.222074\n",
      "2024-06-05 18:31:25,054 - 2024Jun05-180814_configs_algorithm=default - INFO - \n",
      "\n",
      "2024-06-05 18:31:25,054 - 2024Jun05-180814_configs_algorithm=default - INFO - Ended training session after 1 epochs at t = 7000\n",
      "2024-06-05 18:31:25,199 - 2024Jun05-180814_configs_algorithm=default - INFO - Resuming training session at: 7000 (1 epochs left)\n",
      "2024-06-05 18:31:25,199 - 2024Jun05-180814_configs_algorithm=default - INFO - Starting training epoch at t = 7000\n",
      "2024-06-05 18:31:25,420 - 2024Jun05-180814_configs_algorithm=default - INFO - TRAINING STATS | Frames seen: 7500 | Episode: 11 | Max reward: 1.0 | Avg reward: 1.0 | Avg frames (episode): 1948.0 | Avg max Q: 0.12881956303246545 | Epsilon: 0.01 | Train epoch time: 0:00:00.218613\n",
      "2024-06-05 18:31:25,420 - 2024Jun05-180814_configs_algorithm=default - INFO - Saving checkpoint at t = 7500 ...\n",
      "2024-06-05 18:31:25,422 - 2024Jun05-180814_configs_algorithm=default - INFO - Checkpoint saved at t = 7500\n",
      "2024-06-05 18:31:25,422 - 2024Jun05-180814_configs_algorithm=default - INFO - Epoch 0 completed in 0:00:00.222615\n",
      "2024-06-05 18:31:25,423 - 2024Jun05-180814_configs_algorithm=default - INFO - \n",
      "\n",
      "2024-06-05 18:31:25,423 - 2024Jun05-180814_configs_algorithm=default - INFO - Ended training session after 1 epochs at t = 7500\n",
      "2024-06-05 18:31:25,567 - 2024Jun05-180814_configs_algorithm=default - INFO - Resuming training session at: 7500 (1 epochs left)\n",
      "2024-06-05 18:31:25,567 - 2024Jun05-180814_configs_algorithm=default - INFO - Starting training epoch at t = 7500\n",
      "2024-06-05 18:31:25,777 - 2024Jun05-180814_configs_algorithm=default - INFO - TRAINING STATS | Frames seen: 8000 | Episode: 11 | Max reward: None | Avg reward: None | Avg frames (episode): None | Avg max Q: None | Epsilon: 0.01 | Train epoch time: 0:00:00.210310\n",
      "2024-06-05 18:31:25,777 - 2024Jun05-180814_configs_algorithm=default - INFO - Saving checkpoint at t = 8000 ...\n",
      "2024-06-05 18:31:25,778 - 2024Jun05-180814_configs_algorithm=default - INFO - Checkpoint saved at t = 8000\n",
      "2024-06-05 18:31:25,779 - 2024Jun05-180814_configs_algorithm=default - INFO - Epoch 0 completed in 0:00:00.212342\n",
      "2024-06-05 18:31:25,779 - 2024Jun05-180814_configs_algorithm=default - INFO - \n",
      "\n",
      "2024-06-05 18:31:25,780 - 2024Jun05-180814_configs_algorithm=default - INFO - Ended training session after 1 epochs at t = 8000\n",
      "2024-06-05 18:31:25,924 - 2024Jun05-180814_configs_algorithm=default - INFO - Resuming training session at: 8000 (1 epochs left)\n",
      "2024-06-05 18:31:25,924 - 2024Jun05-180814_configs_algorithm=default - INFO - Starting training epoch at t = 8000\n",
      "2024-06-05 18:31:26,147 - 2024Jun05-180814_configs_algorithm=default - INFO - TRAINING STATS | Frames seen: 8500 | Episode: 12 | Max reward: 1.0 | Avg reward: 1.0 | Avg frames (episode): 595.0 | Avg max Q: 0.08060818718325707 | Epsilon: 0.01 | Train epoch time: 0:00:00.221542\n",
      "2024-06-05 18:31:26,147 - 2024Jun05-180814_configs_algorithm=default - INFO - Saving checkpoint at t = 8500 ...\n",
      "2024-06-05 18:31:26,149 - 2024Jun05-180814_configs_algorithm=default - INFO - Checkpoint saved at t = 8500\n",
      "2024-06-05 18:31:26,149 - 2024Jun05-180814_configs_algorithm=default - INFO - Epoch 0 completed in 0:00:00.224541\n",
      "2024-06-05 18:31:26,149 - 2024Jun05-180814_configs_algorithm=default - INFO - \n",
      "\n",
      "2024-06-05 18:31:26,149 - 2024Jun05-180814_configs_algorithm=default - INFO - Ended training session after 1 epochs at t = 8500\n",
      "2024-06-05 18:31:26,291 - 2024Jun05-180814_configs_algorithm=default - INFO - Resuming training session at: 8500 (1 epochs left)\n",
      "2024-06-05 18:31:26,291 - 2024Jun05-180814_configs_algorithm=default - INFO - Starting training epoch at t = 8500\n",
      "2024-06-05 18:31:26,523 - 2024Jun05-180814_configs_algorithm=default - INFO - TRAINING STATS | Frames seen: 9000 | Episode: 13 | Max reward: 1.0 | Avg reward: 1.0 | Avg frames (episode): 480.0 | Avg max Q: 0.07827025069560431 | Epsilon: 0.01 | Train epoch time: 0:00:00.230795\n",
      "2024-06-05 18:31:26,523 - 2024Jun05-180814_configs_algorithm=default - INFO - Saving checkpoint at t = 9000 ...\n",
      "2024-06-05 18:31:26,524 - 2024Jun05-180814_configs_algorithm=default - INFO - Checkpoint saved at t = 9000\n",
      "2024-06-05 18:31:26,525 - 2024Jun05-180814_configs_algorithm=default - INFO - Epoch 0 completed in 0:00:00.234300\n",
      "2024-06-05 18:31:26,525 - 2024Jun05-180814_configs_algorithm=default - INFO - \n",
      "\n",
      "2024-06-05 18:31:26,525 - 2024Jun05-180814_configs_algorithm=default - INFO - Ended training session after 1 epochs at t = 9000\n",
      "2024-06-05 18:31:26,667 - 2024Jun05-180814_configs_algorithm=default - INFO - Resuming training session at: 9000 (1 epochs left)\n",
      "2024-06-05 18:31:26,667 - 2024Jun05-180814_configs_algorithm=default - INFO - Starting training epoch at t = 9000\n",
      "2024-06-05 18:31:26,902 - 2024Jun05-180814_configs_algorithm=default - INFO - TRAINING STATS | Frames seen: 9500 | Episode: 13 | Max reward: None | Avg reward: None | Avg frames (episode): None | Avg max Q: None | Epsilon: 0.01 | Train epoch time: 0:00:00.235034\n",
      "2024-06-05 18:31:26,902 - 2024Jun05-180814_configs_algorithm=default - INFO - Saving checkpoint at t = 9500 ...\n",
      "2024-06-05 18:31:26,904 - 2024Jun05-180814_configs_algorithm=default - INFO - Checkpoint saved at t = 9500\n",
      "2024-06-05 18:31:26,904 - 2024Jun05-180814_configs_algorithm=default - INFO - Epoch 0 completed in 0:00:00.237038\n",
      "2024-06-05 18:31:26,904 - 2024Jun05-180814_configs_algorithm=default - INFO - \n",
      "\n",
      "2024-06-05 18:31:26,904 - 2024Jun05-180814_configs_algorithm=default - INFO - Ended training session after 1 epochs at t = 9500\n",
      "2024-06-05 18:31:27,046 - 2024Jun05-180814_configs_algorithm=default - INFO - Resuming training session at: 9500 (1 epochs left)\n",
      "2024-06-05 18:31:27,047 - 2024Jun05-180814_configs_algorithm=default - INFO - Starting training epoch at t = 9500\n",
      "2024-06-05 18:31:27,263 - 2024Jun05-180814_configs_algorithm=default - INFO - TRAINING STATS | Frames seen: 10000 | Episode: 14 | Max reward: 1.0 | Avg reward: 1.0 | Avg frames (episode): 1201.0 | Avg max Q: 0.08400229925460219 | Epsilon: 0.01 | Train epoch time: 0:00:00.214438\n",
      "2024-06-05 18:31:27,263 - 2024Jun05-180814_configs_algorithm=default - INFO - Saving checkpoint at t = 10000 ...\n",
      "2024-06-05 18:31:27,264 - 2024Jun05-180814_configs_algorithm=default - INFO - Checkpoint saved at t = 10000\n",
      "2024-06-05 18:31:27,265 - 2024Jun05-180814_configs_algorithm=default - INFO - Epoch 0 completed in 0:00:00.217944\n",
      "2024-06-05 18:31:27,265 - 2024Jun05-180814_configs_algorithm=default - INFO - \n",
      "\n",
      "2024-06-05 18:31:27,265 - 2024Jun05-180814_configs_algorithm=default - INFO - Ended training session after 1 epochs at t = 10000\n",
      "2024-06-05 18:31:27,412 - 2024Jun05-180814_configs_algorithm=default - INFO - Resuming training session at: 10000 (1 epochs left)\n",
      "2024-06-05 18:31:27,412 - 2024Jun05-180814_configs_algorithm=default - INFO - Starting training epoch at t = 10000\n",
      "2024-06-05 18:31:27,633 - 2024Jun05-180814_configs_algorithm=default - INFO - TRAINING STATS | Frames seen: 10500 | Episode: 14 | Max reward: None | Avg reward: None | Avg frames (episode): None | Avg max Q: None | Epsilon: 0.01 | Train epoch time: 0:00:00.220864\n",
      "2024-06-05 18:31:27,634 - 2024Jun05-180814_configs_algorithm=default - INFO - Saving checkpoint at t = 10500 ...\n",
      "2024-06-05 18:31:27,635 - 2024Jun05-180814_configs_algorithm=default - INFO - Checkpoint saved at t = 10500\n",
      "2024-06-05 18:31:27,636 - 2024Jun05-180814_configs_algorithm=default - INFO - Epoch 0 completed in 0:00:00.223864\n",
      "2024-06-05 18:31:27,636 - 2024Jun05-180814_configs_algorithm=default - INFO - \n",
      "\n",
      "2024-06-05 18:31:27,637 - 2024Jun05-180814_configs_algorithm=default - INFO - Ended training session after 1 epochs at t = 10500\n",
      "2024-06-05 18:31:27,777 - 2024Jun05-180814_configs_algorithm=default - INFO - Resuming training session at: 10500 (1 epochs left)\n",
      "2024-06-05 18:31:27,777 - 2024Jun05-180814_configs_algorithm=default - INFO - Starting training epoch at t = 10500\n",
      "2024-06-05 18:31:27,995 - 2024Jun05-180814_configs_algorithm=default - INFO - TRAINING STATS | Frames seen: 11000 | Episode: 15 | Max reward: 1.0 | Avg reward: 1.0 | Avg frames (episode): 878.0 | Avg max Q: 0.06768038437373376 | Epsilon: 0.01 | Train epoch time: 0:00:00.217571\n",
      "2024-06-05 18:31:27,995 - 2024Jun05-180814_configs_algorithm=default - INFO - Saving checkpoint at t = 11000 ...\n",
      "2024-06-05 18:31:27,996 - 2024Jun05-180814_configs_algorithm=default - INFO - Checkpoint saved at t = 11000\n",
      "2024-06-05 18:31:27,997 - 2024Jun05-180814_configs_algorithm=default - INFO - Epoch 0 completed in 0:00:00.220570\n",
      "2024-06-05 18:31:27,997 - 2024Jun05-180814_configs_algorithm=default - INFO - \n",
      "\n",
      "2024-06-05 18:31:27,998 - 2024Jun05-180814_configs_algorithm=default - INFO - Ended training session after 1 epochs at t = 11000\n",
      "2024-06-05 18:31:28,131 - 2024Jun05-180814_configs_algorithm=default - INFO - Resuming training session at: 11000 (1 epochs left)\n",
      "2024-06-05 18:31:28,131 - 2024Jun05-180814_configs_algorithm=default - INFO - Starting training epoch at t = 11000\n",
      "2024-06-05 18:31:28,362 - 2024Jun05-180814_configs_algorithm=default - INFO - TRAINING STATS | Frames seen: 11500 | Episode: 16 | Max reward: 1.0 | Avg reward: 1.0 | Avg frames (episode): 749.0 | Avg max Q: 0.0823881972586162 | Epsilon: 0.01 | Train epoch time: 0:00:00.229343\n",
      "2024-06-05 18:31:28,362 - 2024Jun05-180814_configs_algorithm=default - INFO - Saving checkpoint at t = 11500 ...\n",
      "2024-06-05 18:31:28,364 - 2024Jun05-180814_configs_algorithm=default - INFO - Checkpoint saved at t = 11500\n",
      "2024-06-05 18:31:28,364 - 2024Jun05-180814_configs_algorithm=default - INFO - Epoch 0 completed in 0:00:00.232851\n",
      "2024-06-05 18:31:28,365 - 2024Jun05-180814_configs_algorithm=default - INFO - \n",
      "\n",
      "2024-06-05 18:31:28,365 - 2024Jun05-180814_configs_algorithm=default - INFO - Ended training session after 1 epochs at t = 11500\n",
      "2024-06-05 18:31:28,508 - 2024Jun05-180814_configs_algorithm=default - INFO - Resuming training session at: 11500 (1 epochs left)\n",
      "2024-06-05 18:31:28,509 - 2024Jun05-180814_configs_algorithm=default - INFO - Starting training epoch at t = 11500\n",
      "2024-06-05 18:31:28,724 - 2024Jun05-180814_configs_algorithm=default - INFO - TRAINING STATS | Frames seen: 12000 | Episode: 17 | Max reward: 1.0 | Avg reward: 1.0 | Avg frames (episode): 345.0 | Avg max Q: 0.08093979702009792 | Epsilon: 0.01 | Train epoch time: 0:00:00.214517\n",
      "2024-06-05 18:31:28,724 - 2024Jun05-180814_configs_algorithm=default - INFO - Saving checkpoint at t = 12000 ...\n",
      "2024-06-05 18:31:28,727 - 2024Jun05-180814_configs_algorithm=default - INFO - Checkpoint saved at t = 12000\n",
      "2024-06-05 18:31:28,728 - 2024Jun05-180814_configs_algorithm=default - INFO - Epoch 0 completed in 0:00:00.218024\n",
      "2024-06-05 18:31:28,728 - 2024Jun05-180814_configs_algorithm=default - INFO - \n",
      "\n",
      "2024-06-05 18:31:28,728 - 2024Jun05-180814_configs_algorithm=default - INFO - Ended training session after 1 epochs at t = 12000\n",
      "2024-06-05 18:31:28,872 - 2024Jun05-180814_configs_algorithm=default - INFO - Resuming training session at: 12000 (1 epochs left)\n",
      "2024-06-05 18:31:28,872 - 2024Jun05-180814_configs_algorithm=default - INFO - Starting training epoch at t = 12000\n",
      "2024-06-05 18:31:29,081 - 2024Jun05-180814_configs_algorithm=default - INFO - TRAINING STATS | Frames seen: 12500 | Episode: 17 | Max reward: None | Avg reward: None | Avg frames (episode): None | Avg max Q: None | Epsilon: 0.01 | Train epoch time: 0:00:00.208617\n",
      "2024-06-05 18:31:29,081 - 2024Jun05-180814_configs_algorithm=default - INFO - Saving checkpoint at t = 12500 ...\n",
      "2024-06-05 18:31:29,083 - 2024Jun05-180814_configs_algorithm=default - INFO - Checkpoint saved at t = 12500\n",
      "2024-06-05 18:31:29,084 - 2024Jun05-180814_configs_algorithm=default - INFO - Epoch 0 completed in 0:00:00.212385\n",
      "2024-06-05 18:31:29,084 - 2024Jun05-180814_configs_algorithm=default - INFO - \n",
      "\n",
      "2024-06-05 18:31:29,084 - 2024Jun05-180814_configs_algorithm=default - INFO - Ended training session after 1 epochs at t = 12500\n",
      "2024-06-05 18:31:29,231 - 2024Jun05-180814_configs_algorithm=default - INFO - Resuming training session at: 12500 (1 epochs left)\n",
      "2024-06-05 18:31:29,231 - 2024Jun05-180814_configs_algorithm=default - INFO - Starting training epoch at t = 12500\n",
      "2024-06-05 18:31:29,441 - 2024Jun05-180814_configs_algorithm=default - INFO - TRAINING STATS | Frames seen: 13000 | Episode: 18 | Max reward: 1.0 | Avg reward: 1.0 | Avg frames (episode): 911.0 | Avg max Q: 0.07871982715119326 | Epsilon: 0.01 | Train epoch time: 0:00:00.210552\n",
      "2024-06-05 18:31:29,441 - 2024Jun05-180814_configs_algorithm=default - INFO - Saving checkpoint at t = 13000 ...\n",
      "2024-06-05 18:31:29,444 - 2024Jun05-180814_configs_algorithm=default - INFO - Checkpoint saved at t = 13000\n",
      "2024-06-05 18:31:29,445 - 2024Jun05-180814_configs_algorithm=default - INFO - Epoch 0 completed in 0:00:00.213060\n",
      "2024-06-05 18:31:29,445 - 2024Jun05-180814_configs_algorithm=default - INFO - \n",
      "\n",
      "2024-06-05 18:31:29,445 - 2024Jun05-180814_configs_algorithm=default - INFO - Ended training session after 1 epochs at t = 13000\n",
      "2024-06-05 18:31:29,607 - 2024Jun05-180814_configs_algorithm=default - INFO - Resuming training session at: 13000 (1 epochs left)\n",
      "2024-06-05 18:31:29,608 - 2024Jun05-180814_configs_algorithm=default - INFO - Starting training epoch at t = 13000\n",
      "2024-06-05 18:31:29,825 - 2024Jun05-180814_configs_algorithm=default - INFO - TRAINING STATS | Frames seen: 13500 | Episode: 21 | Max reward: 1.0 | Avg reward: 1.0 | Avg frames (episode): 265.6666666666667 | Avg max Q: 0.11984623364191882 | Epsilon: 0.01 | Train epoch time: 0:00:00.217594\n",
      "2024-06-05 18:31:29,827 - 2024Jun05-180814_configs_algorithm=default - INFO - Saving checkpoint at t = 13500 ...\n",
      "2024-06-05 18:31:29,828 - 2024Jun05-180814_configs_algorithm=default - INFO - Checkpoint saved at t = 13500\n",
      "2024-06-05 18:31:29,829 - 2024Jun05-180814_configs_algorithm=default - INFO - Epoch 0 completed in 0:00:00.221101\n",
      "2024-06-05 18:31:29,829 - 2024Jun05-180814_configs_algorithm=default - INFO - \n",
      "\n",
      "2024-06-05 18:31:29,829 - 2024Jun05-180814_configs_algorithm=default - INFO - Ended training session after 1 epochs at t = 13500\n",
      "2024-06-05 18:31:29,975 - 2024Jun05-180814_configs_algorithm=default - INFO - Resuming training session at: 13500 (1 epochs left)\n",
      "2024-06-05 18:31:29,976 - 2024Jun05-180814_configs_algorithm=default - INFO - Starting training epoch at t = 13500\n",
      "2024-06-05 18:31:30,195 - 2024Jun05-180814_configs_algorithm=default - INFO - TRAINING STATS | Frames seen: 14000 | Episode: 22 | Max reward: 1.0 | Avg reward: 1.0 | Avg frames (episode): 240.0 | Avg max Q: 0.15455485470279925 | Epsilon: 0.01 | Train epoch time: 0:00:00.219453\n",
      "2024-06-05 18:31:30,195 - 2024Jun05-180814_configs_algorithm=default - INFO - Saving checkpoint at t = 14000 ...\n",
      "2024-06-05 18:31:30,197 - 2024Jun05-180814_configs_algorithm=default - INFO - Checkpoint saved at t = 14000\n",
      "2024-06-05 18:31:30,198 - 2024Jun05-180814_configs_algorithm=default - INFO - Epoch 0 completed in 0:00:00.222454\n",
      "2024-06-05 18:31:30,198 - 2024Jun05-180814_configs_algorithm=default - INFO - \n",
      "\n",
      "2024-06-05 18:31:30,199 - 2024Jun05-180814_configs_algorithm=default - INFO - Ended training session after 1 epochs at t = 14000\n",
      "2024-06-05 18:31:30,351 - 2024Jun05-180814_configs_algorithm=default - INFO - Resuming training session at: 14000 (1 epochs left)\n",
      "2024-06-05 18:31:30,351 - 2024Jun05-180814_configs_algorithm=default - INFO - Starting training epoch at t = 14000\n",
      "2024-06-05 18:31:30,566 - 2024Jun05-180814_configs_algorithm=default - INFO - TRAINING STATS | Frames seen: 14500 | Episode: 22 | Max reward: None | Avg reward: None | Avg frames (episode): None | Avg max Q: None | Epsilon: 0.01 | Train epoch time: 0:00:00.213724\n",
      "2024-06-05 18:31:30,566 - 2024Jun05-180814_configs_algorithm=default - INFO - Saving checkpoint at t = 14500 ...\n",
      "2024-06-05 18:31:30,568 - 2024Jun05-180814_configs_algorithm=default - INFO - Checkpoint saved at t = 14500\n",
      "2024-06-05 18:31:30,569 - 2024Jun05-180814_configs_algorithm=default - INFO - Epoch 0 completed in 0:00:00.218231\n",
      "2024-06-05 18:31:30,569 - 2024Jun05-180814_configs_algorithm=default - INFO - \n",
      "\n",
      "2024-06-05 18:31:30,569 - 2024Jun05-180814_configs_algorithm=default - INFO - Ended training session after 1 epochs at t = 14500\n",
      "2024-06-05 18:31:30,690 - 2024Jun05-180814_configs_algorithm=default - INFO - Resuming training session at: 14500 (1 epochs left)\n",
      "2024-06-05 18:31:30,690 - 2024Jun05-180814_configs_algorithm=default - INFO - Starting training epoch at t = 14500\n",
      "2024-06-05 18:31:30,919 - 2024Jun05-180814_configs_algorithm=default - INFO - TRAINING STATS | Frames seen: 15000 | Episode: 22 | Max reward: None | Avg reward: None | Avg frames (episode): None | Avg max Q: None | Epsilon: 0.01 | Train epoch time: 0:00:00.227579\n",
      "2024-06-05 18:31:30,920 - 2024Jun05-180814_configs_algorithm=default - INFO - Saving checkpoint at t = 15000 ...\n",
      "2024-06-05 18:31:30,921 - 2024Jun05-180814_configs_algorithm=default - INFO - Checkpoint saved at t = 15000\n",
      "2024-06-05 18:31:30,923 - 2024Jun05-180814_configs_algorithm=default - INFO - Epoch 0 completed in 0:00:00.232639\n",
      "2024-06-05 18:31:30,923 - 2024Jun05-180814_configs_algorithm=default - INFO - \n",
      "\n",
      "2024-06-05 18:31:30,923 - 2024Jun05-180814_configs_algorithm=default - INFO - Ended training session after 1 epochs at t = 15000\n"
     ]
    }
   ],
   "source": [
    "logger.info(f\"Starting experiment: {opts_dict['full_title']}\")\n",
    "\n",
    "agent = setup_dqn_agent(\n",
    "    config=opts_dict,\n",
    "    logger=logger,\n",
    ")\n",
    "\n",
    "transitions_list = [\n",
    "    (key[0], key[1], *value[0]) for key, value in agent.train_env.mdp.items()\n",
    "]\n",
    "\n",
    "experiment_data = []\n",
    "for i in range(1, 3):\n",
    "    agent.train(i)\n",
    "\n",
    "    bm_error_validation = compute_validation_bellmans_error(\n",
    "        agent.target_model,\n",
    "        validation_transitions=transitions_list,\n",
    "        error_mode=opts_dict[\"neural_fit_mode\"],\n",
    "        gamma=agent.gamma,\n",
    "        logger=logger,\n",
    "    )\n",
    "\n",
    "    rb_entropy = agent.replay_buffer.calculate_buffer_entropy()\n",
    "\n",
    "    normalized_rb = agent.replay_buffer.normalize_replay_buffer()\n",
    "    normalized_rb_entropy = normalized_rb.calculate_buffer_entropy()\n",
    "\n",
    "# experiment_agent.train(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "rb_buffer = agent.replay_buffer\n",
    "buffer = rb_buffer.buffer\n",
    "\n",
    "examples = [(transition[0], transition[1]) for transition in buffer]\n",
    "example_strings = [f\"{state}_{action}\" for state, action in examples]\n",
    "unique_examples, counts = np.unique(example_strings, return_counts=True)\n",
    "example_entropy = entropy(counts, base=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "123"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unique_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([111,   6,   8,  80,   7,   5,   5,   5,   3,   5,   3,   5,   3,\n",
       "         5,   3,   5,   3,   5,   3,   4,   3,  15,  31,   3,   2,   8,\n",
       "         1,   9,   1,   1,   1,   1,   1,   1,   4,   9,   9,   1,   2,\n",
       "         4,   9,   9,   5,   1,   2,   4,   9,   1,   8,  72,   1,   2,\n",
       "         1,   2,   1,   2,   1,   1,   2,   1,   2,   1,   2,   2,   1,\n",
       "         2,   3,   1,   7,   1,   8,   1,   1,   1,   1,   1,   1,   1,\n",
       "         1,   1,   2,  11,   5,   8,   8,   1,   3,   5,   8,   8,   1,\n",
       "         3,   5,   8,   8,   1,   3,   5,   8,   3,  81, 101,   3,   3,\n",
       "         3,   3,   3,   3,   1,   1,   3,   1,   2,   1,   2,   1,   2,\n",
       "         1,   2,   3,  77,  43,   2], dtype=int64)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.302732267659845"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "normalized_rb = rb_buffer.normalize_replay_buffer()\n",
    "normalized_rb_entropy = normalized_rb.calculate_buffer_entropy()\n",
    "buffer_normed = normalized_rb.buffer\n",
    "\n",
    "\n",
    "examples_normalized = [(transition[0], transition[1]) for transition in buffer_normed]\n",
    "example_strings_normalized = [f\"{state}_{action}\" for state, action in examples_normalized]\n",
    "len(example_strings_normalized)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "123"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_examples, counts = np.unique(example_strings_normalized, return_counts=True)\n",
    "len(unique_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([111,   6,   8,  80,   7,   5,   5,   5,   3,   5,   3,   5,   3,\n",
       "         5,   3,   5,   3,   5,   3,   4,   3,  15,  31,   3,   2,   8,\n",
       "         1,   9,   1,   1,   1,   1,   1,   1,   4,   9,   9,   1,   2,\n",
       "         4,   9,   9,   5,   1,   2,   4,   9,   1,   8,  72,   1,   2,\n",
       "         1,   2,   1,   2,   1,   1,   2,   1,   2,   1,   2,   2,   1,\n",
       "         2,   3,   1,   7,   1,   8,   1,   1,   1,   1,   1,   1,   1,\n",
       "         1,   1,   2,  11,   5,   8,   8,   1,   3,   5,   8,   8,   1,\n",
       "         3,   5,   8,   8,   1,   3,   5,   8,   3,  81, 101,   3,   3,\n",
       "         3,   3,   3,   3,   1,   1,   3,   1,   2,   1,   2,   1,   2,\n",
       "         1,   2,   3,  77,  43,   2], dtype=int64)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_entropy_normed = entropy(counts, base=2)\n",
    "example_entropy_normed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_rb_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New State: (1, 2), Action: 1, Reward: 0, Terminated: False, Truncated: False, Info: {}\n",
      "New State: (0, 2), Action: 0, Reward: 0, Terminated: False, Truncated: False, Info: {}\n",
      "New State: (0, 1), Action: 3, Reward: 0, Terminated: False, Truncated: False, Info: {}\n",
      "New State: (1, 1), Action: 2, Reward: 0, Terminated: False, Truncated: False, Info: {}\n",
      "New State: (0, 3), Action: 1, Reward: 0, Terminated: False, Truncated: False, Info: {}\n",
      "New State: (2, 2), Action: 2, Reward: 0, Terminated: False, Truncated: False, Info: {}\n",
      "New State: (3, 2), Action: 2, Reward: 0, Terminated: False, Truncated: False, Info: {}\n",
      "New State: (3, 3), Action: 1, Reward: 0, Terminated: False, Truncated: False, Info: {}\n",
      "New State: (2, 3), Action: 0, Reward: 0, Terminated: False, Truncated: False, Info: {}\n",
      "New State: (1, 3), Action: 0, Reward: 0, Terminated: False, Truncated: False, Info: {}\n",
      "New State: (1, 4), Action: 1, Reward: 0, Terminated: False, Truncated: False, Info: {}\n",
      "New State: (2, 4), Action: 1, Reward: 0, Terminated: False, Truncated: False, Info: {}\n",
      "New State: (3, 4), Action: 2, Reward: 0, Terminated: False, Truncated: False, Info: {}\n",
      "New State: (3, 1), Action: 3, Reward: 0, Terminated: False, Truncated: False, Info: {}\n",
      "New State: (4, 1), Action: 2, Reward: 0, Terminated: False, Truncated: False, Info: {}\n",
      "New State: (4, 0), Action: 3, Reward: 0, Terminated: False, Truncated: False, Info: {}\n",
      "New State: (4, 2), Action: 1, Reward: 0, Terminated: False, Truncated: False, Info: {}\n",
      "New State: (5, 2), Action: 2, Reward: 0, Terminated: False, Truncated: False, Info: {}\n",
      "New State: (5, 1), Action: 3, Reward: 0, Terminated: False, Truncated: False, Info: {}\n",
      "New State: (6, 1), Action: 2, Reward: 0, Terminated: False, Truncated: False, Info: {}\n",
      "New State: (6, 2), Action: 1, Reward: 0, Terminated: False, Truncated: False, Info: {}\n",
      "New State: (7, 2), Action: 2, Reward: 0, Terminated: False, Truncated: False, Info: {}\n",
      "New State: (8, 2), Action: 2, Reward: 0, Terminated: False, Truncated: False, Info: {}\n",
      "New State: (8, 3), Action: 1, Reward: 0, Terminated: False, Truncated: False, Info: {}\n",
      "New State: (9, 3), Action: 2, Reward: 0, Terminated: False, Truncated: False, Info: {}\n",
      "New State: (7, 3), Action: 0, Reward: 0, Terminated: False, Truncated: False, Info: {}\n",
      "New State: (6, 3), Action: 0, Reward: 0, Terminated: False, Truncated: False, Info: {}\n",
      "New State: (6, 4), Action: 1, Reward: 0, Terminated: False, Truncated: False, Info: {}\n",
      "New State: (7, 4), Action: 2, Reward: 0, Terminated: False, Truncated: False, Info: {}\n",
      "New State: (5, 4), Action: 0, Reward: 0, Terminated: False, Truncated: False, Info: {}\n",
      "New State: (2, 1), Action: 3, Reward: 0, Terminated: False, Truncated: False, Info: {}\n",
      "New State: (3, 0), Action: 3, Reward: 0, Terminated: False, Truncated: False, Info: {}\n",
      "New State: (5, 0), Action: 2, Reward: 0, Terminated: False, Truncated: False, Info: {}\n",
      "New State: (6, 0), Action: 2, Reward: 0, Terminated: False, Truncated: False, Info: {}\n",
      "New State: (7, 0), Action: 2, Reward: 0, Terminated: False, Truncated: False, Info: {}\n",
      "New State: (8, 0), Action: 2, Reward: 0, Terminated: False, Truncated: False, Info: {}\n",
      "New State: (9, 0), Action: 2, Reward: 0, Terminated: False, Truncated: False, Info: {}\n",
      "New State: (9, 1), Action: 1, Reward: 0, Terminated: False, Truncated: False, Info: {}\n",
      "New State: (7, 1), Action: 1, Reward: 0, Terminated: False, Truncated: False, Info: {}\n",
      "New State: (8, 1), Action: 2, Reward: 0, Terminated: False, Truncated: False, Info: {}\n",
      "New State: (0, 4), Action: 1, Reward: 0, Terminated: False, Truncated: False, Info: {}\n",
      "New State: (2, 5), Action: 1, Reward: 0, Terminated: False, Truncated: False, Info: {}\n",
      "New State: (3, 5), Action: 2, Reward: 0, Terminated: False, Truncated: False, Info: {}\n",
      "New State: (2, 6), Action: 1, Reward: 0, Terminated: False, Truncated: False, Info: {}\n",
      "New State: (2, 7), Action: 1, Reward: 0, Terminated: False, Truncated: False, Info: {}\n",
      "New State: (2, 8), Action: 1, Reward: 0, Terminated: False, Truncated: False, Info: {}\n",
      "New State: (3, 8), Action: 2, Reward: 0, Terminated: False, Truncated: False, Info: {}\n",
      "New State: (3, 9), Action: 1, Reward: 0, Terminated: False, Truncated: False, Info: {}\n",
      "New State: (2, 9), Action: 0, Reward: 0, Terminated: False, Truncated: False, Info: {}\n",
      "New State: (1, 7), Action: 0, Reward: 0, Terminated: False, Truncated: False, Info: {}\n",
      "New State: (3, 7), Action: 2, Reward: 0, Terminated: False, Truncated: False, Info: {}\n",
      "New State: (1, 8), Action: 0, Reward: 0, Terminated: False, Truncated: False, Info: {}\n",
      "New State: (0, 8), Action: 0, Reward: 0, Terminated: False, Truncated: False, Info: {}\n",
      "New State: (0, 7), Action: 3, Reward: 0, Terminated: False, Truncated: False, Info: {}\n",
      "New State: (1, 6), Action: 3, Reward: 0, Terminated: False, Truncated: False, Info: {}\n",
      "New State: (1, 5), Action: 3, Reward: 0, Terminated: False, Truncated: False, Info: {}\n",
      "New State: (3, 6), Action: 2, Reward: 0, Terminated: False, Truncated: False, Info: {}\n",
      "New State: (4, 6), Action: 2, Reward: 0, Terminated: False, Truncated: False, Info: {}\n",
      "New State: (4, 5), Action: 2, Reward: 0, Terminated: False, Truncated: False, Info: {}\n",
      "New State: (4, 4), Action: 3, Reward: 0, Terminated: False, Truncated: False, Info: {}\n",
      "New State: (4, 3), Action: 3, Reward: 0, Terminated: False, Truncated: False, Info: {}\n",
      "New State: (9, 2), Action: 1, Reward: 0, Terminated: False, Truncated: False, Info: {}\n",
      "New State: (9, 4), Action: 1, Reward: 0, Terminated: False, Truncated: False, Info: {}\n",
      "New State: (9, 5), Action: 1, Reward: 0, Terminated: False, Truncated: False, Info: {}\n",
      "New State: (8, 5), Action: 0, Reward: 0, Terminated: False, Truncated: False, Info: {}\n",
      "New State: (8, 6), Action: 1, Reward: 0, Terminated: False, Truncated: False, Info: {}\n",
      "New State: (8, 4), Action: 3, Reward: 0, Terminated: False, Truncated: False, Info: {}\n",
      "New State: (8, 7), Action: 1, Reward: 0, Terminated: False, Truncated: False, Info: {}\n",
      "New State: (7, 7), Action: 0, Reward: 0, Terminated: False, Truncated: False, Info: {}\n",
      "New State: (8, 8), Action: 1, Reward: 1.0, Terminated: True, Truncated: False, Info: {}\n",
      "Reached terminal state or truncated.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(1, 2),\n",
       " (0, 2),\n",
       " (0, 1),\n",
       " (1, 1),\n",
       " (0, 3),\n",
       " (2, 2),\n",
       " (3, 2),\n",
       " (3, 3),\n",
       " (2, 3),\n",
       " (1, 3),\n",
       " (1, 4),\n",
       " (2, 4),\n",
       " (3, 4),\n",
       " (3, 1),\n",
       " (4, 1),\n",
       " (4, 0),\n",
       " (4, 2),\n",
       " (5, 2),\n",
       " (5, 1),\n",
       " (6, 1),\n",
       " (6, 2),\n",
       " (7, 2),\n",
       " (8, 2),\n",
       " (8, 3),\n",
       " (9, 3),\n",
       " (7, 3),\n",
       " (6, 3),\n",
       " (6, 4),\n",
       " (7, 4),\n",
       " (5, 4),\n",
       " (2, 1),\n",
       " (3, 0),\n",
       " (5, 0),\n",
       " (6, 0),\n",
       " (7, 0),\n",
       " (8, 0),\n",
       " (9, 0),\n",
       " (9, 1),\n",
       " (7, 1),\n",
       " (8, 1),\n",
       " (0, 4),\n",
       " (2, 5),\n",
       " (3, 5),\n",
       " (2, 6),\n",
       " (2, 7),\n",
       " (2, 8),\n",
       " (3, 8),\n",
       " (3, 9),\n",
       " (2, 9),\n",
       " (1, 7),\n",
       " (3, 7),\n",
       " (1, 8),\n",
       " (0, 8),\n",
       " (0, 7),\n",
       " (1, 6),\n",
       " (1, 5),\n",
       " (3, 6),\n",
       " (4, 6),\n",
       " (4, 5),\n",
       " (4, 4),\n",
       " (4, 3),\n",
       " (9, 2),\n",
       " (9, 4),\n",
       " (9, 5),\n",
       " (8, 5),\n",
       " (8, 6),\n",
       " (8, 4),\n",
       " (8, 7),\n",
       " (7, 7),\n",
       " (8, 8)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def randomly_step_through_env(env):\n",
    "    is_terminated = False\n",
    "    truncated = False\n",
    "    visited_states = set()\n",
    "    recorded_states = []\n",
    "\n",
    "    while not is_terminated and not truncated:\n",
    "        # Sample a random action from the action space\n",
    "        action = env.action_space.sample()\n",
    "\n",
    "        # Take a step in the environment\n",
    "        s_prime, reward, is_terminated, truncated, info = env.step(action)\n",
    "\n",
    "        # Convert state to a hashable type (e.g., tuple) if it's not already\n",
    "        s_prime_hashable = (\n",
    "            tuple(s_prime) if isinstance(s_prime, (list, np.ndarray)) else s_prime\n",
    "        )\n",
    "\n",
    "        # Check if the state is new\n",
    "        if s_prime_hashable not in visited_states:\n",
    "            visited_states.add(s_prime_hashable)\n",
    "            recorded_states.append(s_prime)\n",
    "            print(\n",
    "                f\"New State: {s_prime}, Action: {action}, Reward: {reward}, Terminated: {is_terminated}, Truncated: {truncated}, Info: {info}\"\n",
    "            )\n",
    "\n",
    "    print(\"Reached terminal state or truncated.\")\n",
    "    return recorded_states\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "# Assuming `train_env` is your environment instance\n",
    "randomly_step_through_env(train_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss_records, bm_error = run_distribution_correction_experiment(\n",
    "#         tau=opts.tau,\n",
    "#         seed=opts.seed,\n",
    "#         run_id=opts.run_id,\n",
    "#         rows=opts.rows,\n",
    "#         cols=opts.cols,\n",
    "#         start_state=opts.start_state,\n",
    "#         p_success=opts.p_success,\n",
    "#         terminal_states=opts.terminal_states,\n",
    "#         num_steps=opts.num_steps,\n",
    "#         gamma=opts.gamma,\n",
    "#         min_samples=opts.min_samples,\n",
    "#         batch_size=opts.batch_size,\n",
    "#         train_max_iterations=opts.train_max_iterations,\n",
    "#         neural_fit_mode=opts.neural_fit_mode,\n",
    "#         algorithm=opts.algorithm,\n",
    "#         logger=logger,\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss_records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "general",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

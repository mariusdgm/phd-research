{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import random\n",
    "import pandas as pd\n",
    "import yaml\n",
    "\n",
    "from argparse import Namespace\n",
    "\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\", {'axes.grid' : False})\n",
    "\n",
    "root_dir = os.path.dirname(\n",
    "        os.path.dirname(os.path.realpath(\".\")))\n",
    "\n",
    "sys.path.append(root_dir)\n",
    "\n",
    "\n",
    "import logging\n",
    "\n",
    "from rl_envs_forge.envs.grid_world.grid_world import GridWorld\n",
    "from common.src.distribution_src import ( \n",
    "                                         make_env, \n",
    "                                        randomize_walls_positions, \n",
    "                                        generate_train_test_split_with_valid_path,\n",
    "                                        run_distribution_correction_experiment,\n",
    "                                        compute_validation_bellmans_error,\n",
    "                                        setup_dqn_agent\n",
    "                                        )\n",
    "from common.src.simple_dqn_agent import AgentDQN\n",
    "from scipy.stats import entropy\n",
    "\n",
    "\n",
    "from common.src.experiment_utils import (\n",
    "    setup_logger,\n",
    "    namespace_to_dict,\n",
    ")\n",
    "\n",
    "from common.src.distribution_src import run_dqn_distribution_correction_experiment\n",
    "\n",
    "\n",
    "from argparse import Namespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(2, 0), (1, 2)]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "terminal_states = {(2, 2): 1}\n",
    "start_state = (2, 1)\n",
    "rows = 5\n",
    "cols = 5\n",
    "seed = 2\n",
    "\n",
    "# random_walls = randomize_walls_positions(rows, cols, start_state, terminal_states, 0.2, seed=seed)\n",
    "random_walls = [(2, 0), (1, 2)]\n",
    "print(random_walls)\n",
    "env = make_env(\n",
    "    rows,\n",
    "    cols,\n",
    "    start_state=start_state,\n",
    "    p_success=1,\n",
    "    terminal_states=terminal_states,\n",
    "    seed=seed,\n",
    "    walls=random_walls,\n",
    ")\n",
    "env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_observation_space_shape(observation_space):\n",
    "    \"\"\"Extract a shape-like tuple from a tuple of discrete spaces.\"\"\"\n",
    "    return tuple(space.n for space in observation_space.spaces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tuple(Discrete(5), Discrete(5))"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 1)"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 0],\n",
       "       [1, 3, 2, 0, 0],\n",
       "       [0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def state_to_matrix(state, env):\n",
    "    import numpy as np\n",
    "\n",
    "    # Extract the environment size from walls and terminal states\n",
    "    max_rows = env.rows\n",
    "    max_cols = env.cols\n",
    "\n",
    "    # Create the matrix\n",
    "    matrix = np.zeros((max_rows, max_cols), dtype=int)\n",
    "\n",
    "    # Mark walls in the matrix\n",
    "    for wall in env.walls:\n",
    "        matrix[wall[0], wall[1]] = 1  # Use 1 to indicate walls\n",
    "\n",
    "    # Mark terminal states in the matrix\n",
    "    for terminal, value in env.terminal_states.items():\n",
    "        matrix[terminal[0], terminal[1]] = 2\n",
    "\n",
    "    pos = state\n",
    "    matrix[pos[0], pos[1]] = 3  # Use 3 to indicate the agent's position\n",
    "\n",
    "    return matrix\n",
    "\n",
    "\n",
    "state_to_matrix(env.state, env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 5)"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_shape = get_observation_space_shape(env.observation_space)\n",
    "state_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "# env.mdp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ts = next(iter(terminal_states))\n",
    "\n",
    "# for trial in range(100000):\n",
    "#     random_walls = randomize_walls_positions(rows, cols, start_state, terminal_states, 0.2, seed=trial)\n",
    "\n",
    "#     if (start_state in random_walls) or (ts in random_walls):\n",
    "#         raise ValueError(\"start state or terminal state in walls\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "transitions_list = [(key[0], key[1], *value[0]) for key, value in env.mdp.items()]\n",
    "\n",
    "transitions_train, transitions_val = generate_train_test_split_with_valid_path(\n",
    "    transitions_list=transitions_list,\n",
    "    start_state=start_state,\n",
    "    terminal_states=terminal_states,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'agent_params': {'agent': 'AgentDQN',\n",
       "  'args_': {'batch_size': 32,\n",
       "   'epsilon': {'decay': 5000, 'end': 0.01, 'start': 1.0},\n",
       "   'gamma': 0.9,\n",
       "   'loss_fcn': 'mse_loss',\n",
       "   'replay_start_size': 50,\n",
       "   'target_model_update_freq': 40,\n",
       "   'train_step_cnt': 500,\n",
       "   'training_freq': 4,\n",
       "   'validation_enabled': False,\n",
       "   'validation_epsilon': 0.001,\n",
       "   'validation_step_cnt': 250}},\n",
       " 'algorithm': 'default',\n",
       " 'cfg_id': 0,\n",
       " 'cols': 10,\n",
       " 'experiment': 'experiment_distributions',\n",
       " 'experiment_arguments': {'algorithm': 'default'},\n",
       " 'full_title': '2024Jun05-180814_configs_algorithm=default',\n",
       " 'neural_fit_mode': 'max',\n",
       " 'num_steps': 40000,\n",
       " 'optim': {'args_': {'eps': 0.0003125, 'lr': 0.1}, 'name': 'Adam'},\n",
       " 'out_dir': '.\\\\results\\\\2024Jun05-180814_configs\\\\0000_algorithm_default\\\\0',\n",
       " 'p_success': 1,\n",
       " 'replay_buffer': {'action_dim': 1, 'max_size': 1000, 'n_step': 0},\n",
       " 'rows': 10,\n",
       " 'run_id': 0,\n",
       " 'seed': 761532230,\n",
       " 'start_state': (1, 1),\n",
       " 'terminal_states': {(8, 8): 1.0},\n",
       " 'title': 'algorithm=default',\n",
       " 'train_max_iterations': 30}"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Load up a config\n",
    "\n",
    "file_path = r\"D:\\Work\\repos\\phd-research\\experiments\\dqn\\results\\2024Jun05-180814_configs\\0000_algorithm_default\\0\\cfg.yaml\"\n",
    "\n",
    "# Open the YAML file and load its content into a dictionary\n",
    "with open(file_path, \"r\") as file:\n",
    "    data = yaml.safe_load(file)\n",
    "\n",
    "opts = Namespace(**data)\n",
    "\n",
    "logger = setup_logger(opts.full_title)\n",
    "\n",
    "opts.seed = random.randint(0, 2**32 - 1) if opts.seed is None else opts.seed\n",
    "opts_dict = namespace_to_dict(opts)\n",
    "# opts_dict = vars(opts)\n",
    "\n",
    "opts_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Namespace(agent_params={'agent': 'AgentDQN', 'args_': {'batch_size': 32, 'epsilon': {'decay': 5000, 'end': 0.01, 'start': 1.0}, 'gamma': 0.9, 'loss_fcn': 'mse_loss', 'replay_start_size': 50, 'target_model_update_freq': 40, 'train_step_cnt': 500, 'training_freq': 4, 'validation_enabled': False, 'validation_epsilon': 0.001, 'validation_step_cnt': 250}}, algorithm='default', cfg_id=0, cols=10, experiment='experiment_distributions', experiment_arguments={'algorithm': 'default'}, full_title='2024Jun05-180814_configs_algorithm=default', neural_fit_mode='max', num_steps=40000, optim={'args_': {'eps': 0.0003125, 'lr': 0.1}, 'name': 'Adam'}, out_dir='.\\\\results\\\\2024Jun05-180814_configs\\\\0000_algorithm_default\\\\0', p_success=1, replay_buffer={'action_dim': 1, 'max_size': 1000, 'n_step': 0}, rows=10, run_id=0, seed=761532230, start_state='(1, 1)', terminal_states={'(8, 8)': 1.0}, title='algorithm=default', train_max_iterations=30)"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1)"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opts_dict[\"start_state\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(8, 8): 1.0}"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opts_dict[\"terminal_states\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-06-06 00:26:33,389 - 2024Jun05-180814_configs_algorithm=default - INFO - Starting experiment: 2024Jun05-180814_configs_algorithm=default\n",
      "2024-06-06 00:26:33,389 - 2024Jun05-180814_configs_algorithm=default - INFO - Starting experiment: 2024Jun05-180814_configs_algorithm=default\n",
      "2024-06-06 00:26:33,389 - 2024Jun05-180814_configs_algorithm=default - INFO - Starting experiment: 2024Jun05-180814_configs_algorithm=default\n",
      "2024-06-06 00:26:33,389 - 2024Jun05-180814_configs_algorithm=default - INFO - Starting experiment: 2024Jun05-180814_configs_algorithm=default\n",
      "2024-06-06 00:26:33,389 - 2024Jun05-180814_configs_algorithm=default - INFO - Starting experiment: 2024Jun05-180814_configs_algorithm=default\n",
      "2024-06-06 00:26:33,389 - 2024Jun05-180814_configs_algorithm=default - INFO - Starting experiment: 2024Jun05-180814_configs_algorithm=default\n",
      "2024-06-06 00:26:33,389 - 2024Jun05-180814_configs_algorithm=default - INFO - Starting experiment: 2024Jun05-180814_configs_algorithm=default\n",
      "2024-06-06 00:26:33,389 - 2024Jun05-180814_configs_algorithm=default - INFO - Starting experiment: 2024Jun05-180814_configs_algorithm=default\n",
      "2024-06-06 00:26:33,389 - 2024Jun05-180814_configs_algorithm=default - INFO - Starting experiment: 2024Jun05-180814_configs_algorithm=default\n",
      "2024-06-06 00:26:33,389 - 2024Jun05-180814_configs_algorithm=default - INFO - Starting experiment: 2024Jun05-180814_configs_algorithm=default\n",
      "2024-06-06 00:26:33,389 - 2024Jun05-180814_configs_algorithm=default - INFO - Starting experiment: 2024Jun05-180814_configs_algorithm=default\n",
      "2024-06-06 00:26:33,393 - 2024Jun05-180814_configs_algorithm=default - INFO - Starting experiment: 2024Jun05-180814_configs_algorithm=default\n",
      "2024-06-06 00:26:33,393 - 2024Jun05-180814_configs_algorithm=default - INFO - Starting experiment: 2024Jun05-180814_configs_algorithm=default\n",
      "2024-06-06 00:26:33,393 - 2024Jun05-180814_configs_algorithm=default - INFO - Starting experiment: 2024Jun05-180814_configs_algorithm=default\n",
      "2024-06-06 00:26:33,393 - 2024Jun05-180814_configs_algorithm=default - INFO - Starting experiment: 2024Jun05-180814_configs_algorithm=default\n",
      "2024-06-06 00:26:33,393 - 2024Jun05-180814_configs_algorithm=default - INFO - Starting experiment: 2024Jun05-180814_configs_algorithm=default\n",
      "2024-06-06 00:26:33,393 - 2024Jun05-180814_configs_algorithm=default - INFO - Starting experiment: 2024Jun05-180814_configs_algorithm=default\n",
      "2024-06-06 00:26:33,393 - 2024Jun05-180814_configs_algorithm=default - INFO - Starting experiment: 2024Jun05-180814_configs_algorithm=default\n",
      "2024-06-06 00:26:33,393 - 2024Jun05-180814_configs_algorithm=default - INFO - Starting experiment: 2024Jun05-180814_configs_algorithm=default\n",
      "2024-06-06 00:26:33,393 - 2024Jun05-180814_configs_algorithm=default - INFO - Starting experiment: 2024Jun05-180814_configs_algorithm=default\n",
      "2024-06-06 00:26:33,393 - 2024Jun05-180814_configs_algorithm=default - INFO - Starting experiment: 2024Jun05-180814_configs_algorithm=default\n",
      "2024-06-06 00:26:33,393 - 2024Jun05-180814_configs_algorithm=default - INFO - Starting experiment: 2024Jun05-180814_configs_algorithm=default\n",
      "2024-06-06 00:26:33,401 - 2024Jun05-180814_configs_algorithm=default - INFO - Loaded configuration settings.\n",
      "2024-06-06 00:26:33,401 - 2024Jun05-180814_configs_algorithm=default - INFO - Loaded configuration settings.\n",
      "2024-06-06 00:26:33,401 - 2024Jun05-180814_configs_algorithm=default - INFO - Loaded configuration settings.\n",
      "2024-06-06 00:26:33,401 - 2024Jun05-180814_configs_algorithm=default - INFO - Loaded configuration settings.\n",
      "2024-06-06 00:26:33,401 - 2024Jun05-180814_configs_algorithm=default - INFO - Loaded configuration settings.\n",
      "2024-06-06 00:26:33,401 - 2024Jun05-180814_configs_algorithm=default - INFO - Loaded configuration settings.\n",
      "2024-06-06 00:26:33,401 - 2024Jun05-180814_configs_algorithm=default - INFO - Loaded configuration settings.\n",
      "2024-06-06 00:26:33,401 - 2024Jun05-180814_configs_algorithm=default - INFO - Loaded configuration settings.\n",
      "2024-06-06 00:26:33,401 - 2024Jun05-180814_configs_algorithm=default - INFO - Loaded configuration settings.\n",
      "2024-06-06 00:26:33,401 - 2024Jun05-180814_configs_algorithm=default - INFO - Loaded configuration settings.\n",
      "2024-06-06 00:26:33,401 - 2024Jun05-180814_configs_algorithm=default - INFO - Loaded configuration settings.\n",
      "2024-06-06 00:26:33,405 - 2024Jun05-180814_configs_algorithm=default - INFO - Initialized newtworks and optimizer.\n",
      "2024-06-06 00:26:33,405 - 2024Jun05-180814_configs_algorithm=default - INFO - Initialized newtworks and optimizer.\n",
      "2024-06-06 00:26:33,405 - 2024Jun05-180814_configs_algorithm=default - INFO - Initialized newtworks and optimizer.\n",
      "2024-06-06 00:26:33,405 - 2024Jun05-180814_configs_algorithm=default - INFO - Initialized newtworks and optimizer.\n",
      "2024-06-06 00:26:33,405 - 2024Jun05-180814_configs_algorithm=default - INFO - Initialized newtworks and optimizer.\n",
      "2024-06-06 00:26:33,405 - 2024Jun05-180814_configs_algorithm=default - INFO - Initialized newtworks and optimizer.\n",
      "2024-06-06 00:26:33,405 - 2024Jun05-180814_configs_algorithm=default - INFO - Initialized newtworks and optimizer.\n",
      "2024-06-06 00:26:33,405 - 2024Jun05-180814_configs_algorithm=default - INFO - Initialized newtworks and optimizer.\n",
      "2024-06-06 00:26:33,405 - 2024Jun05-180814_configs_algorithm=default - INFO - Initialized newtworks and optimizer.\n",
      "2024-06-06 00:26:33,405 - 2024Jun05-180814_configs_algorithm=default - INFO - Initialized newtworks and optimizer.\n",
      "2024-06-06 00:26:33,405 - 2024Jun05-180814_configs_algorithm=default - INFO - Initialized newtworks and optimizer.\n",
      "2024-06-06 00:26:33,409 - 2024Jun05-180814_configs_algorithm=default - INFO - Starting training session at: 0\n",
      "2024-06-06 00:26:33,409 - 2024Jun05-180814_configs_algorithm=default - INFO - Starting training session at: 0\n",
      "2024-06-06 00:26:33,409 - 2024Jun05-180814_configs_algorithm=default - INFO - Starting training session at: 0\n",
      "2024-06-06 00:26:33,409 - 2024Jun05-180814_configs_algorithm=default - INFO - Starting training session at: 0\n",
      "2024-06-06 00:26:33,409 - 2024Jun05-180814_configs_algorithm=default - INFO - Starting training session at: 0\n",
      "2024-06-06 00:26:33,409 - 2024Jun05-180814_configs_algorithm=default - INFO - Starting training session at: 0\n",
      "2024-06-06 00:26:33,409 - 2024Jun05-180814_configs_algorithm=default - INFO - Starting training session at: 0\n",
      "2024-06-06 00:26:33,409 - 2024Jun05-180814_configs_algorithm=default - INFO - Starting training session at: 0\n",
      "2024-06-06 00:26:33,409 - 2024Jun05-180814_configs_algorithm=default - INFO - Starting training session at: 0\n",
      "2024-06-06 00:26:33,409 - 2024Jun05-180814_configs_algorithm=default - INFO - Starting training session at: 0\n",
      "2024-06-06 00:26:33,409 - 2024Jun05-180814_configs_algorithm=default - INFO - Starting training session at: 0\n",
      "2024-06-06 00:26:33,412 - 2024Jun05-180814_configs_algorithm=default - INFO - Starting training epoch at t = 0\n",
      "2024-06-06 00:26:33,412 - 2024Jun05-180814_configs_algorithm=default - INFO - Starting training epoch at t = 0\n",
      "2024-06-06 00:26:33,412 - 2024Jun05-180814_configs_algorithm=default - INFO - Starting training epoch at t = 0\n",
      "2024-06-06 00:26:33,412 - 2024Jun05-180814_configs_algorithm=default - INFO - Starting training epoch at t = 0\n",
      "2024-06-06 00:26:33,412 - 2024Jun05-180814_configs_algorithm=default - INFO - Starting training epoch at t = 0\n",
      "2024-06-06 00:26:33,412 - 2024Jun05-180814_configs_algorithm=default - INFO - Starting training epoch at t = 0\n",
      "2024-06-06 00:26:33,412 - 2024Jun05-180814_configs_algorithm=default - INFO - Starting training epoch at t = 0\n",
      "2024-06-06 00:26:33,412 - 2024Jun05-180814_configs_algorithm=default - INFO - Starting training epoch at t = 0\n",
      "2024-06-06 00:26:33,412 - 2024Jun05-180814_configs_algorithm=default - INFO - Starting training epoch at t = 0\n",
      "2024-06-06 00:26:33,412 - 2024Jun05-180814_configs_algorithm=default - INFO - Starting training epoch at t = 0\n",
      "2024-06-06 00:26:33,412 - 2024Jun05-180814_configs_algorithm=default - INFO - Starting training epoch at t = 0\n",
      "2024-06-06 00:26:33,561 - 2024Jun05-180814_configs_algorithm=default - INFO - TRAINING STATS | Frames seen: 500 | Episode: 2 | Max reward: 1.0 | Avg reward: 1.0 | Avg frames (episode): 250.0 | Avg max Q: 0.42218176275491714 | Epsilon: 0.9109 | Train epoch time: 0:00:00.144598\n",
      "2024-06-06 00:26:33,561 - 2024Jun05-180814_configs_algorithm=default - INFO - TRAINING STATS | Frames seen: 500 | Episode: 2 | Max reward: 1.0 | Avg reward: 1.0 | Avg frames (episode): 250.0 | Avg max Q: 0.42218176275491714 | Epsilon: 0.9109 | Train epoch time: 0:00:00.144598\n",
      "2024-06-06 00:26:33,561 - 2024Jun05-180814_configs_algorithm=default - INFO - TRAINING STATS | Frames seen: 500 | Episode: 2 | Max reward: 1.0 | Avg reward: 1.0 | Avg frames (episode): 250.0 | Avg max Q: 0.42218176275491714 | Epsilon: 0.9109 | Train epoch time: 0:00:00.144598\n",
      "2024-06-06 00:26:33,561 - 2024Jun05-180814_configs_algorithm=default - INFO - TRAINING STATS | Frames seen: 500 | Episode: 2 | Max reward: 1.0 | Avg reward: 1.0 | Avg frames (episode): 250.0 | Avg max Q: 0.42218176275491714 | Epsilon: 0.9109 | Train epoch time: 0:00:00.144598\n",
      "2024-06-06 00:26:33,561 - 2024Jun05-180814_configs_algorithm=default - INFO - TRAINING STATS | Frames seen: 500 | Episode: 2 | Max reward: 1.0 | Avg reward: 1.0 | Avg frames (episode): 250.0 | Avg max Q: 0.42218176275491714 | Epsilon: 0.9109 | Train epoch time: 0:00:00.144598\n",
      "2024-06-06 00:26:33,561 - 2024Jun05-180814_configs_algorithm=default - INFO - TRAINING STATS | Frames seen: 500 | Episode: 2 | Max reward: 1.0 | Avg reward: 1.0 | Avg frames (episode): 250.0 | Avg max Q: 0.42218176275491714 | Epsilon: 0.9109 | Train epoch time: 0:00:00.144598\n",
      "2024-06-06 00:26:33,561 - 2024Jun05-180814_configs_algorithm=default - INFO - TRAINING STATS | Frames seen: 500 | Episode: 2 | Max reward: 1.0 | Avg reward: 1.0 | Avg frames (episode): 250.0 | Avg max Q: 0.42218176275491714 | Epsilon: 0.9109 | Train epoch time: 0:00:00.144598\n",
      "2024-06-06 00:26:33,561 - 2024Jun05-180814_configs_algorithm=default - INFO - TRAINING STATS | Frames seen: 500 | Episode: 2 | Max reward: 1.0 | Avg reward: 1.0 | Avg frames (episode): 250.0 | Avg max Q: 0.42218176275491714 | Epsilon: 0.9109 | Train epoch time: 0:00:00.144598\n",
      "2024-06-06 00:26:33,561 - 2024Jun05-180814_configs_algorithm=default - INFO - TRAINING STATS | Frames seen: 500 | Episode: 2 | Max reward: 1.0 | Avg reward: 1.0 | Avg frames (episode): 250.0 | Avg max Q: 0.42218176275491714 | Epsilon: 0.9109 | Train epoch time: 0:00:00.144598\n",
      "2024-06-06 00:26:33,561 - 2024Jun05-180814_configs_algorithm=default - INFO - TRAINING STATS | Frames seen: 500 | Episode: 2 | Max reward: 1.0 | Avg reward: 1.0 | Avg frames (episode): 250.0 | Avg max Q: 0.42218176275491714 | Epsilon: 0.9109 | Train epoch time: 0:00:00.144598\n",
      "2024-06-06 00:26:33,561 - 2024Jun05-180814_configs_algorithm=default - INFO - TRAINING STATS | Frames seen: 500 | Episode: 2 | Max reward: 1.0 | Avg reward: 1.0 | Avg frames (episode): 250.0 | Avg max Q: 0.42218176275491714 | Epsilon: 0.9109 | Train epoch time: 0:00:00.144598\n",
      "2024-06-06 00:26:33,565 - 2024Jun05-180814_configs_algorithm=default - INFO - Saving checkpoint at t = 500 ...\n",
      "2024-06-06 00:26:33,565 - 2024Jun05-180814_configs_algorithm=default - INFO - Saving checkpoint at t = 500 ...\n",
      "2024-06-06 00:26:33,565 - 2024Jun05-180814_configs_algorithm=default - INFO - Saving checkpoint at t = 500 ...\n",
      "2024-06-06 00:26:33,565 - 2024Jun05-180814_configs_algorithm=default - INFO - Saving checkpoint at t = 500 ...\n",
      "2024-06-06 00:26:33,565 - 2024Jun05-180814_configs_algorithm=default - INFO - Saving checkpoint at t = 500 ...\n",
      "2024-06-06 00:26:33,565 - 2024Jun05-180814_configs_algorithm=default - INFO - Saving checkpoint at t = 500 ...\n",
      "2024-06-06 00:26:33,565 - 2024Jun05-180814_configs_algorithm=default - INFO - Saving checkpoint at t = 500 ...\n",
      "2024-06-06 00:26:33,565 - 2024Jun05-180814_configs_algorithm=default - INFO - Saving checkpoint at t = 500 ...\n",
      "2024-06-06 00:26:33,565 - 2024Jun05-180814_configs_algorithm=default - INFO - Saving checkpoint at t = 500 ...\n",
      "2024-06-06 00:26:33,565 - 2024Jun05-180814_configs_algorithm=default - INFO - Saving checkpoint at t = 500 ...\n",
      "2024-06-06 00:26:33,565 - 2024Jun05-180814_configs_algorithm=default - INFO - Saving checkpoint at t = 500 ...\n",
      "2024-06-06 00:26:33,569 - 2024Jun05-180814_configs_algorithm=default - INFO - Checkpoint saved at t = 500\n",
      "2024-06-06 00:26:33,569 - 2024Jun05-180814_configs_algorithm=default - INFO - Checkpoint saved at t = 500\n",
      "2024-06-06 00:26:33,569 - 2024Jun05-180814_configs_algorithm=default - INFO - Checkpoint saved at t = 500\n",
      "2024-06-06 00:26:33,569 - 2024Jun05-180814_configs_algorithm=default - INFO - Checkpoint saved at t = 500\n",
      "2024-06-06 00:26:33,569 - 2024Jun05-180814_configs_algorithm=default - INFO - Checkpoint saved at t = 500\n",
      "2024-06-06 00:26:33,569 - 2024Jun05-180814_configs_algorithm=default - INFO - Checkpoint saved at t = 500\n",
      "2024-06-06 00:26:33,569 - 2024Jun05-180814_configs_algorithm=default - INFO - Checkpoint saved at t = 500\n",
      "2024-06-06 00:26:33,569 - 2024Jun05-180814_configs_algorithm=default - INFO - Checkpoint saved at t = 500\n",
      "2024-06-06 00:26:33,569 - 2024Jun05-180814_configs_algorithm=default - INFO - Checkpoint saved at t = 500\n",
      "2024-06-06 00:26:33,569 - 2024Jun05-180814_configs_algorithm=default - INFO - Checkpoint saved at t = 500\n",
      "2024-06-06 00:26:33,569 - 2024Jun05-180814_configs_algorithm=default - INFO - Checkpoint saved at t = 500\n",
      "2024-06-06 00:26:33,571 - 2024Jun05-180814_configs_algorithm=default - INFO - Epoch 0 completed in 0:00:00.158870\n",
      "2024-06-06 00:26:33,571 - 2024Jun05-180814_configs_algorithm=default - INFO - Epoch 0 completed in 0:00:00.158870\n",
      "2024-06-06 00:26:33,571 - 2024Jun05-180814_configs_algorithm=default - INFO - Epoch 0 completed in 0:00:00.158870\n",
      "2024-06-06 00:26:33,571 - 2024Jun05-180814_configs_algorithm=default - INFO - Epoch 0 completed in 0:00:00.158870\n",
      "2024-06-06 00:26:33,571 - 2024Jun05-180814_configs_algorithm=default - INFO - Epoch 0 completed in 0:00:00.158870\n",
      "2024-06-06 00:26:33,571 - 2024Jun05-180814_configs_algorithm=default - INFO - Epoch 0 completed in 0:00:00.158870\n",
      "2024-06-06 00:26:33,571 - 2024Jun05-180814_configs_algorithm=default - INFO - Epoch 0 completed in 0:00:00.158870\n",
      "2024-06-06 00:26:33,571 - 2024Jun05-180814_configs_algorithm=default - INFO - Epoch 0 completed in 0:00:00.158870\n",
      "2024-06-06 00:26:33,571 - 2024Jun05-180814_configs_algorithm=default - INFO - Epoch 0 completed in 0:00:00.158870\n",
      "2024-06-06 00:26:33,571 - 2024Jun05-180814_configs_algorithm=default - INFO - Epoch 0 completed in 0:00:00.158870\n",
      "2024-06-06 00:26:33,571 - 2024Jun05-180814_configs_algorithm=default - INFO - Epoch 0 completed in 0:00:00.158870\n",
      "2024-06-06 00:26:33,575 - 2024Jun05-180814_configs_algorithm=default - INFO - \n",
      "\n",
      "2024-06-06 00:26:33,575 - 2024Jun05-180814_configs_algorithm=default - INFO - \n",
      "\n",
      "2024-06-06 00:26:33,575 - 2024Jun05-180814_configs_algorithm=default - INFO - \n",
      "\n",
      "2024-06-06 00:26:33,575 - 2024Jun05-180814_configs_algorithm=default - INFO - \n",
      "\n",
      "2024-06-06 00:26:33,575 - 2024Jun05-180814_configs_algorithm=default - INFO - \n",
      "\n",
      "2024-06-06 00:26:33,575 - 2024Jun05-180814_configs_algorithm=default - INFO - \n",
      "\n",
      "2024-06-06 00:26:33,575 - 2024Jun05-180814_configs_algorithm=default - INFO - \n",
      "\n",
      "2024-06-06 00:26:33,575 - 2024Jun05-180814_configs_algorithm=default - INFO - \n",
      "\n",
      "2024-06-06 00:26:33,575 - 2024Jun05-180814_configs_algorithm=default - INFO - \n",
      "\n",
      "2024-06-06 00:26:33,575 - 2024Jun05-180814_configs_algorithm=default - INFO - \n",
      "\n",
      "2024-06-06 00:26:33,575 - 2024Jun05-180814_configs_algorithm=default - INFO - \n",
      "\n",
      "2024-06-06 00:26:33,578 - 2024Jun05-180814_configs_algorithm=default - INFO - Ended training session after 1 epochs at t = 500\n",
      "2024-06-06 00:26:33,578 - 2024Jun05-180814_configs_algorithm=default - INFO - Ended training session after 1 epochs at t = 500\n",
      "2024-06-06 00:26:33,578 - 2024Jun05-180814_configs_algorithm=default - INFO - Ended training session after 1 epochs at t = 500\n",
      "2024-06-06 00:26:33,578 - 2024Jun05-180814_configs_algorithm=default - INFO - Ended training session after 1 epochs at t = 500\n",
      "2024-06-06 00:26:33,578 - 2024Jun05-180814_configs_algorithm=default - INFO - Ended training session after 1 epochs at t = 500\n",
      "2024-06-06 00:26:33,578 - 2024Jun05-180814_configs_algorithm=default - INFO - Ended training session after 1 epochs at t = 500\n",
      "2024-06-06 00:26:33,578 - 2024Jun05-180814_configs_algorithm=default - INFO - Ended training session after 1 epochs at t = 500\n",
      "2024-06-06 00:26:33,578 - 2024Jun05-180814_configs_algorithm=default - INFO - Ended training session after 1 epochs at t = 500\n",
      "2024-06-06 00:26:33,578 - 2024Jun05-180814_configs_algorithm=default - INFO - Ended training session after 1 epochs at t = 500\n",
      "2024-06-06 00:26:33,578 - 2024Jun05-180814_configs_algorithm=default - INFO - Ended training session after 1 epochs at t = 500\n",
      "2024-06-06 00:26:33,578 - 2024Jun05-180814_configs_algorithm=default - INFO - Ended training session after 1 epochs at t = 500\n",
      "Initial transitions count: 500\n",
      "Initial transitions (first 10):\n",
      "(tensor([1., 1.]), 1, 0, tensor([1., 2.]), False)\n",
      "(tensor([1., 2.]), 1, 0, tensor([1., 3.]), False)\n",
      "(tensor([1., 3.]), 0, 0, tensor([0., 3.]), False)\n",
      "(tensor([0., 3.]), 2, 0, tensor([1., 3.]), False)\n",
      "(tensor([1., 3.]), 2, 0, tensor([2., 3.]), False)\n",
      "(tensor([2., 3.]), 2, 0, tensor([3., 3.]), False)\n",
      "(tensor([3., 3.]), 2, 0, tensor([4., 3.]), False)\n",
      "(tensor([4., 3.]), 1, 0, tensor([4., 4.]), False)\n",
      "(tensor([4., 4.]), 0, 0, tensor([3., 4.]), False)\n",
      "(tensor([3., 4.]), 1, 0, tensor([3., 5.]), False)\n",
      "500\n",
      "[(tensor([1., 1.]), 1, 0, tensor([1., 2.]), False), (tensor([1., 2.]), 1, 0, tensor([1., 3.]), False), (tensor([1., 3.]), 0, 0, tensor([0., 3.]), False)]\n",
      "unique_nr 214\n",
      "Counts after normalization: [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "Normalized buffer contents (first 10):\n",
      "((5.0, 2.0), 1, 0, (5.0, 3.0), False)\n",
      "((5.0, 1.0), 3, 0, (5.0, 0.0), False)\n",
      "((7.0, 5.0), 2, 0, (8.0, 5.0), False)\n",
      "((6.0, 0.0), 2, 0, (7.0, 0.0), False)\n",
      "((4.0, 4.0), 3, 0, (4.0, 3.0), False)\n",
      "((7.0, 1.0), 2, 0, (8.0, 1.0), False)\n",
      "((3.0, 1.0), 2, 0, (4.0, 1.0), False)\n",
      "((6.0, 2.0), 0, 0, (5.0, 2.0), False)\n",
      "((4.0, 1.0), 1, 0, (4.0, 2.0), False)\n",
      "((2.0, 0.0), 2, 0, (3.0, 0.0), False)\n",
      "2024-06-06 00:26:33,637 - 2024Jun05-180814_configs_algorithm=default - INFO - Resuming training session at: 500 (1 epochs left)\n",
      "2024-06-06 00:26:33,637 - 2024Jun05-180814_configs_algorithm=default - INFO - Resuming training session at: 500 (1 epochs left)\n",
      "2024-06-06 00:26:33,637 - 2024Jun05-180814_configs_algorithm=default - INFO - Resuming training session at: 500 (1 epochs left)\n",
      "2024-06-06 00:26:33,637 - 2024Jun05-180814_configs_algorithm=default - INFO - Resuming training session at: 500 (1 epochs left)\n",
      "2024-06-06 00:26:33,637 - 2024Jun05-180814_configs_algorithm=default - INFO - Resuming training session at: 500 (1 epochs left)\n",
      "2024-06-06 00:26:33,637 - 2024Jun05-180814_configs_algorithm=default - INFO - Resuming training session at: 500 (1 epochs left)\n",
      "2024-06-06 00:26:33,637 - 2024Jun05-180814_configs_algorithm=default - INFO - Resuming training session at: 500 (1 epochs left)\n",
      "2024-06-06 00:26:33,637 - 2024Jun05-180814_configs_algorithm=default - INFO - Resuming training session at: 500 (1 epochs left)\n",
      "2024-06-06 00:26:33,637 - 2024Jun05-180814_configs_algorithm=default - INFO - Resuming training session at: 500 (1 epochs left)\n",
      "2024-06-06 00:26:33,637 - 2024Jun05-180814_configs_algorithm=default - INFO - Resuming training session at: 500 (1 epochs left)\n",
      "2024-06-06 00:26:33,637 - 2024Jun05-180814_configs_algorithm=default - INFO - Resuming training session at: 500 (1 epochs left)\n",
      "2024-06-06 00:26:33,641 - 2024Jun05-180814_configs_algorithm=default - INFO - Starting training epoch at t = 500\n",
      "2024-06-06 00:26:33,641 - 2024Jun05-180814_configs_algorithm=default - INFO - Starting training epoch at t = 500\n",
      "2024-06-06 00:26:33,641 - 2024Jun05-180814_configs_algorithm=default - INFO - Starting training epoch at t = 500\n",
      "2024-06-06 00:26:33,641 - 2024Jun05-180814_configs_algorithm=default - INFO - Starting training epoch at t = 500\n",
      "2024-06-06 00:26:33,641 - 2024Jun05-180814_configs_algorithm=default - INFO - Starting training epoch at t = 500\n",
      "2024-06-06 00:26:33,641 - 2024Jun05-180814_configs_algorithm=default - INFO - Starting training epoch at t = 500\n",
      "2024-06-06 00:26:33,641 - 2024Jun05-180814_configs_algorithm=default - INFO - Starting training epoch at t = 500\n",
      "2024-06-06 00:26:33,641 - 2024Jun05-180814_configs_algorithm=default - INFO - Starting training epoch at t = 500\n",
      "2024-06-06 00:26:33,641 - 2024Jun05-180814_configs_algorithm=default - INFO - Starting training epoch at t = 500\n",
      "2024-06-06 00:26:33,641 - 2024Jun05-180814_configs_algorithm=default - INFO - Starting training epoch at t = 500\n",
      "2024-06-06 00:26:33,641 - 2024Jun05-180814_configs_algorithm=default - INFO - Starting training epoch at t = 500\n",
      "2024-06-06 00:26:33,808 - 2024Jun05-180814_configs_algorithm=default - INFO - TRAINING STATS | Frames seen: 1000 | Episode: 6 | Max reward: 1.0 | Avg reward: 1.0 | Avg frames (episode): 80.5 | Avg max Q: 0.4138857764311326 | Epsilon: 0.8119000000000001 | Train epoch time: 0:00:00.160766\n",
      "2024-06-06 00:26:33,808 - 2024Jun05-180814_configs_algorithm=default - INFO - TRAINING STATS | Frames seen: 1000 | Episode: 6 | Max reward: 1.0 | Avg reward: 1.0 | Avg frames (episode): 80.5 | Avg max Q: 0.4138857764311326 | Epsilon: 0.8119000000000001 | Train epoch time: 0:00:00.160766\n",
      "2024-06-06 00:26:33,808 - 2024Jun05-180814_configs_algorithm=default - INFO - TRAINING STATS | Frames seen: 1000 | Episode: 6 | Max reward: 1.0 | Avg reward: 1.0 | Avg frames (episode): 80.5 | Avg max Q: 0.4138857764311326 | Epsilon: 0.8119000000000001 | Train epoch time: 0:00:00.160766\n",
      "2024-06-06 00:26:33,808 - 2024Jun05-180814_configs_algorithm=default - INFO - TRAINING STATS | Frames seen: 1000 | Episode: 6 | Max reward: 1.0 | Avg reward: 1.0 | Avg frames (episode): 80.5 | Avg max Q: 0.4138857764311326 | Epsilon: 0.8119000000000001 | Train epoch time: 0:00:00.160766\n",
      "2024-06-06 00:26:33,808 - 2024Jun05-180814_configs_algorithm=default - INFO - TRAINING STATS | Frames seen: 1000 | Episode: 6 | Max reward: 1.0 | Avg reward: 1.0 | Avg frames (episode): 80.5 | Avg max Q: 0.4138857764311326 | Epsilon: 0.8119000000000001 | Train epoch time: 0:00:00.160766\n",
      "2024-06-06 00:26:33,808 - 2024Jun05-180814_configs_algorithm=default - INFO - TRAINING STATS | Frames seen: 1000 | Episode: 6 | Max reward: 1.0 | Avg reward: 1.0 | Avg frames (episode): 80.5 | Avg max Q: 0.4138857764311326 | Epsilon: 0.8119000000000001 | Train epoch time: 0:00:00.160766\n",
      "2024-06-06 00:26:33,808 - 2024Jun05-180814_configs_algorithm=default - INFO - TRAINING STATS | Frames seen: 1000 | Episode: 6 | Max reward: 1.0 | Avg reward: 1.0 | Avg frames (episode): 80.5 | Avg max Q: 0.4138857764311326 | Epsilon: 0.8119000000000001 | Train epoch time: 0:00:00.160766\n",
      "2024-06-06 00:26:33,808 - 2024Jun05-180814_configs_algorithm=default - INFO - TRAINING STATS | Frames seen: 1000 | Episode: 6 | Max reward: 1.0 | Avg reward: 1.0 | Avg frames (episode): 80.5 | Avg max Q: 0.4138857764311326 | Epsilon: 0.8119000000000001 | Train epoch time: 0:00:00.160766\n",
      "2024-06-06 00:26:33,808 - 2024Jun05-180814_configs_algorithm=default - INFO - TRAINING STATS | Frames seen: 1000 | Episode: 6 | Max reward: 1.0 | Avg reward: 1.0 | Avg frames (episode): 80.5 | Avg max Q: 0.4138857764311326 | Epsilon: 0.8119000000000001 | Train epoch time: 0:00:00.160766\n",
      "2024-06-06 00:26:33,808 - 2024Jun05-180814_configs_algorithm=default - INFO - TRAINING STATS | Frames seen: 1000 | Episode: 6 | Max reward: 1.0 | Avg reward: 1.0 | Avg frames (episode): 80.5 | Avg max Q: 0.4138857764311326 | Epsilon: 0.8119000000000001 | Train epoch time: 0:00:00.160766\n",
      "2024-06-06 00:26:33,808 - 2024Jun05-180814_configs_algorithm=default - INFO - TRAINING STATS | Frames seen: 1000 | Episode: 6 | Max reward: 1.0 | Avg reward: 1.0 | Avg frames (episode): 80.5 | Avg max Q: 0.4138857764311326 | Epsilon: 0.8119000000000001 | Train epoch time: 0:00:00.160766\n",
      "2024-06-06 00:26:33,811 - 2024Jun05-180814_configs_algorithm=default - INFO - Saving checkpoint at t = 1000 ...\n",
      "2024-06-06 00:26:33,811 - 2024Jun05-180814_configs_algorithm=default - INFO - Saving checkpoint at t = 1000 ...\n",
      "2024-06-06 00:26:33,811 - 2024Jun05-180814_configs_algorithm=default - INFO - Saving checkpoint at t = 1000 ...\n",
      "2024-06-06 00:26:33,811 - 2024Jun05-180814_configs_algorithm=default - INFO - Saving checkpoint at t = 1000 ...\n",
      "2024-06-06 00:26:33,811 - 2024Jun05-180814_configs_algorithm=default - INFO - Saving checkpoint at t = 1000 ...\n",
      "2024-06-06 00:26:33,811 - 2024Jun05-180814_configs_algorithm=default - INFO - Saving checkpoint at t = 1000 ...\n",
      "2024-06-06 00:26:33,811 - 2024Jun05-180814_configs_algorithm=default - INFO - Saving checkpoint at t = 1000 ...\n",
      "2024-06-06 00:26:33,811 - 2024Jun05-180814_configs_algorithm=default - INFO - Saving checkpoint at t = 1000 ...\n",
      "2024-06-06 00:26:33,811 - 2024Jun05-180814_configs_algorithm=default - INFO - Saving checkpoint at t = 1000 ...\n",
      "2024-06-06 00:26:33,811 - 2024Jun05-180814_configs_algorithm=default - INFO - Saving checkpoint at t = 1000 ...\n",
      "2024-06-06 00:26:33,811 - 2024Jun05-180814_configs_algorithm=default - INFO - Saving checkpoint at t = 1000 ...\n",
      "2024-06-06 00:26:33,814 - 2024Jun05-180814_configs_algorithm=default - INFO - Checkpoint saved at t = 1000\n",
      "2024-06-06 00:26:33,814 - 2024Jun05-180814_configs_algorithm=default - INFO - Checkpoint saved at t = 1000\n",
      "2024-06-06 00:26:33,814 - 2024Jun05-180814_configs_algorithm=default - INFO - Checkpoint saved at t = 1000\n",
      "2024-06-06 00:26:33,814 - 2024Jun05-180814_configs_algorithm=default - INFO - Checkpoint saved at t = 1000\n",
      "2024-06-06 00:26:33,814 - 2024Jun05-180814_configs_algorithm=default - INFO - Checkpoint saved at t = 1000\n",
      "2024-06-06 00:26:33,814 - 2024Jun05-180814_configs_algorithm=default - INFO - Checkpoint saved at t = 1000\n",
      "2024-06-06 00:26:33,814 - 2024Jun05-180814_configs_algorithm=default - INFO - Checkpoint saved at t = 1000\n",
      "2024-06-06 00:26:33,814 - 2024Jun05-180814_configs_algorithm=default - INFO - Checkpoint saved at t = 1000\n",
      "2024-06-06 00:26:33,814 - 2024Jun05-180814_configs_algorithm=default - INFO - Checkpoint saved at t = 1000\n",
      "2024-06-06 00:26:33,814 - 2024Jun05-180814_configs_algorithm=default - INFO - Checkpoint saved at t = 1000\n",
      "2024-06-06 00:26:33,814 - 2024Jun05-180814_configs_algorithm=default - INFO - Checkpoint saved at t = 1000\n",
      "2024-06-06 00:26:33,817 - 2024Jun05-180814_configs_algorithm=default - INFO - Epoch 0 completed in 0:00:00.175769\n",
      "2024-06-06 00:26:33,817 - 2024Jun05-180814_configs_algorithm=default - INFO - Epoch 0 completed in 0:00:00.175769\n",
      "2024-06-06 00:26:33,817 - 2024Jun05-180814_configs_algorithm=default - INFO - Epoch 0 completed in 0:00:00.175769\n",
      "2024-06-06 00:26:33,817 - 2024Jun05-180814_configs_algorithm=default - INFO - Epoch 0 completed in 0:00:00.175769\n",
      "2024-06-06 00:26:33,817 - 2024Jun05-180814_configs_algorithm=default - INFO - Epoch 0 completed in 0:00:00.175769\n",
      "2024-06-06 00:26:33,817 - 2024Jun05-180814_configs_algorithm=default - INFO - Epoch 0 completed in 0:00:00.175769\n",
      "2024-06-06 00:26:33,817 - 2024Jun05-180814_configs_algorithm=default - INFO - Epoch 0 completed in 0:00:00.175769\n",
      "2024-06-06 00:26:33,817 - 2024Jun05-180814_configs_algorithm=default - INFO - Epoch 0 completed in 0:00:00.175769\n",
      "2024-06-06 00:26:33,817 - 2024Jun05-180814_configs_algorithm=default - INFO - Epoch 0 completed in 0:00:00.175769\n",
      "2024-06-06 00:26:33,817 - 2024Jun05-180814_configs_algorithm=default - INFO - Epoch 0 completed in 0:00:00.175769\n",
      "2024-06-06 00:26:33,817 - 2024Jun05-180814_configs_algorithm=default - INFO - Epoch 0 completed in 0:00:00.175769\n",
      "2024-06-06 00:26:33,820 - 2024Jun05-180814_configs_algorithm=default - INFO - \n",
      "\n",
      "2024-06-06 00:26:33,820 - 2024Jun05-180814_configs_algorithm=default - INFO - \n",
      "\n",
      "2024-06-06 00:26:33,820 - 2024Jun05-180814_configs_algorithm=default - INFO - \n",
      "\n",
      "2024-06-06 00:26:33,820 - 2024Jun05-180814_configs_algorithm=default - INFO - \n",
      "\n",
      "2024-06-06 00:26:33,820 - 2024Jun05-180814_configs_algorithm=default - INFO - \n",
      "\n",
      "2024-06-06 00:26:33,820 - 2024Jun05-180814_configs_algorithm=default - INFO - \n",
      "\n",
      "2024-06-06 00:26:33,820 - 2024Jun05-180814_configs_algorithm=default - INFO - \n",
      "\n",
      "2024-06-06 00:26:33,820 - 2024Jun05-180814_configs_algorithm=default - INFO - \n",
      "\n",
      "2024-06-06 00:26:33,820 - 2024Jun05-180814_configs_algorithm=default - INFO - \n",
      "\n",
      "2024-06-06 00:26:33,820 - 2024Jun05-180814_configs_algorithm=default - INFO - \n",
      "\n",
      "2024-06-06 00:26:33,820 - 2024Jun05-180814_configs_algorithm=default - INFO - \n",
      "\n",
      "2024-06-06 00:26:33,822 - 2024Jun05-180814_configs_algorithm=default - INFO - Ended training session after 1 epochs at t = 1000\n",
      "2024-06-06 00:26:33,822 - 2024Jun05-180814_configs_algorithm=default - INFO - Ended training session after 1 epochs at t = 1000\n",
      "2024-06-06 00:26:33,822 - 2024Jun05-180814_configs_algorithm=default - INFO - Ended training session after 1 epochs at t = 1000\n",
      "2024-06-06 00:26:33,822 - 2024Jun05-180814_configs_algorithm=default - INFO - Ended training session after 1 epochs at t = 1000\n",
      "2024-06-06 00:26:33,822 - 2024Jun05-180814_configs_algorithm=default - INFO - Ended training session after 1 epochs at t = 1000\n",
      "2024-06-06 00:26:33,822 - 2024Jun05-180814_configs_algorithm=default - INFO - Ended training session after 1 epochs at t = 1000\n",
      "2024-06-06 00:26:33,822 - 2024Jun05-180814_configs_algorithm=default - INFO - Ended training session after 1 epochs at t = 1000\n",
      "2024-06-06 00:26:33,822 - 2024Jun05-180814_configs_algorithm=default - INFO - Ended training session after 1 epochs at t = 1000\n",
      "2024-06-06 00:26:33,822 - 2024Jun05-180814_configs_algorithm=default - INFO - Ended training session after 1 epochs at t = 1000\n",
      "2024-06-06 00:26:33,822 - 2024Jun05-180814_configs_algorithm=default - INFO - Ended training session after 1 epochs at t = 1000\n",
      "2024-06-06 00:26:33,822 - 2024Jun05-180814_configs_algorithm=default - INFO - Ended training session after 1 epochs at t = 1000\n",
      "Initial transitions count: 1000\n",
      "Initial transitions (first 10):\n",
      "(tensor([1., 1.]), 1, 0, tensor([1., 2.]), False)\n",
      "(tensor([1., 2.]), 1, 0, tensor([1., 3.]), False)\n",
      "(tensor([1., 3.]), 0, 0, tensor([0., 3.]), False)\n",
      "(tensor([0., 3.]), 2, 0, tensor([1., 3.]), False)\n",
      "(tensor([1., 3.]), 2, 0, tensor([2., 3.]), False)\n",
      "(tensor([2., 3.]), 2, 0, tensor([3., 3.]), False)\n",
      "(tensor([3., 3.]), 2, 0, tensor([4., 3.]), False)\n",
      "(tensor([4., 3.]), 1, 0, tensor([4., 4.]), False)\n",
      "(tensor([4., 4.]), 0, 0, tensor([3., 4.]), False)\n",
      "(tensor([3., 4.]), 1, 0, tensor([3., 5.]), False)\n",
      "1000\n",
      "[(tensor([1., 1.]), 1, 0, tensor([1., 2.]), False), (tensor([1., 2.]), 1, 0, tensor([1., 3.]), False), (tensor([1., 3.]), 0, 0, tensor([0., 3.]), False)]\n",
      "unique_nr 298\n",
      "Counts after normalization: [3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
      " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
      " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
      " 4 4]\n",
      "Normalized buffer contents (first 10):\n",
      "((9.0, 3.0), 2, 0, (9.0, 3.0), False)\n",
      "((4.0, 5.0), 1, 0, (4.0, 6.0), False)\n",
      "((4.0, 3.0), 0, 0, (3.0, 3.0), False)\n",
      "((2.0, 0.0), 1, 0, (2.0, 1.0), False)\n",
      "((2.0, 5.0), 2, 0, (3.0, 5.0), False)\n",
      "((2.0, 3.0), 0, 0, (1.0, 3.0), False)\n",
      "((5.0, 0.0), 2, 0, (6.0, 0.0), False)\n",
      "((1.0, 4.0), 0, 0, (0.0, 4.0), False)\n",
      "((9.0, 5.0), 1, 0, (9.0, 6.0), False)\n",
      "((1.0, 1.0), 1, 0, (1.0, 2.0), False)\n"
     ]
    }
   ],
   "source": [
    "logger.info(f\"Starting experiment: {opts_dict['full_title']}\")\n",
    "\n",
    "agent = setup_dqn_agent(\n",
    "    config=opts_dict,\n",
    "    logger=logger,\n",
    ")\n",
    "\n",
    "transitions_list = [\n",
    "    (key[0], key[1], *value[0]) for key, value in agent.train_env.mdp.items()\n",
    "]\n",
    "\n",
    "experiment_data = []\n",
    "for i in range(1, 3):\n",
    "    agent.train(i)\n",
    "\n",
    "    bm_error_validation = compute_validation_bellmans_error(\n",
    "        agent.target_model,\n",
    "        validation_transitions=transitions_list,\n",
    "        error_mode=opts_dict[\"neural_fit_mode\"],\n",
    "        gamma=agent.gamma,\n",
    "        logger=logger,\n",
    "    )\n",
    "\n",
    "    rb_entropy = agent.replay_buffer.calculate_buffer_entropy()\n",
    "\n",
    "    normalized_rb = agent.replay_buffer.normalize_replay_buffer()\n",
    "    normalized_rb_entropy = normalized_rb.calculate_buffer_entropy()\n",
    "\n",
    "# experiment_agent.train(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "rb_buffer = agent.replay_buffer\n",
    "buffer = rb_buffer.buffer\n",
    "\n",
    "examples = [(transition[0], transition[1]) for transition in buffer]\n",
    "example_strings = [f\"{state}_{action}\" for state, action in examples]\n",
    "unique_examples, counts = np.unique(example_strings, return_counts=True)\n",
    "example_entropy = entropy(counts, base=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "298"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unique_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  2,\n",
       "        2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
       "        2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
       "        2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
       "        2,  2,  2,  2,  2,  2,  2,  2,  2,  3,  3,  3,  3,  3,  3,  3,  3,\n",
       "        3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,\n",
       "        3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,\n",
       "        3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  4,  4,  4,  4,\n",
       "        4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,\n",
       "        4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  5,  5,  5,\n",
       "        5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,\n",
       "        5,  5,  5,  5,  5,  5,  5,  5,  5,  6,  6,  6,  6,  6,  6,  6,  6,\n",
       "        6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  7,  7,\n",
       "        7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  8,  8,  8,  8,  8,  8,  8,\n",
       "        8,  9,  9,  9,  9,  9,  9, 10, 11], dtype=int64)"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts.sort()\n",
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.938594280900301"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial transitions count: 1000\n",
      "Initial transitions (first 10):\n",
      "(tensor([1., 1.]), 1, 0, tensor([1., 2.]), False)\n",
      "(tensor([1., 2.]), 1, 0, tensor([1., 3.]), False)\n",
      "(tensor([1., 3.]), 0, 0, tensor([0., 3.]), False)\n",
      "(tensor([0., 3.]), 2, 0, tensor([1., 3.]), False)\n",
      "(tensor([1., 3.]), 2, 0, tensor([2., 3.]), False)\n",
      "(tensor([2., 3.]), 2, 0, tensor([3., 3.]), False)\n",
      "(tensor([3., 3.]), 2, 0, tensor([4., 3.]), False)\n",
      "(tensor([4., 3.]), 1, 0, tensor([4., 4.]), False)\n",
      "(tensor([4., 4.]), 0, 0, tensor([3., 4.]), False)\n",
      "(tensor([3., 4.]), 1, 0, tensor([3., 5.]), False)\n",
      "1000\n",
      "[(tensor([1., 1.]), 1, 0, tensor([1., 2.]), False), (tensor([1., 2.]), 1, 0, tensor([1., 3.]), False), (tensor([1., 3.]), 0, 0, tensor([0., 3.]), False)]\n",
      "unique_nr 298\n",
      "Counts after normalization: [3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
      " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
      " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
      " 4 4]\n",
      "Normalized buffer contents (first 10):\n",
      "((3.0, 8.0), 3, 0, (3.0, 7.0), False)\n",
      "((4.0, 4.0), 1, 0, (4.0, 5.0), False)\n",
      "((2.0, 0.0), 3, 0, (2.0, 0.0), False)\n",
      "((5.0, 0.0), 3, 0, (5.0, 0.0), False)\n",
      "((9.0, 4.0), 2, 0, (9.0, 4.0), False)\n",
      "((9.0, 3.0), 2, 0, (9.0, 3.0), False)\n",
      "((4.0, 3.0), 0, 0, (3.0, 3.0), False)\n",
      "((8.0, 2.0), 0, 0, (7.0, 2.0), False)\n",
      "((6.0, 6.0), 0, 0, (5.0, 6.0), False)\n",
      "((3.0, 1.0), 0, 0, (2.0, 1.0), False)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "normalized_rb = rb_buffer.normalize_replay_buffer()\n",
    "normalized_rb_entropy = normalized_rb.calculate_buffer_entropy()\n",
    "buffer_normed = normalized_rb.buffer\n",
    "\n",
    "\n",
    "examples_normalized = [(transition[0], transition[1]) for transition in buffer_normed]\n",
    "example_strings_normalized = [f\"{state}_{action}\" for state, action in examples_normalized]\n",
    "len(example_strings_normalized)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "298"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_examples, counts = np.unique(example_strings_normalized, return_counts=True)\n",
    "len(unique_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 3, 3, 3, 3, 3, 3, 4, 4, 3, 4, 3,\n",
       "       4, 3, 3, 3, 4, 4, 4, 3, 4, 3, 4, 3, 4, 3, 3, 4, 3, 4, 3, 4, 3, 3,\n",
       "       4, 4, 3, 4, 4, 3, 3, 3, 3, 4, 3, 4, 3, 3, 3, 3, 4, 4, 3, 3, 3, 3,\n",
       "       3, 4, 4, 3, 3, 4, 3, 3, 3, 3, 3, 4, 3, 4, 4, 4, 3, 4, 3, 4, 4, 3,\n",
       "       3, 3, 4, 3, 4, 3, 3, 3, 3, 3, 4, 3, 3, 4, 3, 4, 3, 4, 3, 3, 4, 3,\n",
       "       4, 4, 4, 4, 3, 3, 4, 4, 4, 3, 3, 3, 3, 4, 4, 4, 4, 4, 3, 3, 3, 3,\n",
       "       4, 3, 3, 3, 4, 4, 3, 3, 3, 3, 4, 3, 3, 3, 4, 3, 3, 4, 3, 3, 3, 3,\n",
       "       3, 3, 3, 4, 4, 3, 3, 4, 4, 3, 3, 3, 3, 3, 4, 4, 3, 4, 4, 3, 3, 3,\n",
       "       3, 3, 4, 4, 3, 3, 3, 3, 4, 3, 3, 4, 3, 3, 4, 4, 3, 4, 3, 3, 4, 4,\n",
       "       4, 3, 3, 3, 3, 4, 4, 3, 3, 3, 3, 3, 4, 3, 3, 3, 3, 4, 3, 4, 3, 3,\n",
       "       3, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 3, 3, 4, 3, 3, 3, 3,\n",
       "       4, 4, 3, 3, 3, 4, 3, 3, 3, 3, 4, 3, 3, 3, 4, 4, 3, 3, 3, 3, 4, 4,\n",
       "       3, 4, 4, 4, 3, 3, 3, 3, 3, 4, 3, 3, 4, 3, 3, 4, 3, 3, 4, 3, 4, 3,\n",
       "       3, 4, 4, 3, 3, 4, 3, 4, 3, 3, 4, 3], dtype=int64)"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.204845884246701"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_entropy_normed = entropy(counts, base=2)\n",
    "example_entropy_normed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.204845884246701"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_rb_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_env' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[276], line 33\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m recorded_states\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# Example usage:\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# Assuming `train_env` is your environment instance\u001b[39;00m\n\u001b[1;32m---> 33\u001b[0m randomly_step_through_env(\u001b[43mtrain_env\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_env' is not defined"
     ]
    }
   ],
   "source": [
    "def randomly_step_through_env(env):\n",
    "    is_terminated = False\n",
    "    truncated = False\n",
    "    visited_states = set()\n",
    "    recorded_states = []\n",
    "\n",
    "    while not is_terminated and not truncated:\n",
    "        # Sample a random action from the action space\n",
    "        action = env.action_space.sample()\n",
    "\n",
    "        # Take a step in the environment\n",
    "        s_prime, reward, is_terminated, truncated, info = env.step(action)\n",
    "\n",
    "        # Convert state to a hashable type (e.g., tuple) if it's not already\n",
    "        s_prime_hashable = (\n",
    "            tuple(s_prime) if isinstance(s_prime, (list, np.ndarray)) else s_prime\n",
    "        )\n",
    "\n",
    "        # Check if the state is new\n",
    "        if s_prime_hashable not in visited_states:\n",
    "            visited_states.add(s_prime_hashable)\n",
    "            recorded_states.append(s_prime)\n",
    "            print(\n",
    "                f\"New State: {s_prime}, Action: {action}, Reward: {reward}, Terminated: {is_terminated}, Truncated: {truncated}, Info: {info}\"\n",
    "            )\n",
    "\n",
    "    print(\"Reached terminal state or truncated.\")\n",
    "    return recorded_states\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "# Assuming `train_env` is your environment instance\n",
    "randomly_step_through_env(train_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss_records, bm_error = run_distribution_correction_experiment(\n",
    "#         tau=opts.tau,\n",
    "#         seed=opts.seed,\n",
    "#         run_id=opts.run_id,\n",
    "#         rows=opts.rows,\n",
    "#         cols=opts.cols,\n",
    "#         start_state=opts.start_state,\n",
    "#         p_success=opts.p_success,\n",
    "#         terminal_states=opts.terminal_states,\n",
    "#         num_steps=opts.num_steps,\n",
    "#         gamma=opts.gamma,\n",
    "#         min_samples=opts.min_samples,\n",
    "#         batch_size=opts.batch_size,\n",
    "#         train_max_iterations=opts.train_max_iterations,\n",
    "#         neural_fit_mode=opts.neural_fit_mode,\n",
    "#         algorithm=opts.algorithm,\n",
    "#         logger=logger,\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss_records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "general",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

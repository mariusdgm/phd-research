{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import random\n",
    "import pandas as pd\n",
    "import yaml\n",
    "\n",
    "from argparse import Namespace\n",
    "\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\", {'axes.grid' : False})\n",
    "\n",
    "root_dir = os.path.dirname(\n",
    "        os.path.dirname(os.path.realpath(\".\")))\n",
    "\n",
    "sys.path.append(root_dir)\n",
    "\n",
    "\n",
    "import logging\n",
    "\n",
    "from rl_envs_forge.envs.grid_world.grid_world import GridWorld\n",
    "from common.src.distribution_src import ( \n",
    "                                         make_env, \n",
    "                                        randomize_walls_positions, \n",
    "                                        generate_train_test_split_with_valid_path,\n",
    "                                        run_distribution_correction_experiment,\n",
    "                                        compute_validation_bellmans_error,\n",
    "                                        setup_dqn_agent\n",
    "                                        )\n",
    "from common.src.simple_dqn_agent import AgentDQN\n",
    "from scipy.stats import entropy\n",
    "\n",
    "\n",
    "from common.src.experiment_utils import (\n",
    "    setup_logger,\n",
    "    namespace_to_dict,\n",
    ")\n",
    "\n",
    "from common.src.distribution_src import run_dqn_distribution_correction_experiment\n",
    "\n",
    "\n",
    "from argparse import Namespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(2, 0), (1, 2)]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "terminal_states = {(2, 2): 1}\n",
    "start_state = (2, 1)\n",
    "rows = 5\n",
    "cols = 5\n",
    "seed = 2\n",
    "\n",
    "# random_walls = randomize_walls_positions(rows, cols, start_state, terminal_states, 0.2, seed=seed)\n",
    "random_walls = [(2, 0), (1, 2)]\n",
    "print(random_walls)\n",
    "env = make_env(\n",
    "    rows,\n",
    "    cols,\n",
    "    start_state=start_state,\n",
    "    p_success=1,\n",
    "    terminal_states=terminal_states,\n",
    "    seed=seed,\n",
    "    walls=random_walls,\n",
    ")\n",
    "env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_observation_space_shape(observation_space):\n",
    "    \"\"\"Extract a shape-like tuple from a tuple of discrete spaces.\"\"\"\n",
    "    return tuple(space.n for space in observation_space.spaces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tuple(Discrete(5), Discrete(5))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 1)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 0],\n",
       "       [1, 3, 2, 0, 0],\n",
       "       [0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def state_to_matrix(state, env):\n",
    "    import numpy as np\n",
    "\n",
    "    # Extract the environment size from walls and terminal states\n",
    "    max_rows = env.rows\n",
    "    max_cols = env.cols\n",
    "\n",
    "    # Create the matrix\n",
    "    matrix = np.zeros((max_rows, max_cols), dtype=int)\n",
    "\n",
    "    # Mark walls in the matrix\n",
    "    for wall in env.walls:\n",
    "        matrix[wall[0], wall[1]] = 1  # Use 1 to indicate walls\n",
    "\n",
    "    # Mark terminal states in the matrix\n",
    "    for terminal, value in env.terminal_states.items():\n",
    "        matrix[terminal[0], terminal[1]] = 2\n",
    "\n",
    "    pos = state\n",
    "    matrix[pos[0], pos[1]] = 3  # Use 3 to indicate the agent's position\n",
    "\n",
    "    return matrix\n",
    "\n",
    "\n",
    "state_to_matrix(env.state, env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 5)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_shape = get_observation_space_shape(env.observation_space)\n",
    "state_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# env.mdp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ts = next(iter(terminal_states))\n",
    "\n",
    "# for trial in range(100000):\n",
    "#     random_walls = randomize_walls_positions(rows, cols, start_state, terminal_states, 0.2, seed=trial)\n",
    "\n",
    "#     if (start_state in random_walls) or (ts in random_walls):\n",
    "#         raise ValueError(\"start state or terminal state in walls\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "transitions_list = [(key[0], key[1], *value[0]) for key, value in env.mdp.items()]\n",
    "\n",
    "transitions_train, transitions_val = generate_train_test_split_with_valid_path(\n",
    "    transitions_list=transitions_list,\n",
    "    start_state=start_state,\n",
    "    terminal_states=terminal_states,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'agent_params': {'agent': 'AgentDQN',\n",
       "  'args_': {'batch_size': 32,\n",
       "   'epsilon': {'decay': 5000, 'end': 0.01, 'start': 1.0},\n",
       "   'gamma': 0.9,\n",
       "   'loss_fcn': 'mse_loss',\n",
       "   'replay_start_size': 50,\n",
       "   'target_model_update_freq': 40,\n",
       "   'train_step_cnt': 500,\n",
       "   'training_freq': 4,\n",
       "   'validation_enabled': False,\n",
       "   'validation_epsilon': 0.001,\n",
       "   'validation_step_cnt': 250}},\n",
       " 'algorithm': 'default',\n",
       " 'cfg_id': 0,\n",
       " 'cols': 10,\n",
       " 'experiment': 'experiment_distributions',\n",
       " 'experiment_arguments': {'algorithm': 'default'},\n",
       " 'full_title': '2024Jun10-002258_configs_algorithm=default',\n",
       " 'neural_fit_mode': 'max',\n",
       " 'num_steps': 40000,\n",
       " 'optim': {'args_': {'eps': 0.0003125, 'lr': 0.1}, 'name': 'Adam'},\n",
       " 'out_dir': '.\\\\results\\\\2024Jun10-002258_configs\\\\0000_algorithm_default\\\\1',\n",
       " 'p_success': 1,\n",
       " 'replay_buffer': {'action_dim': 1, 'max_size': 1000, 'n_step': 0},\n",
       " 'rows': 10,\n",
       " 'run_id': 1,\n",
       " 'seed': 539462332,\n",
       " 'start_state': (1, 1),\n",
       " 'terminal_states': {(8, 8): 1.0},\n",
       " 'title': 'algorithm=default',\n",
       " 'train_max_iterations': 30}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Load up a config\n",
    "\n",
    "file_path = r\"D:\\Work\\repos\\phd-research\\experiments\\dqn\\results\\2024Jun10-002258_configs\\0000_algorithm_default\\1\\cfg.yaml\"\n",
    "\n",
    "# Open the YAML file and load its content into a dictionary\n",
    "with open(file_path, \"r\") as file:\n",
    "    data = yaml.safe_load(file)\n",
    "\n",
    "opts = Namespace(**data)\n",
    "\n",
    "logger = setup_logger(opts.full_title)\n",
    "\n",
    "opts.seed = random.randint(0, 2**32 - 1) if opts.seed is None else opts.seed\n",
    "opts_dict = namespace_to_dict(opts)\n",
    "# opts_dict = vars(opts)\n",
    "\n",
    "opts_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Namespace(agent_params={'agent': 'AgentDQN', 'args_': {'batch_size': 32, 'epsilon': {'decay': 5000, 'end': 0.01, 'start': 1.0}, 'gamma': 0.9, 'loss_fcn': 'mse_loss', 'replay_start_size': 50, 'target_model_update_freq': 40, 'train_step_cnt': 500, 'training_freq': 4, 'validation_enabled': False, 'validation_epsilon': 0.001, 'validation_step_cnt': 250}}, algorithm='default', cfg_id=0, cols=10, experiment='experiment_distributions', experiment_arguments={'algorithm': 'default'}, full_title='2024Jun10-002258_configs_algorithm=default', neural_fit_mode='max', num_steps=40000, optim={'args_': {'eps': 0.0003125, 'lr': 0.1}, 'name': 'Adam'}, out_dir='.\\\\results\\\\2024Jun10-002258_configs\\\\0000_algorithm_default\\\\1', p_success=1, replay_buffer={'action_dim': 1, 'max_size': 1000, 'n_step': 0}, rows=10, run_id=1, seed=539462332, start_state='(1, 1)', terminal_states={'(8, 8)': 1.0}, title='algorithm=default', train_max_iterations=30)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opts_dict[\"start_state\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(8, 8): 1.0}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opts_dict[\"terminal_states\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-06-10 00:26:41,467 - 2024Jun10-002258_configs_algorithm=default - INFO - Starting experiment: 2024Jun10-002258_configs_algorithm=default\n",
      "2024-06-10 00:26:41,467 - 2024Jun10-002258_configs_algorithm=default - INFO - Starting experiment: 2024Jun10-002258_configs_algorithm=default\n",
      "2024-06-10 00:26:41,468 - 2024Jun10-002258_configs_algorithm=default - INFO - Starting experiment: 2024Jun10-002258_configs_algorithm=default\n",
      "2024-06-10 00:26:41,468 - 2024Jun10-002258_configs_algorithm=default - INFO - Starting experiment: 2024Jun10-002258_configs_algorithm=default\n",
      "2024-06-10 00:26:41,554 - 2024Jun10-002258_configs_algorithm=default - INFO - Loaded configuration settings.\n",
      "2024-06-10 00:26:41,554 - 2024Jun10-002258_configs_algorithm=default - INFO - Loaded configuration settings.\n",
      "2024-06-10 00:26:41,556 - 2024Jun10-002258_configs_algorithm=default - INFO - Initialized newtworks and optimizer.\n",
      "2024-06-10 00:26:41,556 - 2024Jun10-002258_configs_algorithm=default - INFO - Initialized newtworks and optimizer.\n",
      "2024-06-10 00:26:41,557 - 2024Jun10-002258_configs_algorithm=default - INFO - Starting training session at: 0\n",
      "2024-06-10 00:26:41,557 - 2024Jun10-002258_configs_algorithm=default - INFO - Starting training session at: 0\n",
      "2024-06-10 00:26:41,558 - 2024Jun10-002258_configs_algorithm=default - INFO - Starting training epoch at t = 0\n",
      "2024-06-10 00:26:41,558 - 2024Jun10-002258_configs_algorithm=default - INFO - Starting training epoch at t = 0\n",
      "2024-06-10 00:26:41,559 - 2024Jun10-002258_configs_algorithm=default - INFO - Episode 0 terminated at frame 39 with reward 1.0\n",
      "2024-06-10 00:26:41,559 - 2024Jun10-002258_configs_algorithm=default - INFO - Episode 0 terminated at frame 39 with reward 1.0\n",
      "2024-06-10 00:26:41,716 - 2024Jun10-002258_configs_algorithm=default - INFO - TRAINING STATS | Frames seen: 500 | Episode: 1 | Max reward: 1.0 | Avg reward: 1.0 | Avg frames (episode): 40.0 | Avg max Q: nan | Epsilon: 0.9109 | Train epoch time: 0:00:00.155864\n",
      "2024-06-10 00:26:41,716 - 2024Jun10-002258_configs_algorithm=default - INFO - TRAINING STATS | Frames seen: 500 | Episode: 1 | Max reward: 1.0 | Avg reward: 1.0 | Avg frames (episode): 40.0 | Avg max Q: nan | Epsilon: 0.9109 | Train epoch time: 0:00:00.155864\n",
      "2024-06-10 00:26:41,716 - 2024Jun10-002258_configs_algorithm=default - INFO - Saving checkpoint at t = 500 ...\n",
      "2024-06-10 00:26:41,716 - 2024Jun10-002258_configs_algorithm=default - INFO - Saving checkpoint at t = 500 ...\n",
      "2024-06-10 00:26:41,718 - 2024Jun10-002258_configs_algorithm=default - INFO - Checkpoint saved at t = 500\n",
      "2024-06-10 00:26:41,718 - 2024Jun10-002258_configs_algorithm=default - INFO - Checkpoint saved at t = 500\n",
      "2024-06-10 00:26:41,718 - 2024Jun10-002258_configs_algorithm=default - INFO - Epoch 0 completed in 0:00:00.159863. Frames seen: 500\n",
      "2024-06-10 00:26:41,718 - 2024Jun10-002258_configs_algorithm=default - INFO - Epoch 0 completed in 0:00:00.159863. Frames seen: 500\n",
      "2024-06-10 00:26:41,719 - 2024Jun10-002258_configs_algorithm=default - INFO - \n",
      "\n",
      "2024-06-10 00:26:41,719 - 2024Jun10-002258_configs_algorithm=default - INFO - \n",
      "\n",
      "2024-06-10 00:26:41,719 - 2024Jun10-002258_configs_algorithm=default - INFO - Ended training session after 1 epochs at t = 500\n",
      "2024-06-10 00:26:41,719 - 2024Jun10-002258_configs_algorithm=default - INFO - Ended training session after 1 epochs at t = 500\n",
      "2024-06-10 00:26:41,804 - 2024Jun10-002258_configs_algorithm=default - INFO - Resuming training session at: 500 (1 epochs left)\n",
      "2024-06-10 00:26:41,804 - 2024Jun10-002258_configs_algorithm=default - INFO - Resuming training session at: 500 (1 epochs left)\n",
      "2024-06-10 00:26:41,804 - 2024Jun10-002258_configs_algorithm=default - INFO - Starting training epoch at t = 500\n",
      "2024-06-10 00:26:41,804 - 2024Jun10-002258_configs_algorithm=default - INFO - Starting training epoch at t = 500\n",
      "2024-06-10 00:26:41,902 - 2024Jun10-002258_configs_algorithm=default - INFO - Episode 1 terminated at frame 263 with reward 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Work\\repos\\phd-research\\common\\src\\simple_dqn_agent.py:725: RuntimeWarning: All-NaN axis encountered\n",
      "  stats[\"min\"] = np.nanmin(vector)\n",
      "D:\\Work\\repos\\phd-research\\common\\src\\simple_dqn_agent.py:726: RuntimeWarning: All-NaN axis encountered\n",
      "  stats[\"max\"] = np.nanmax(vector)\n",
      "D:\\Work\\repos\\phd-research\\common\\src\\simple_dqn_agent.py:727: RuntimeWarning: Mean of empty slice\n",
      "  stats[\"mean\"] = np.nanmean(vector)\n",
      "D:\\Work\\repos\\phd-research\\common\\src\\simple_dqn_agent.py:728: RuntimeWarning: All-NaN slice encountered\n",
      "  stats[\"median\"] = np.nanmedian(vector)\n",
      "c:\\Users\\Chainsword\\anaconda3\\envs\\phd_rl_algos\\Lib\\site-packages\\numpy\\lib\\nanfunctions.py:1879: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-06-10 00:26:41,902 - 2024Jun10-002258_configs_algorithm=default - INFO - Episode 1 terminated at frame 263 with reward 1.0\n",
      "2024-06-10 00:26:41,990 - 2024Jun10-002258_configs_algorithm=default - INFO - TRAINING STATS | Frames seen: 1000 | Episode: 2 | Max reward: 1.0 | Avg reward: 1.0 | Avg frames (episode): 724.0 | Avg max Q: 0.9396681218850808 | Epsilon: 0.8119000000000001 | Train epoch time: 0:00:00.185904\n",
      "2024-06-10 00:26:41,990 - 2024Jun10-002258_configs_algorithm=default - INFO - TRAINING STATS | Frames seen: 1000 | Episode: 2 | Max reward: 1.0 | Avg reward: 1.0 | Avg frames (episode): 724.0 | Avg max Q: 0.9396681218850808 | Epsilon: 0.8119000000000001 | Train epoch time: 0:00:00.185904\n",
      "2024-06-10 00:26:41,991 - 2024Jun10-002258_configs_algorithm=default - INFO - Saving checkpoint at t = 1000 ...\n",
      "2024-06-10 00:26:41,991 - 2024Jun10-002258_configs_algorithm=default - INFO - Saving checkpoint at t = 1000 ...\n",
      "2024-06-10 00:26:41,992 - 2024Jun10-002258_configs_algorithm=default - INFO - Checkpoint saved at t = 1000\n",
      "2024-06-10 00:26:41,992 - 2024Jun10-002258_configs_algorithm=default - INFO - Checkpoint saved at t = 1000\n",
      "2024-06-10 00:26:41,992 - 2024Jun10-002258_configs_algorithm=default - INFO - Epoch 0 completed in 0:00:00.188905. Frames seen: 1000\n",
      "2024-06-10 00:26:41,992 - 2024Jun10-002258_configs_algorithm=default - INFO - Epoch 0 completed in 0:00:00.188905. Frames seen: 1000\n",
      "2024-06-10 00:26:41,993 - 2024Jun10-002258_configs_algorithm=default - INFO - \n",
      "\n",
      "2024-06-10 00:26:41,993 - 2024Jun10-002258_configs_algorithm=default - INFO - \n",
      "\n",
      "2024-06-10 00:26:41,993 - 2024Jun10-002258_configs_algorithm=default - INFO - Ended training session after 1 epochs at t = 1000\n",
      "2024-06-10 00:26:41,993 - 2024Jun10-002258_configs_algorithm=default - INFO - Ended training session after 1 epochs at t = 1000\n",
      "2024-06-10 00:26:42,168 - 2024Jun10-002258_configs_algorithm=default - INFO - Resuming training session at: 1000 (1 epochs left)\n",
      "2024-06-10 00:26:42,168 - 2024Jun10-002258_configs_algorithm=default - INFO - Resuming training session at: 1000 (1 epochs left)\n",
      "2024-06-10 00:26:42,168 - 2024Jun10-002258_configs_algorithm=default - INFO - Starting training epoch at t = 1000\n",
      "2024-06-10 00:26:42,168 - 2024Jun10-002258_configs_algorithm=default - INFO - Starting training epoch at t = 1000\n",
      "2024-06-10 00:26:42,190 - 2024Jun10-002258_configs_algorithm=default - INFO - Episode 2 terminated at frame 49 with reward 1.0\n",
      "2024-06-10 00:26:42,190 - 2024Jun10-002258_configs_algorithm=default - INFO - Episode 2 terminated at frame 49 with reward 1.0\n",
      "2024-06-10 00:26:42,241 - 2024Jun10-002258_configs_algorithm=default - INFO - Episode 3 terminated at frame 156 with reward 1.0\n",
      "2024-06-10 00:26:42,241 - 2024Jun10-002258_configs_algorithm=default - INFO - Episode 3 terminated at frame 156 with reward 1.0\n",
      "2024-06-10 00:26:42,339 - 2024Jun10-002258_configs_algorithm=default - INFO - Episode 4 terminated at frame 449 with reward 1.0\n",
      "2024-06-10 00:26:42,339 - 2024Jun10-002258_configs_algorithm=default - INFO - Episode 4 terminated at frame 449 with reward 1.0\n",
      "2024-06-10 00:26:42,357 - 2024Jun10-002258_configs_algorithm=default - INFO - TRAINING STATS | Frames seen: 1500 | Episode: 5 | Max reward: 1.0 | Avg reward: 1.0 | Avg frames (episode): 228.66666666666666 | Avg max Q: 0.8061540085408423 | Epsilon: 0.7129000000000001 | Train epoch time: 0:00:00.188011\n",
      "2024-06-10 00:26:42,357 - 2024Jun10-002258_configs_algorithm=default - INFO - TRAINING STATS | Frames seen: 1500 | Episode: 5 | Max reward: 1.0 | Avg reward: 1.0 | Avg frames (episode): 228.66666666666666 | Avg max Q: 0.8061540085408423 | Epsilon: 0.7129000000000001 | Train epoch time: 0:00:00.188011\n",
      "2024-06-10 00:26:42,358 - 2024Jun10-002258_configs_algorithm=default - INFO - Saving checkpoint at t = 1500 ...\n",
      "2024-06-10 00:26:42,358 - 2024Jun10-002258_configs_algorithm=default - INFO - Saving checkpoint at t = 1500 ...\n",
      "2024-06-10 00:26:42,359 - 2024Jun10-002258_configs_algorithm=default - INFO - Checkpoint saved at t = 1500\n",
      "2024-06-10 00:26:42,359 - 2024Jun10-002258_configs_algorithm=default - INFO - Checkpoint saved at t = 1500\n",
      "2024-06-10 00:26:42,360 - 2024Jun10-002258_configs_algorithm=default - INFO - Epoch 0 completed in 0:00:00.192012. Frames seen: 1500\n",
      "2024-06-10 00:26:42,360 - 2024Jun10-002258_configs_algorithm=default - INFO - Epoch 0 completed in 0:00:00.192012. Frames seen: 1500\n",
      "2024-06-10 00:26:42,361 - 2024Jun10-002258_configs_algorithm=default - INFO - \n",
      "\n",
      "2024-06-10 00:26:42,361 - 2024Jun10-002258_configs_algorithm=default - INFO - \n",
      "\n",
      "2024-06-10 00:26:42,361 - 2024Jun10-002258_configs_algorithm=default - INFO - Ended training session after 1 epochs at t = 1500\n",
      "2024-06-10 00:26:42,361 - 2024Jun10-002258_configs_algorithm=default - INFO - Ended training session after 1 epochs at t = 1500\n",
      "2024-06-10 00:26:42,526 - 2024Jun10-002258_configs_algorithm=default - INFO - Resuming training session at: 1500 (1 epochs left)\n",
      "2024-06-10 00:26:42,526 - 2024Jun10-002258_configs_algorithm=default - INFO - Resuming training session at: 1500 (1 epochs left)\n",
      "2024-06-10 00:26:42,526 - 2024Jun10-002258_configs_algorithm=default - INFO - Starting training epoch at t = 1500\n",
      "2024-06-10 00:26:42,526 - 2024Jun10-002258_configs_algorithm=default - INFO - Starting training epoch at t = 1500\n",
      "2024-06-10 00:26:42,570 - 2024Jun10-002258_configs_algorithm=default - INFO - Episode 5 terminated at frame 101 with reward 1.0\n",
      "2024-06-10 00:26:42,570 - 2024Jun10-002258_configs_algorithm=default - INFO - Episode 5 terminated at frame 101 with reward 1.0\n",
      "2024-06-10 00:26:42,589 - 2024Jun10-002258_configs_algorithm=default - INFO - Episode 6 terminated at frame 144 with reward 1.0\n",
      "2024-06-10 00:26:42,589 - 2024Jun10-002258_configs_algorithm=default - INFO - Episode 6 terminated at frame 144 with reward 1.0\n",
      "2024-06-10 00:26:42,603 - 2024Jun10-002258_configs_algorithm=default - INFO - Episode 7 terminated at frame 174 with reward 1.0\n",
      "2024-06-10 00:26:42,603 - 2024Jun10-002258_configs_algorithm=default - INFO - Episode 7 terminated at frame 174 with reward 1.0\n",
      "2024-06-10 00:26:42,619 - 2024Jun10-002258_configs_algorithm=default - INFO - Episode 8 terminated at frame 219 with reward 1.0\n",
      "2024-06-10 00:26:42,619 - 2024Jun10-002258_configs_algorithm=default - INFO - Episode 8 terminated at frame 219 with reward 1.0\n",
      "2024-06-10 00:26:42,701 - 2024Jun10-002258_configs_algorithm=default - INFO - Episode 9 terminated at frame 458 with reward 1.0\n",
      "2024-06-10 00:26:42,701 - 2024Jun10-002258_configs_algorithm=default - INFO - Episode 9 terminated at frame 458 with reward 1.0\n",
      "2024-06-10 00:26:42,717 - 2024Jun10-002258_configs_algorithm=default - INFO - TRAINING STATS | Frames seen: 2000 | Episode: 10 | Max reward: 1.0 | Avg reward: 1.0 | Avg frames (episode): 101.8 | Avg max Q: 0.6306714232553515 | Epsilon: 0.6139 | Train epoch time: 0:00:00.189526\n",
      "2024-06-10 00:26:42,717 - 2024Jun10-002258_configs_algorithm=default - INFO - TRAINING STATS | Frames seen: 2000 | Episode: 10 | Max reward: 1.0 | Avg reward: 1.0 | Avg frames (episode): 101.8 | Avg max Q: 0.6306714232553515 | Epsilon: 0.6139 | Train epoch time: 0:00:00.189526\n",
      "2024-06-10 00:26:42,718 - 2024Jun10-002258_configs_algorithm=default - INFO - Saving checkpoint at t = 2000 ...\n",
      "2024-06-10 00:26:42,718 - 2024Jun10-002258_configs_algorithm=default - INFO - Saving checkpoint at t = 2000 ...\n",
      "2024-06-10 00:26:42,719 - 2024Jun10-002258_configs_algorithm=default - INFO - Checkpoint saved at t = 2000\n",
      "2024-06-10 00:26:42,719 - 2024Jun10-002258_configs_algorithm=default - INFO - Checkpoint saved at t = 2000\n",
      "2024-06-10 00:26:42,720 - 2024Jun10-002258_configs_algorithm=default - INFO - Epoch 0 completed in 0:00:00.194072. Frames seen: 2000\n",
      "2024-06-10 00:26:42,720 - 2024Jun10-002258_configs_algorithm=default - INFO - Epoch 0 completed in 0:00:00.194072. Frames seen: 2000\n",
      "2024-06-10 00:26:42,721 - 2024Jun10-002258_configs_algorithm=default - INFO - \n",
      "\n",
      "2024-06-10 00:26:42,721 - 2024Jun10-002258_configs_algorithm=default - INFO - \n",
      "\n",
      "2024-06-10 00:26:42,721 - 2024Jun10-002258_configs_algorithm=default - INFO - Ended training session after 1 epochs at t = 2000\n",
      "2024-06-10 00:26:42,721 - 2024Jun10-002258_configs_algorithm=default - INFO - Ended training session after 1 epochs at t = 2000\n",
      "2024-06-10 00:26:42,890 - 2024Jun10-002258_configs_algorithm=default - INFO - Resuming training session at: 2000 (1 epochs left)\n",
      "2024-06-10 00:26:42,890 - 2024Jun10-002258_configs_algorithm=default - INFO - Resuming training session at: 2000 (1 epochs left)\n",
      "2024-06-10 00:26:42,890 - 2024Jun10-002258_configs_algorithm=default - INFO - Starting training epoch at t = 2000\n",
      "2024-06-10 00:26:42,890 - 2024Jun10-002258_configs_algorithm=default - INFO - Starting training epoch at t = 2000\n",
      "2024-06-10 00:26:42,908 - 2024Jun10-002258_configs_algorithm=default - INFO - Episode 10 terminated at frame 48 with reward 1.0\n",
      "2024-06-10 00:26:42,908 - 2024Jun10-002258_configs_algorithm=default - INFO - Episode 10 terminated at frame 48 with reward 1.0\n",
      "2024-06-10 00:26:43,031 - 2024Jun10-002258_configs_algorithm=default - INFO - Episode 11 terminated at frame 411 with reward 1.0\n",
      "2024-06-10 00:26:43,031 - 2024Jun10-002258_configs_algorithm=default - INFO - Episode 11 terminated at frame 411 with reward 1.0\n",
      "2024-06-10 00:26:43,062 - 2024Jun10-002258_configs_algorithm=default - INFO - TRAINING STATS | Frames seen: 2500 | Episode: 12 | Max reward: 1.0 | Avg reward: 1.0 | Avg frames (episode): 226.5 | Avg max Q: 0.43868856287972874 | Epsilon: 0.5149 | Train epoch time: 0:00:00.170228\n",
      "2024-06-10 00:26:43,062 - 2024Jun10-002258_configs_algorithm=default - INFO - TRAINING STATS | Frames seen: 2500 | Episode: 12 | Max reward: 1.0 | Avg reward: 1.0 | Avg frames (episode): 226.5 | Avg max Q: 0.43868856287972874 | Epsilon: 0.5149 | Train epoch time: 0:00:00.170228\n",
      "2024-06-10 00:26:43,063 - 2024Jun10-002258_configs_algorithm=default - INFO - Saving checkpoint at t = 2500 ...\n",
      "2024-06-10 00:26:43,063 - 2024Jun10-002258_configs_algorithm=default - INFO - Saving checkpoint at t = 2500 ...\n",
      "2024-06-10 00:26:43,064 - 2024Jun10-002258_configs_algorithm=default - INFO - Checkpoint saved at t = 2500\n",
      "2024-06-10 00:26:43,064 - 2024Jun10-002258_configs_algorithm=default - INFO - Checkpoint saved at t = 2500\n",
      "2024-06-10 00:26:43,065 - 2024Jun10-002258_configs_algorithm=default - INFO - Epoch 0 completed in 0:00:00.174228. Frames seen: 2500\n",
      "2024-06-10 00:26:43,065 - 2024Jun10-002258_configs_algorithm=default - INFO - Epoch 0 completed in 0:00:00.174228. Frames seen: 2500\n",
      "2024-06-10 00:26:43,065 - 2024Jun10-002258_configs_algorithm=default - INFO - \n",
      "\n",
      "2024-06-10 00:26:43,065 - 2024Jun10-002258_configs_algorithm=default - INFO - \n",
      "\n",
      "2024-06-10 00:26:43,066 - 2024Jun10-002258_configs_algorithm=default - INFO - Ended training session after 1 epochs at t = 2500\n",
      "2024-06-10 00:26:43,066 - 2024Jun10-002258_configs_algorithm=default - INFO - Ended training session after 1 epochs at t = 2500\n",
      "2024-06-10 00:26:43,228 - 2024Jun10-002258_configs_algorithm=default - INFO - Resuming training session at: 2500 (1 epochs left)\n",
      "2024-06-10 00:26:43,228 - 2024Jun10-002258_configs_algorithm=default - INFO - Resuming training session at: 2500 (1 epochs left)\n",
      "2024-06-10 00:26:43,229 - 2024Jun10-002258_configs_algorithm=default - INFO - Starting training epoch at t = 2500\n",
      "2024-06-10 00:26:43,229 - 2024Jun10-002258_configs_algorithm=default - INFO - Starting training epoch at t = 2500\n",
      "2024-06-10 00:26:43,414 - 2024Jun10-002258_configs_algorithm=default - INFO - TRAINING STATS | Frames seen: 3000 | Episode: 12 | Max reward: None | Avg reward: None | Avg frames (episode): None | Avg max Q: None | Epsilon: 0.41590000000000005 | Train epoch time: 0:00:00.184038\n",
      "2024-06-10 00:26:43,414 - 2024Jun10-002258_configs_algorithm=default - INFO - TRAINING STATS | Frames seen: 3000 | Episode: 12 | Max reward: None | Avg reward: None | Avg frames (episode): None | Avg max Q: None | Epsilon: 0.41590000000000005 | Train epoch time: 0:00:00.184038\n",
      "2024-06-10 00:26:43,414 - 2024Jun10-002258_configs_algorithm=default - INFO - Saving checkpoint at t = 3000 ...\n",
      "2024-06-10 00:26:43,414 - 2024Jun10-002258_configs_algorithm=default - INFO - Saving checkpoint at t = 3000 ...\n",
      "2024-06-10 00:26:43,416 - 2024Jun10-002258_configs_algorithm=default - INFO - Checkpoint saved at t = 3000\n",
      "2024-06-10 00:26:43,416 - 2024Jun10-002258_configs_algorithm=default - INFO - Checkpoint saved at t = 3000\n",
      "2024-06-10 00:26:43,416 - 2024Jun10-002258_configs_algorithm=default - INFO - Epoch 0 completed in 0:00:00.187038. Frames seen: 3000\n",
      "2024-06-10 00:26:43,416 - 2024Jun10-002258_configs_algorithm=default - INFO - Epoch 0 completed in 0:00:00.187038. Frames seen: 3000\n",
      "2024-06-10 00:26:43,417 - 2024Jun10-002258_configs_algorithm=default - INFO - \n",
      "\n",
      "2024-06-10 00:26:43,417 - 2024Jun10-002258_configs_algorithm=default - INFO - \n",
      "\n",
      "2024-06-10 00:26:43,418 - 2024Jun10-002258_configs_algorithm=default - INFO - Ended training session after 1 epochs at t = 3000\n",
      "2024-06-10 00:26:43,418 - 2024Jun10-002258_configs_algorithm=default - INFO - Ended training session after 1 epochs at t = 3000\n",
      "2024-06-10 00:26:43,586 - 2024Jun10-002258_configs_algorithm=default - INFO - Resuming training session at: 3000 (1 epochs left)\n",
      "2024-06-10 00:26:43,586 - 2024Jun10-002258_configs_algorithm=default - INFO - Resuming training session at: 3000 (1 epochs left)\n",
      "2024-06-10 00:26:43,587 - 2024Jun10-002258_configs_algorithm=default - INFO - Starting training epoch at t = 3000\n",
      "2024-06-10 00:26:43,587 - 2024Jun10-002258_configs_algorithm=default - INFO - Starting training epoch at t = 3000\n",
      "2024-06-10 00:26:43,737 - 2024Jun10-002258_configs_algorithm=default - INFO - Episode 12 terminated at frame 385 with reward 1.0\n",
      "2024-06-10 00:26:43,737 - 2024Jun10-002258_configs_algorithm=default - INFO - Episode 12 terminated at frame 385 with reward 1.0\n",
      "2024-06-10 00:26:43,785 - 2024Jun10-002258_configs_algorithm=default - INFO - TRAINING STATS | Frames seen: 3500 | Episode: 13 | Max reward: 1.0 | Avg reward: 1.0 | Avg frames (episode): 974.0 | Avg max Q: 0.3312507224456892 | Epsilon: 0.31690000000000007 | Train epoch time: 0:00:00.197415\n",
      "2024-06-10 00:26:43,785 - 2024Jun10-002258_configs_algorithm=default - INFO - TRAINING STATS | Frames seen: 3500 | Episode: 13 | Max reward: 1.0 | Avg reward: 1.0 | Avg frames (episode): 974.0 | Avg max Q: 0.3312507224456892 | Epsilon: 0.31690000000000007 | Train epoch time: 0:00:00.197415\n",
      "2024-06-10 00:26:43,786 - 2024Jun10-002258_configs_algorithm=default - INFO - Saving checkpoint at t = 3500 ...\n",
      "2024-06-10 00:26:43,786 - 2024Jun10-002258_configs_algorithm=default - INFO - Saving checkpoint at t = 3500 ...\n",
      "2024-06-10 00:26:43,787 - 2024Jun10-002258_configs_algorithm=default - INFO - Checkpoint saved at t = 3500\n",
      "2024-06-10 00:26:43,787 - 2024Jun10-002258_configs_algorithm=default - INFO - Checkpoint saved at t = 3500\n",
      "2024-06-10 00:26:43,788 - 2024Jun10-002258_configs_algorithm=default - INFO - Epoch 0 completed in 0:00:00.201416. Frames seen: 3500\n",
      "2024-06-10 00:26:43,788 - 2024Jun10-002258_configs_algorithm=default - INFO - Epoch 0 completed in 0:00:00.201416. Frames seen: 3500\n",
      "2024-06-10 00:26:43,788 - 2024Jun10-002258_configs_algorithm=default - INFO - \n",
      "\n",
      "2024-06-10 00:26:43,788 - 2024Jun10-002258_configs_algorithm=default - INFO - \n",
      "\n",
      "2024-06-10 00:26:43,789 - 2024Jun10-002258_configs_algorithm=default - INFO - Ended training session after 1 epochs at t = 3500\n",
      "2024-06-10 00:26:43,789 - 2024Jun10-002258_configs_algorithm=default - INFO - Ended training session after 1 epochs at t = 3500\n",
      "2024-06-10 00:26:43,954 - 2024Jun10-002258_configs_algorithm=default - INFO - Resuming training session at: 3500 (1 epochs left)\n",
      "2024-06-10 00:26:43,954 - 2024Jun10-002258_configs_algorithm=default - INFO - Resuming training session at: 3500 (1 epochs left)\n",
      "2024-06-10 00:26:43,954 - 2024Jun10-002258_configs_algorithm=default - INFO - Starting training epoch at t = 3500\n",
      "2024-06-10 00:26:43,954 - 2024Jun10-002258_configs_algorithm=default - INFO - Starting training epoch at t = 3500\n",
      "2024-06-10 00:26:44,018 - 2024Jun10-002258_configs_algorithm=default - INFO - Episode 13 terminated at frame 143 with reward 1.0\n",
      "2024-06-10 00:26:44,018 - 2024Jun10-002258_configs_algorithm=default - INFO - Episode 13 terminated at frame 143 with reward 1.0\n",
      "2024-06-10 00:26:44,029 - 2024Jun10-002258_configs_algorithm=default - INFO - Episode 14 terminated at frame 166 with reward 1.0\n",
      "2024-06-10 00:26:44,029 - 2024Jun10-002258_configs_algorithm=default - INFO - Episode 14 terminated at frame 166 with reward 1.0\n",
      "2024-06-10 00:26:44,144 - 2024Jun10-002258_configs_algorithm=default - INFO - Episode 15 terminated at frame 440 with reward 1.0\n",
      "2024-06-10 00:26:44,144 - 2024Jun10-002258_configs_algorithm=default - INFO - Episode 15 terminated at frame 440 with reward 1.0\n",
      "2024-06-10 00:26:44,172 - 2024Jun10-002258_configs_algorithm=default - INFO - TRAINING STATS | Frames seen: 4000 | Episode: 16 | Max reward: 1.0 | Avg reward: 1.0 | Avg frames (episode): 185.0 | Avg max Q: 0.25065007450143295 | Epsilon: 0.21789999999999998 | Train epoch time: 0:00:00.216015\n",
      "2024-06-10 00:26:44,172 - 2024Jun10-002258_configs_algorithm=default - INFO - TRAINING STATS | Frames seen: 4000 | Episode: 16 | Max reward: 1.0 | Avg reward: 1.0 | Avg frames (episode): 185.0 | Avg max Q: 0.25065007450143295 | Epsilon: 0.21789999999999998 | Train epoch time: 0:00:00.216015\n",
      "2024-06-10 00:26:44,173 - 2024Jun10-002258_configs_algorithm=default - INFO - Saving checkpoint at t = 4000 ...\n",
      "2024-06-10 00:26:44,173 - 2024Jun10-002258_configs_algorithm=default - INFO - Saving checkpoint at t = 4000 ...\n",
      "2024-06-10 00:26:44,174 - 2024Jun10-002258_configs_algorithm=default - INFO - Checkpoint saved at t = 4000\n",
      "2024-06-10 00:26:44,174 - 2024Jun10-002258_configs_algorithm=default - INFO - Checkpoint saved at t = 4000\n",
      "2024-06-10 00:26:44,175 - 2024Jun10-002258_configs_algorithm=default - INFO - Epoch 0 completed in 0:00:00.221015. Frames seen: 4000\n",
      "2024-06-10 00:26:44,175 - 2024Jun10-002258_configs_algorithm=default - INFO - Epoch 0 completed in 0:00:00.221015. Frames seen: 4000\n",
      "2024-06-10 00:26:44,176 - 2024Jun10-002258_configs_algorithm=default - INFO - \n",
      "\n",
      "2024-06-10 00:26:44,176 - 2024Jun10-002258_configs_algorithm=default - INFO - \n",
      "\n",
      "2024-06-10 00:26:44,177 - 2024Jun10-002258_configs_algorithm=default - INFO - Ended training session after 1 epochs at t = 4000\n",
      "2024-06-10 00:26:44,177 - 2024Jun10-002258_configs_algorithm=default - INFO - Ended training session after 1 epochs at t = 4000\n",
      "2024-06-10 00:26:44,341 - 2024Jun10-002258_configs_algorithm=default - INFO - Resuming training session at: 4000 (1 epochs left)\n",
      "2024-06-10 00:26:44,341 - 2024Jun10-002258_configs_algorithm=default - INFO - Resuming training session at: 4000 (1 epochs left)\n",
      "2024-06-10 00:26:44,342 - 2024Jun10-002258_configs_algorithm=default - INFO - Starting training epoch at t = 4000\n",
      "2024-06-10 00:26:44,342 - 2024Jun10-002258_configs_algorithm=default - INFO - Starting training epoch at t = 4000\n",
      "2024-06-10 00:26:44,452 - 2024Jun10-002258_configs_algorithm=default - INFO - Episode 16 terminated at frame 233 with reward 1.0\n",
      "2024-06-10 00:26:44,452 - 2024Jun10-002258_configs_algorithm=default - INFO - Episode 16 terminated at frame 233 with reward 1.0\n",
      "2024-06-10 00:26:44,569 - 2024Jun10-002258_configs_algorithm=default - INFO - TRAINING STATS | Frames seen: 4500 | Episode: 17 | Max reward: 1.0 | Avg reward: 1.0 | Avg frames (episode): 293.0 | Avg max Q: 0.2196274161069102 | Epsilon: 0.1189 | Train epoch time: 0:00:00.226586\n",
      "2024-06-10 00:26:44,569 - 2024Jun10-002258_configs_algorithm=default - INFO - TRAINING STATS | Frames seen: 4500 | Episode: 17 | Max reward: 1.0 | Avg reward: 1.0 | Avg frames (episode): 293.0 | Avg max Q: 0.2196274161069102 | Epsilon: 0.1189 | Train epoch time: 0:00:00.226586\n",
      "2024-06-10 00:26:44,569 - 2024Jun10-002258_configs_algorithm=default - INFO - Saving checkpoint at t = 4500 ...\n",
      "2024-06-10 00:26:44,569 - 2024Jun10-002258_configs_algorithm=default - INFO - Saving checkpoint at t = 4500 ...\n",
      "2024-06-10 00:26:44,571 - 2024Jun10-002258_configs_algorithm=default - INFO - Checkpoint saved at t = 4500\n",
      "2024-06-10 00:26:44,571 - 2024Jun10-002258_configs_algorithm=default - INFO - Checkpoint saved at t = 4500\n",
      "2024-06-10 00:26:44,572 - 2024Jun10-002258_configs_algorithm=default - INFO - Epoch 0 completed in 0:00:00.230586. Frames seen: 4500\n",
      "2024-06-10 00:26:44,572 - 2024Jun10-002258_configs_algorithm=default - INFO - Epoch 0 completed in 0:00:00.230586. Frames seen: 4500\n",
      "2024-06-10 00:26:44,572 - 2024Jun10-002258_configs_algorithm=default - INFO - \n",
      "\n",
      "2024-06-10 00:26:44,572 - 2024Jun10-002258_configs_algorithm=default - INFO - \n",
      "\n",
      "2024-06-10 00:26:44,573 - 2024Jun10-002258_configs_algorithm=default - INFO - Ended training session after 1 epochs at t = 4500\n",
      "2024-06-10 00:26:44,573 - 2024Jun10-002258_configs_algorithm=default - INFO - Ended training session after 1 epochs at t = 4500\n",
      "2024-06-10 00:26:44,741 - 2024Jun10-002258_configs_algorithm=default - INFO - Resuming training session at: 4500 (1 epochs left)\n",
      "2024-06-10 00:26:44,741 - 2024Jun10-002258_configs_algorithm=default - INFO - Resuming training session at: 4500 (1 epochs left)\n",
      "2024-06-10 00:26:44,741 - 2024Jun10-002258_configs_algorithm=default - INFO - Starting training epoch at t = 4500\n",
      "2024-06-10 00:26:44,741 - 2024Jun10-002258_configs_algorithm=default - INFO - Starting training epoch at t = 4500\n",
      "2024-06-10 00:26:44,963 - 2024Jun10-002258_configs_algorithm=default - INFO - TRAINING STATS | Frames seen: 5000 | Episode: 17 | Max reward: None | Avg reward: None | Avg frames (episode): None | Avg max Q: None | Epsilon: 0.01990000000000003 | Train epoch time: 0:00:00.221059\n",
      "2024-06-10 00:26:44,963 - 2024Jun10-002258_configs_algorithm=default - INFO - TRAINING STATS | Frames seen: 5000 | Episode: 17 | Max reward: None | Avg reward: None | Avg frames (episode): None | Avg max Q: None | Epsilon: 0.01990000000000003 | Train epoch time: 0:00:00.221059\n",
      "2024-06-10 00:26:44,964 - 2024Jun10-002258_configs_algorithm=default - INFO - Saving checkpoint at t = 5000 ...\n",
      "2024-06-10 00:26:44,964 - 2024Jun10-002258_configs_algorithm=default - INFO - Saving checkpoint at t = 5000 ...\n",
      "2024-06-10 00:26:44,965 - 2024Jun10-002258_configs_algorithm=default - INFO - Checkpoint saved at t = 5000\n",
      "2024-06-10 00:26:44,965 - 2024Jun10-002258_configs_algorithm=default - INFO - Checkpoint saved at t = 5000\n",
      "2024-06-10 00:26:44,966 - 2024Jun10-002258_configs_algorithm=default - INFO - Epoch 0 completed in 0:00:00.225059. Frames seen: 5000\n",
      "2024-06-10 00:26:44,966 - 2024Jun10-002258_configs_algorithm=default - INFO - Epoch 0 completed in 0:00:00.225059. Frames seen: 5000\n",
      "2024-06-10 00:26:44,966 - 2024Jun10-002258_configs_algorithm=default - INFO - \n",
      "\n",
      "2024-06-10 00:26:44,966 - 2024Jun10-002258_configs_algorithm=default - INFO - \n",
      "\n",
      "2024-06-10 00:26:44,967 - 2024Jun10-002258_configs_algorithm=default - INFO - Ended training session after 1 epochs at t = 5000\n",
      "2024-06-10 00:26:44,967 - 2024Jun10-002258_configs_algorithm=default - INFO - Ended training session after 1 epochs at t = 5000\n",
      "2024-06-10 00:26:45,127 - 2024Jun10-002258_configs_algorithm=default - INFO - Resuming training session at: 5000 (1 epochs left)\n",
      "2024-06-10 00:26:45,127 - 2024Jun10-002258_configs_algorithm=default - INFO - Resuming training session at: 5000 (1 epochs left)\n",
      "2024-06-10 00:26:45,127 - 2024Jun10-002258_configs_algorithm=default - INFO - Starting training epoch at t = 5000\n",
      "2024-06-10 00:26:45,127 - 2024Jun10-002258_configs_algorithm=default - INFO - Starting training epoch at t = 5000\n",
      "2024-06-10 00:26:45,354 - 2024Jun10-002258_configs_algorithm=default - INFO - TRAINING STATS | Frames seen: 5500 | Episode: 17 | Max reward: None | Avg reward: None | Avg frames (episode): None | Avg max Q: None | Epsilon: 0.01 | Train epoch time: 0:00:00.225629\n",
      "2024-06-10 00:26:45,354 - 2024Jun10-002258_configs_algorithm=default - INFO - TRAINING STATS | Frames seen: 5500 | Episode: 17 | Max reward: None | Avg reward: None | Avg frames (episode): None | Avg max Q: None | Epsilon: 0.01 | Train epoch time: 0:00:00.225629\n",
      "2024-06-10 00:26:45,355 - 2024Jun10-002258_configs_algorithm=default - INFO - Saving checkpoint at t = 5500 ...\n",
      "2024-06-10 00:26:45,355 - 2024Jun10-002258_configs_algorithm=default - INFO - Saving checkpoint at t = 5500 ...\n",
      "2024-06-10 00:26:45,356 - 2024Jun10-002258_configs_algorithm=default - INFO - Checkpoint saved at t = 5500\n",
      "2024-06-10 00:26:45,356 - 2024Jun10-002258_configs_algorithm=default - INFO - Checkpoint saved at t = 5500\n",
      "2024-06-10 00:26:45,357 - 2024Jun10-002258_configs_algorithm=default - INFO - Epoch 0 completed in 0:00:00.229632. Frames seen: 5500\n",
      "2024-06-10 00:26:45,357 - 2024Jun10-002258_configs_algorithm=default - INFO - Epoch 0 completed in 0:00:00.229632. Frames seen: 5500\n",
      "2024-06-10 00:26:45,357 - 2024Jun10-002258_configs_algorithm=default - INFO - \n",
      "\n",
      "2024-06-10 00:26:45,357 - 2024Jun10-002258_configs_algorithm=default - INFO - \n",
      "\n",
      "2024-06-10 00:26:45,358 - 2024Jun10-002258_configs_algorithm=default - INFO - Ended training session after 1 epochs at t = 5500\n",
      "2024-06-10 00:26:45,358 - 2024Jun10-002258_configs_algorithm=default - INFO - Ended training session after 1 epochs at t = 5500\n",
      "2024-06-10 00:26:45,514 - 2024Jun10-002258_configs_algorithm=default - INFO - Resuming training session at: 5500 (1 epochs left)\n",
      "2024-06-10 00:26:45,514 - 2024Jun10-002258_configs_algorithm=default - INFO - Resuming training session at: 5500 (1 epochs left)\n",
      "2024-06-10 00:26:45,515 - 2024Jun10-002258_configs_algorithm=default - INFO - Starting training epoch at t = 5500\n",
      "2024-06-10 00:26:45,515 - 2024Jun10-002258_configs_algorithm=default - INFO - Starting training epoch at t = 5500\n",
      "2024-06-10 00:26:45,721 - 2024Jun10-002258_configs_algorithm=default - INFO - TRAINING STATS | Frames seen: 6000 | Episode: 17 | Max reward: None | Avg reward: None | Avg frames (episode): None | Avg max Q: None | Epsilon: 0.01 | Train epoch time: 0:00:00.204787\n",
      "2024-06-10 00:26:45,721 - 2024Jun10-002258_configs_algorithm=default - INFO - TRAINING STATS | Frames seen: 6000 | Episode: 17 | Max reward: None | Avg reward: None | Avg frames (episode): None | Avg max Q: None | Epsilon: 0.01 | Train epoch time: 0:00:00.204787\n",
      "2024-06-10 00:26:45,722 - 2024Jun10-002258_configs_algorithm=default - INFO - Saving checkpoint at t = 6000 ...\n",
      "2024-06-10 00:26:45,722 - 2024Jun10-002258_configs_algorithm=default - INFO - Saving checkpoint at t = 6000 ...\n",
      "2024-06-10 00:26:45,723 - 2024Jun10-002258_configs_algorithm=default - INFO - Checkpoint saved at t = 6000\n",
      "2024-06-10 00:26:45,723 - 2024Jun10-002258_configs_algorithm=default - INFO - Checkpoint saved at t = 6000\n",
      "2024-06-10 00:26:45,724 - 2024Jun10-002258_configs_algorithm=default - INFO - Epoch 0 completed in 0:00:00.208788. Frames seen: 6000\n",
      "2024-06-10 00:26:45,724 - 2024Jun10-002258_configs_algorithm=default - INFO - Epoch 0 completed in 0:00:00.208788. Frames seen: 6000\n",
      "2024-06-10 00:26:45,725 - 2024Jun10-002258_configs_algorithm=default - INFO - \n",
      "\n",
      "2024-06-10 00:26:45,725 - 2024Jun10-002258_configs_algorithm=default - INFO - \n",
      "\n",
      "2024-06-10 00:26:45,725 - 2024Jun10-002258_configs_algorithm=default - INFO - Ended training session after 1 epochs at t = 6000\n",
      "2024-06-10 00:26:45,725 - 2024Jun10-002258_configs_algorithm=default - INFO - Ended training session after 1 epochs at t = 6000\n",
      "2024-06-10 00:26:45,896 - 2024Jun10-002258_configs_algorithm=default - INFO - Resuming training session at: 6000 (1 epochs left)\n",
      "2024-06-10 00:26:45,896 - 2024Jun10-002258_configs_algorithm=default - INFO - Resuming training session at: 6000 (1 epochs left)\n",
      "2024-06-10 00:26:45,897 - 2024Jun10-002258_configs_algorithm=default - INFO - Starting training epoch at t = 6000\n",
      "2024-06-10 00:26:45,897 - 2024Jun10-002258_configs_algorithm=default - INFO - Starting training epoch at t = 6000\n",
      "2024-06-10 00:26:46,109 - 2024Jun10-002258_configs_algorithm=default - INFO - TRAINING STATS | Frames seen: 6500 | Episode: 17 | Max reward: None | Avg reward: None | Avg frames (episode): None | Avg max Q: None | Epsilon: 0.01 | Train epoch time: 0:00:00.211447\n",
      "2024-06-10 00:26:46,109 - 2024Jun10-002258_configs_algorithm=default - INFO - TRAINING STATS | Frames seen: 6500 | Episode: 17 | Max reward: None | Avg reward: None | Avg frames (episode): None | Avg max Q: None | Epsilon: 0.01 | Train epoch time: 0:00:00.211447\n",
      "2024-06-10 00:26:46,110 - 2024Jun10-002258_configs_algorithm=default - INFO - Saving checkpoint at t = 6500 ...\n",
      "2024-06-10 00:26:46,110 - 2024Jun10-002258_configs_algorithm=default - INFO - Saving checkpoint at t = 6500 ...\n",
      "2024-06-10 00:26:46,111 - 2024Jun10-002258_configs_algorithm=default - INFO - Checkpoint saved at t = 6500\n",
      "2024-06-10 00:26:46,111 - 2024Jun10-002258_configs_algorithm=default - INFO - Checkpoint saved at t = 6500\n",
      "2024-06-10 00:26:46,112 - 2024Jun10-002258_configs_algorithm=default - INFO - Epoch 0 completed in 0:00:00.215102. Frames seen: 6500\n",
      "2024-06-10 00:26:46,112 - 2024Jun10-002258_configs_algorithm=default - INFO - Epoch 0 completed in 0:00:00.215102. Frames seen: 6500\n",
      "2024-06-10 00:26:46,112 - 2024Jun10-002258_configs_algorithm=default - INFO - \n",
      "\n",
      "2024-06-10 00:26:46,112 - 2024Jun10-002258_configs_algorithm=default - INFO - \n",
      "\n",
      "2024-06-10 00:26:46,113 - 2024Jun10-002258_configs_algorithm=default - INFO - Ended training session after 1 epochs at t = 6500\n",
      "2024-06-10 00:26:46,113 - 2024Jun10-002258_configs_algorithm=default - INFO - Ended training session after 1 epochs at t = 6500\n",
      "2024-06-10 00:26:46,287 - 2024Jun10-002258_configs_algorithm=default - INFO - Resuming training session at: 6500 (1 epochs left)\n",
      "2024-06-10 00:26:46,287 - 2024Jun10-002258_configs_algorithm=default - INFO - Resuming training session at: 6500 (1 epochs left)\n",
      "2024-06-10 00:26:46,288 - 2024Jun10-002258_configs_algorithm=default - INFO - Starting training epoch at t = 6500\n",
      "2024-06-10 00:26:46,288 - 2024Jun10-002258_configs_algorithm=default - INFO - Starting training epoch at t = 6500\n",
      "2024-06-10 00:26:46,342 - 2024Jun10-002258_configs_algorithm=default - INFO - Episode 17 terminated at frame 110 with reward 1.0\n",
      "2024-06-10 00:26:46,342 - 2024Jun10-002258_configs_algorithm=default - INFO - Episode 17 terminated at frame 110 with reward 1.0\n",
      "2024-06-10 00:26:46,519 - 2024Jun10-002258_configs_algorithm=default - INFO - TRAINING STATS | Frames seen: 7000 | Episode: 18 | Max reward: 1.0 | Avg reward: 1.0 | Avg frames (episode): 2377.0 | Avg max Q: 0.15208882125355971 | Epsilon: 0.01 | Train epoch time: 0:00:00.228590\n",
      "2024-06-10 00:26:46,519 - 2024Jun10-002258_configs_algorithm=default - INFO - TRAINING STATS | Frames seen: 7000 | Episode: 18 | Max reward: 1.0 | Avg reward: 1.0 | Avg frames (episode): 2377.0 | Avg max Q: 0.15208882125355971 | Epsilon: 0.01 | Train epoch time: 0:00:00.228590\n",
      "2024-06-10 00:26:46,520 - 2024Jun10-002258_configs_algorithm=default - INFO - Saving checkpoint at t = 7000 ...\n",
      "2024-06-10 00:26:46,520 - 2024Jun10-002258_configs_algorithm=default - INFO - Saving checkpoint at t = 7000 ...\n",
      "2024-06-10 00:26:46,521 - 2024Jun10-002258_configs_algorithm=default - INFO - Checkpoint saved at t = 7000\n",
      "2024-06-10 00:26:46,521 - 2024Jun10-002258_configs_algorithm=default - INFO - Checkpoint saved at t = 7000\n",
      "2024-06-10 00:26:46,522 - 2024Jun10-002258_configs_algorithm=default - INFO - Epoch 0 completed in 0:00:00.233589. Frames seen: 7000\n",
      "2024-06-10 00:26:46,522 - 2024Jun10-002258_configs_algorithm=default - INFO - Epoch 0 completed in 0:00:00.233589. Frames seen: 7000\n",
      "2024-06-10 00:26:46,523 - 2024Jun10-002258_configs_algorithm=default - INFO - \n",
      "\n",
      "2024-06-10 00:26:46,523 - 2024Jun10-002258_configs_algorithm=default - INFO - \n",
      "\n",
      "2024-06-10 00:26:46,523 - 2024Jun10-002258_configs_algorithm=default - INFO - Ended training session after 1 epochs at t = 7000\n",
      "2024-06-10 00:26:46,523 - 2024Jun10-002258_configs_algorithm=default - INFO - Ended training session after 1 epochs at t = 7000\n",
      "2024-06-10 00:26:46,686 - 2024Jun10-002258_configs_algorithm=default - INFO - Resuming training session at: 7000 (1 epochs left)\n",
      "2024-06-10 00:26:46,686 - 2024Jun10-002258_configs_algorithm=default - INFO - Resuming training session at: 7000 (1 epochs left)\n",
      "2024-06-10 00:26:46,686 - 2024Jun10-002258_configs_algorithm=default - INFO - Starting training epoch at t = 7000\n",
      "2024-06-10 00:26:46,686 - 2024Jun10-002258_configs_algorithm=default - INFO - Starting training epoch at t = 7000\n",
      "2024-06-10 00:26:46,908 - 2024Jun10-002258_configs_algorithm=default - INFO - TRAINING STATS | Frames seen: 7500 | Episode: 18 | Max reward: None | Avg reward: None | Avg frames (episode): None | Avg max Q: None | Epsilon: 0.01 | Train epoch time: 0:00:00.221222\n",
      "2024-06-10 00:26:46,908 - 2024Jun10-002258_configs_algorithm=default - INFO - TRAINING STATS | Frames seen: 7500 | Episode: 18 | Max reward: None | Avg reward: None | Avg frames (episode): None | Avg max Q: None | Epsilon: 0.01 | Train epoch time: 0:00:00.221222\n",
      "2024-06-10 00:26:46,909 - 2024Jun10-002258_configs_algorithm=default - INFO - Saving checkpoint at t = 7500 ...\n",
      "2024-06-10 00:26:46,909 - 2024Jun10-002258_configs_algorithm=default - INFO - Saving checkpoint at t = 7500 ...\n",
      "2024-06-10 00:26:46,910 - 2024Jun10-002258_configs_algorithm=default - INFO - Checkpoint saved at t = 7500\n",
      "2024-06-10 00:26:46,910 - 2024Jun10-002258_configs_algorithm=default - INFO - Checkpoint saved at t = 7500\n",
      "2024-06-10 00:26:46,911 - 2024Jun10-002258_configs_algorithm=default - INFO - Epoch 0 completed in 0:00:00.225353. Frames seen: 7500\n",
      "2024-06-10 00:26:46,911 - 2024Jun10-002258_configs_algorithm=default - INFO - Epoch 0 completed in 0:00:00.225353. Frames seen: 7500\n",
      "2024-06-10 00:26:46,912 - 2024Jun10-002258_configs_algorithm=default - INFO - \n",
      "\n",
      "2024-06-10 00:26:46,912 - 2024Jun10-002258_configs_algorithm=default - INFO - \n",
      "\n",
      "2024-06-10 00:26:46,912 - 2024Jun10-002258_configs_algorithm=default - INFO - Ended training session after 1 epochs at t = 7500\n",
      "2024-06-10 00:26:46,912 - 2024Jun10-002258_configs_algorithm=default - INFO - Ended training session after 1 epochs at t = 7500\n",
      "2024-06-10 00:26:47,059 - 2024Jun10-002258_configs_algorithm=default - INFO - Resuming training session at: 7500 (1 epochs left)\n",
      "2024-06-10 00:26:47,059 - 2024Jun10-002258_configs_algorithm=default - INFO - Resuming training session at: 7500 (1 epochs left)\n",
      "2024-06-10 00:26:47,060 - 2024Jun10-002258_configs_algorithm=default - INFO - Starting training epoch at t = 7500\n",
      "2024-06-10 00:26:47,060 - 2024Jun10-002258_configs_algorithm=default - INFO - Starting training epoch at t = 7500\n",
      "2024-06-10 00:26:47,276 - 2024Jun10-002258_configs_algorithm=default - INFO - TRAINING STATS | Frames seen: 8000 | Episode: 18 | Max reward: None | Avg reward: None | Avg frames (episode): None | Avg max Q: None | Epsilon: 0.01 | Train epoch time: 0:00:00.215044\n",
      "2024-06-10 00:26:47,276 - 2024Jun10-002258_configs_algorithm=default - INFO - TRAINING STATS | Frames seen: 8000 | Episode: 18 | Max reward: None | Avg reward: None | Avg frames (episode): None | Avg max Q: None | Epsilon: 0.01 | Train epoch time: 0:00:00.215044\n",
      "2024-06-10 00:26:47,276 - 2024Jun10-002258_configs_algorithm=default - INFO - Saving checkpoint at t = 8000 ...\n",
      "2024-06-10 00:26:47,276 - 2024Jun10-002258_configs_algorithm=default - INFO - Saving checkpoint at t = 8000 ...\n",
      "2024-06-10 00:26:47,277 - 2024Jun10-002258_configs_algorithm=default - INFO - Checkpoint saved at t = 8000\n",
      "2024-06-10 00:26:47,277 - 2024Jun10-002258_configs_algorithm=default - INFO - Checkpoint saved at t = 8000\n",
      "2024-06-10 00:26:47,278 - 2024Jun10-002258_configs_algorithm=default - INFO - Epoch 0 completed in 0:00:00.218044. Frames seen: 8000\n",
      "2024-06-10 00:26:47,278 - 2024Jun10-002258_configs_algorithm=default - INFO - Epoch 0 completed in 0:00:00.218044. Frames seen: 8000\n",
      "2024-06-10 00:26:47,278 - 2024Jun10-002258_configs_algorithm=default - INFO - \n",
      "\n",
      "2024-06-10 00:26:47,278 - 2024Jun10-002258_configs_algorithm=default - INFO - \n",
      "\n",
      "2024-06-10 00:26:47,280 - 2024Jun10-002258_configs_algorithm=default - INFO - Ended training session after 1 epochs at t = 8000\n",
      "2024-06-10 00:26:47,280 - 2024Jun10-002258_configs_algorithm=default - INFO - Ended training session after 1 epochs at t = 8000\n",
      "2024-06-10 00:26:47,429 - 2024Jun10-002258_configs_algorithm=default - INFO - Resuming training session at: 8000 (1 epochs left)\n",
      "2024-06-10 00:26:47,429 - 2024Jun10-002258_configs_algorithm=default - INFO - Resuming training session at: 8000 (1 epochs left)\n",
      "2024-06-10 00:26:47,430 - 2024Jun10-002258_configs_algorithm=default - INFO - Starting training epoch at t = 8000\n",
      "2024-06-10 00:26:47,430 - 2024Jun10-002258_configs_algorithm=default - INFO - Starting training epoch at t = 8000\n",
      "2024-06-10 00:26:47,641 - 2024Jun10-002258_configs_algorithm=default - INFO - TRAINING STATS | Frames seen: 8500 | Episode: 18 | Max reward: None | Avg reward: None | Avg frames (episode): None | Avg max Q: None | Epsilon: 0.01 | Train epoch time: 0:00:00.210686\n",
      "2024-06-10 00:26:47,641 - 2024Jun10-002258_configs_algorithm=default - INFO - TRAINING STATS | Frames seen: 8500 | Episode: 18 | Max reward: None | Avg reward: None | Avg frames (episode): None | Avg max Q: None | Epsilon: 0.01 | Train epoch time: 0:00:00.210686\n",
      "2024-06-10 00:26:47,642 - 2024Jun10-002258_configs_algorithm=default - INFO - Saving checkpoint at t = 8500 ...\n",
      "2024-06-10 00:26:47,642 - 2024Jun10-002258_configs_algorithm=default - INFO - Saving checkpoint at t = 8500 ...\n",
      "2024-06-10 00:26:47,644 - 2024Jun10-002258_configs_algorithm=default - INFO - Checkpoint saved at t = 8500\n",
      "2024-06-10 00:26:47,644 - 2024Jun10-002258_configs_algorithm=default - INFO - Checkpoint saved at t = 8500\n",
      "2024-06-10 00:26:47,644 - 2024Jun10-002258_configs_algorithm=default - INFO - Epoch 0 completed in 0:00:00.213538. Frames seen: 8500\n",
      "2024-06-10 00:26:47,644 - 2024Jun10-002258_configs_algorithm=default - INFO - Epoch 0 completed in 0:00:00.213538. Frames seen: 8500\n",
      "2024-06-10 00:26:47,645 - 2024Jun10-002258_configs_algorithm=default - INFO - \n",
      "\n",
      "2024-06-10 00:26:47,645 - 2024Jun10-002258_configs_algorithm=default - INFO - \n",
      "\n",
      "2024-06-10 00:26:47,645 - 2024Jun10-002258_configs_algorithm=default - INFO - Ended training session after 1 epochs at t = 8500\n",
      "2024-06-10 00:26:47,645 - 2024Jun10-002258_configs_algorithm=default - INFO - Ended training session after 1 epochs at t = 8500\n",
      "2024-06-10 00:26:47,805 - 2024Jun10-002258_configs_algorithm=default - INFO - Resuming training session at: 8500 (1 epochs left)\n",
      "2024-06-10 00:26:47,805 - 2024Jun10-002258_configs_algorithm=default - INFO - Resuming training session at: 8500 (1 epochs left)\n",
      "2024-06-10 00:26:47,806 - 2024Jun10-002258_configs_algorithm=default - INFO - Starting training epoch at t = 8500\n",
      "2024-06-10 00:26:47,806 - 2024Jun10-002258_configs_algorithm=default - INFO - Starting training epoch at t = 8500\n",
      "2024-06-10 00:26:48,013 - 2024Jun10-002258_configs_algorithm=default - INFO - TRAINING STATS | Frames seen: 9000 | Episode: 18 | Max reward: None | Avg reward: None | Avg frames (episode): None | Avg max Q: None | Epsilon: 0.01 | Train epoch time: 0:00:00.205328\n",
      "2024-06-10 00:26:48,013 - 2024Jun10-002258_configs_algorithm=default - INFO - TRAINING STATS | Frames seen: 9000 | Episode: 18 | Max reward: None | Avg reward: None | Avg frames (episode): None | Avg max Q: None | Epsilon: 0.01 | Train epoch time: 0:00:00.205328\n",
      "2024-06-10 00:26:48,013 - 2024Jun10-002258_configs_algorithm=default - INFO - Saving checkpoint at t = 9000 ...\n",
      "2024-06-10 00:26:48,013 - 2024Jun10-002258_configs_algorithm=default - INFO - Saving checkpoint at t = 9000 ...\n",
      "2024-06-10 00:26:48,015 - 2024Jun10-002258_configs_algorithm=default - INFO - Checkpoint saved at t = 9000\n",
      "2024-06-10 00:26:48,015 - 2024Jun10-002258_configs_algorithm=default - INFO - Checkpoint saved at t = 9000\n",
      "2024-06-10 00:26:48,016 - 2024Jun10-002258_configs_algorithm=default - INFO - Epoch 0 completed in 0:00:00.209330. Frames seen: 9000\n",
      "2024-06-10 00:26:48,016 - 2024Jun10-002258_configs_algorithm=default - INFO - Epoch 0 completed in 0:00:00.209330. Frames seen: 9000\n",
      "2024-06-10 00:26:48,016 - 2024Jun10-002258_configs_algorithm=default - INFO - \n",
      "\n",
      "2024-06-10 00:26:48,016 - 2024Jun10-002258_configs_algorithm=default - INFO - \n",
      "\n",
      "2024-06-10 00:26:48,017 - 2024Jun10-002258_configs_algorithm=default - INFO - Ended training session after 1 epochs at t = 9000\n",
      "2024-06-10 00:26:48,017 - 2024Jun10-002258_configs_algorithm=default - INFO - Ended training session after 1 epochs at t = 9000\n",
      "2024-06-10 00:26:48,179 - 2024Jun10-002258_configs_algorithm=default - INFO - Resuming training session at: 9000 (1 epochs left)\n",
      "2024-06-10 00:26:48,179 - 2024Jun10-002258_configs_algorithm=default - INFO - Resuming training session at: 9000 (1 epochs left)\n",
      "2024-06-10 00:26:48,180 - 2024Jun10-002258_configs_algorithm=default - INFO - Starting training epoch at t = 9000\n",
      "2024-06-10 00:26:48,180 - 2024Jun10-002258_configs_algorithm=default - INFO - Starting training epoch at t = 9000\n",
      "2024-06-10 00:26:48,264 - 2024Jun10-002258_configs_algorithm=default - INFO - Episode 18 terminated at frame 189 with reward 1.0\n",
      "2024-06-10 00:26:48,264 - 2024Jun10-002258_configs_algorithm=default - INFO - Episode 18 terminated at frame 189 with reward 1.0\n",
      "2024-06-10 00:26:48,394 - 2024Jun10-002258_configs_algorithm=default - INFO - TRAINING STATS | Frames seen: 9500 | Episode: 19 | Max reward: 1.0 | Avg reward: 1.0 | Avg frames (episode): 2579.0 | Avg max Q: 0.1472938348969629 | Epsilon: 0.01 | Train epoch time: 0:00:00.212917\n",
      "2024-06-10 00:26:48,394 - 2024Jun10-002258_configs_algorithm=default - INFO - TRAINING STATS | Frames seen: 9500 | Episode: 19 | Max reward: 1.0 | Avg reward: 1.0 | Avg frames (episode): 2579.0 | Avg max Q: 0.1472938348969629 | Epsilon: 0.01 | Train epoch time: 0:00:00.212917\n",
      "2024-06-10 00:26:48,395 - 2024Jun10-002258_configs_algorithm=default - INFO - Saving checkpoint at t = 9500 ...\n",
      "2024-06-10 00:26:48,395 - 2024Jun10-002258_configs_algorithm=default - INFO - Saving checkpoint at t = 9500 ...\n",
      "2024-06-10 00:26:48,397 - 2024Jun10-002258_configs_algorithm=default - INFO - Checkpoint saved at t = 9500\n",
      "2024-06-10 00:26:48,397 - 2024Jun10-002258_configs_algorithm=default - INFO - Checkpoint saved at t = 9500\n",
      "2024-06-10 00:26:48,397 - 2024Jun10-002258_configs_algorithm=default - INFO - Epoch 0 completed in 0:00:00.216921. Frames seen: 9500\n",
      "2024-06-10 00:26:48,397 - 2024Jun10-002258_configs_algorithm=default - INFO - Epoch 0 completed in 0:00:00.216921. Frames seen: 9500\n",
      "2024-06-10 00:26:48,398 - 2024Jun10-002258_configs_algorithm=default - INFO - \n",
      "\n",
      "2024-06-10 00:26:48,398 - 2024Jun10-002258_configs_algorithm=default - INFO - \n",
      "\n",
      "2024-06-10 00:26:48,399 - 2024Jun10-002258_configs_algorithm=default - INFO - Ended training session after 1 epochs at t = 9500\n",
      "2024-06-10 00:26:48,399 - 2024Jun10-002258_configs_algorithm=default - INFO - Ended training session after 1 epochs at t = 9500\n"
     ]
    }
   ],
   "source": [
    "logger.info(f\"Starting experiment: {opts_dict['full_title']}\")\n",
    "\n",
    "agent = setup_dqn_agent(\n",
    "    config=opts_dict,\n",
    "    logger=logger,\n",
    ")\n",
    "\n",
    "transitions_list = [\n",
    "    (key[0], key[1], *value[0]) for key, value in agent.train_env.mdp.items()\n",
    "]\n",
    "\n",
    "experiment_data = []\n",
    "for i in range(1, 20):\n",
    "    agent.train(i)\n",
    "\n",
    "    bm_error_validation = compute_validation_bellmans_error(\n",
    "        agent.target_model,\n",
    "        validation_transitions=transitions_list,\n",
    "        error_mode=opts_dict[\"neural_fit_mode\"],\n",
    "        gamma=agent.gamma,\n",
    "        logger=logger,\n",
    "    )\n",
    "\n",
    "    rb_entropy = agent.replay_buffer.calculate_buffer_entropy()\n",
    "\n",
    "    normalized_rb = agent.replay_buffer.normalize_replay_buffer()\n",
    "    normalized_rb_entropy = normalized_rb.calculate_buffer_entropy()\n",
    "\n",
    "# experiment_agent.train(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'frame_stamp': 500,\n",
       "  'episode_rewards': {'min': 1.0,\n",
       "   'max': 1.0,\n",
       "   'mean': 1.0,\n",
       "   'median': 1.0,\n",
       "   'std': 0.0},\n",
       "  'episode_frames': {'min': 40,\n",
       "   'max': 40,\n",
       "   'mean': 40.0,\n",
       "   'median': 40.0,\n",
       "   'std': 0.0},\n",
       "  'episode_losses': {'min': None,\n",
       "   'max': None,\n",
       "   'mean': None,\n",
       "   'median': None,\n",
       "   'std': None},\n",
       "  'episode_max_qs': {'min': nan,\n",
       "   'max': nan,\n",
       "   'mean': nan,\n",
       "   'median': nan,\n",
       "   'std': nan},\n",
       "  'policy_trained_times': 112,\n",
       "  'target_trained_times': 8,\n",
       "  'epoch_time': datetime.timedelta(microseconds=155864)},\n",
       " {'frame_stamp': 1000,\n",
       "  'episode_rewards': {'min': 1.0,\n",
       "   'max': 1.0,\n",
       "   'mean': 1.0,\n",
       "   'median': 1.0,\n",
       "   'std': 0.0},\n",
       "  'episode_frames': {'min': 724,\n",
       "   'max': 724,\n",
       "   'mean': 724.0,\n",
       "   'median': 724.0,\n",
       "   'std': 0.0},\n",
       "  'episode_losses': {'min': 0.00033507277839817107,\n",
       "   'max': 699.722900390625,\n",
       "   'mean': 4.026124825912856,\n",
       "   'median': 0.002310633775778115,\n",
       "   'std': 52.29576250169402},\n",
       "  'episode_max_qs': {'min': 0.590980052947998,\n",
       "   'max': 1.206559419631958,\n",
       "   'mean': 0.9396681218850808,\n",
       "   'median': 0.983868420124054,\n",
       "   'std': 0.1766513785801981},\n",
       "  'policy_trained_times': 125,\n",
       "  'target_trained_times': 12,\n",
       "  'epoch_time': datetime.timedelta(microseconds=185904)},\n",
       " {'frame_stamp': 1500,\n",
       "  'episode_rewards': {'min': 1.0,\n",
       "   'max': 1.0,\n",
       "   'mean': 1.0,\n",
       "   'median': 1.0,\n",
       "   'std': 0.0},\n",
       "  'episode_frames': {'min': 107,\n",
       "   'max': 293,\n",
       "   'mean': 228.66666666666666,\n",
       "   'median': 286.0,\n",
       "   'std': 86.07877529075071},\n",
       "  'episode_losses': {'min': 5.828661232953891e-05,\n",
       "   'max': 0.003809970570728183,\n",
       "   'mean': 0.0007129256070563082,\n",
       "   'median': 0.0005167368799448013,\n",
       "   'std': 0.0006257538632147599},\n",
       "  'episode_max_qs': {'min': 0.5293976068496704,\n",
       "   'max': 1.042688012123108,\n",
       "   'mean': 0.8061540085408423,\n",
       "   'median': 0.8080113232135773,\n",
       "   'std': 0.12306209715131738},\n",
       "  'policy_trained_times': 125,\n",
       "  'target_trained_times': 16,\n",
       "  'epoch_time': datetime.timedelta(microseconds=188011)},\n",
       " {'frame_stamp': 2000,\n",
       "  'episode_rewards': {'min': 1.0,\n",
       "   'max': 1.0,\n",
       "   'mean': 1.0,\n",
       "   'median': 1.0,\n",
       "   'std': 0.0},\n",
       "  'episode_frames': {'min': 30,\n",
       "   'max': 239,\n",
       "   'mean': 101.8,\n",
       "   'median': 45.0,\n",
       "   'std': 81.46508454546647},\n",
       "  'episode_losses': {'min': 6.832967483205721e-05,\n",
       "   'max': 0.007602924946695566,\n",
       "   'mean': 0.0012699608790952214,\n",
       "   'median': 0.00044711335795000196,\n",
       "   'std': 0.0016688617681774067},\n",
       "  'episode_max_qs': {'min': 0.45640337467193604,\n",
       "   'max': 0.7731999158859253,\n",
       "   'mean': 0.6306714232553515,\n",
       "   'median': 0.6275911331176758,\n",
       "   'std': 0.06763358179141798},\n",
       "  'policy_trained_times': 125,\n",
       "  'target_trained_times': 12,\n",
       "  'epoch_time': datetime.timedelta(microseconds=189526)},\n",
       " {'frame_stamp': 2500,\n",
       "  'episode_rewards': {'min': 1.0,\n",
       "   'max': 1.0,\n",
       "   'mean': 1.0,\n",
       "   'median': 1.0,\n",
       "   'std': 0.0},\n",
       "  'episode_frames': {'min': 90,\n",
       "   'max': 363,\n",
       "   'mean': 226.5,\n",
       "   'median': 226.5,\n",
       "   'std': 136.5},\n",
       "  'episode_losses': {'min': 3.8706129998899996e-05,\n",
       "   'max': 0.017764244228601456,\n",
       "   'mean': 0.0024609135649145365,\n",
       "   'median': 0.0008151219226419926,\n",
       "   'std': 0.0034009962768112917},\n",
       "  'episode_max_qs': {'min': 0.30076366662979126,\n",
       "   'max': 0.5977259278297424,\n",
       "   'mean': 0.43868856287972874,\n",
       "   'median': 0.4351547658443451,\n",
       "   'std': 0.06560535624744974},\n",
       "  'policy_trained_times': 125,\n",
       "  'target_trained_times': 12,\n",
       "  'epoch_time': datetime.timedelta(microseconds=170228)},\n",
       " {'frame_stamp': 3000,\n",
       "  'episode_rewards': {'min': None,\n",
       "   'max': None,\n",
       "   'mean': None,\n",
       "   'median': None,\n",
       "   'std': None},\n",
       "  'episode_frames': {'min': None,\n",
       "   'max': None,\n",
       "   'mean': None,\n",
       "   'median': None,\n",
       "   'std': None},\n",
       "  'episode_losses': {'min': None,\n",
       "   'max': None,\n",
       "   'mean': None,\n",
       "   'median': None,\n",
       "   'std': None},\n",
       "  'episode_max_qs': {'min': None,\n",
       "   'max': None,\n",
       "   'mean': None,\n",
       "   'median': None,\n",
       "   'std': None},\n",
       "  'policy_trained_times': 125,\n",
       "  'target_trained_times': 12,\n",
       "  'epoch_time': datetime.timedelta(microseconds=184038)},\n",
       " {'frame_stamp': 3500,\n",
       "  'episode_rewards': {'min': 1.0,\n",
       "   'max': 1.0,\n",
       "   'mean': 1.0,\n",
       "   'median': 1.0,\n",
       "   'std': 0.0},\n",
       "  'episode_frames': {'min': 974,\n",
       "   'max': 974,\n",
       "   'mean': 974.0,\n",
       "   'median': 974.0,\n",
       "   'std': 0.0},\n",
       "  'episode_losses': {'min': 2.1621543055516668e-05,\n",
       "   'max': 0.017513461410999298,\n",
       "   'mean': 0.0017422265449284645,\n",
       "   'median': 0.00034261403197888285,\n",
       "   'std': 0.003542116169427149},\n",
       "  'episode_max_qs': {'min': 0.20752866566181183,\n",
       "   'max': 0.5110423564910889,\n",
       "   'mean': 0.3312507224456892,\n",
       "   'median': 0.3247782588005066,\n",
       "   'std': 0.06637869863330059},\n",
       "  'policy_trained_times': 125,\n",
       "  'target_trained_times': 12,\n",
       "  'epoch_time': datetime.timedelta(microseconds=197415)},\n",
       " {'frame_stamp': 4000,\n",
       "  'episode_rewards': {'min': 1.0,\n",
       "   'max': 1.0,\n",
       "   'mean': 1.0,\n",
       "   'median': 1.0,\n",
       "   'std': 0.0},\n",
       "  'episode_frames': {'min': 23,\n",
       "   'max': 274,\n",
       "   'mean': 185.0,\n",
       "   'median': 258.0,\n",
       "   'std': 114.73738129601297},\n",
       "  'episode_losses': {'min': 1.4369911696121562e-05,\n",
       "   'max': 0.018029235303401947,\n",
       "   'mean': 0.001114211020021096,\n",
       "   'median': 0.00014173523231875151,\n",
       "   'std': 0.003734442473828798},\n",
       "  'episode_max_qs': {'min': 0.17847561836242676,\n",
       "   'max': 0.31906843185424805,\n",
       "   'mean': 0.25065007450143295,\n",
       "   'median': 0.2525554895401001,\n",
       "   'std': 0.02867003670693},\n",
       "  'policy_trained_times': 125,\n",
       "  'target_trained_times': 12,\n",
       "  'epoch_time': datetime.timedelta(microseconds=216015)},\n",
       " {'frame_stamp': 4500,\n",
       "  'episode_rewards': {'min': 1.0,\n",
       "   'max': 1.0,\n",
       "   'mean': 1.0,\n",
       "   'median': 1.0,\n",
       "   'std': 0.0},\n",
       "  'episode_frames': {'min': 293,\n",
       "   'max': 293,\n",
       "   'mean': 293.0,\n",
       "   'median': 293.0,\n",
       "   'std': 0.0},\n",
       "  'episode_losses': {'min': 1.8000804629991762e-05,\n",
       "   'max': 0.018651437014341354,\n",
       "   'mean': 0.0013190486048213095,\n",
       "   'median': 0.00010602805559756234,\n",
       "   'std': 0.004335956139508585},\n",
       "  'episode_max_qs': {'min': 0.15907466411590576,\n",
       "   'max': 0.2750322222709656,\n",
       "   'mean': 0.2196274161069102,\n",
       "   'median': 0.2212102711200714,\n",
       "   'std': 0.034338027018461705},\n",
       "  'policy_trained_times': 125,\n",
       "  'target_trained_times': 12,\n",
       "  'epoch_time': datetime.timedelta(microseconds=226586)},\n",
       " {'frame_stamp': 5000,\n",
       "  'episode_rewards': {'min': None,\n",
       "   'max': None,\n",
       "   'mean': None,\n",
       "   'median': None,\n",
       "   'std': None},\n",
       "  'episode_frames': {'min': None,\n",
       "   'max': None,\n",
       "   'mean': None,\n",
       "   'median': None,\n",
       "   'std': None},\n",
       "  'episode_losses': {'min': None,\n",
       "   'max': None,\n",
       "   'mean': None,\n",
       "   'median': None,\n",
       "   'std': None},\n",
       "  'episode_max_qs': {'min': None,\n",
       "   'max': None,\n",
       "   'mean': None,\n",
       "   'median': None,\n",
       "   'std': None},\n",
       "  'policy_trained_times': 125,\n",
       "  'target_trained_times': 12,\n",
       "  'epoch_time': datetime.timedelta(microseconds=221059)},\n",
       " {'frame_stamp': 5500,\n",
       "  'episode_rewards': {'min': None,\n",
       "   'max': None,\n",
       "   'mean': None,\n",
       "   'median': None,\n",
       "   'std': None},\n",
       "  'episode_frames': {'min': None,\n",
       "   'max': None,\n",
       "   'mean': None,\n",
       "   'median': None,\n",
       "   'std': None},\n",
       "  'episode_losses': {'min': None,\n",
       "   'max': None,\n",
       "   'mean': None,\n",
       "   'median': None,\n",
       "   'std': None},\n",
       "  'episode_max_qs': {'min': None,\n",
       "   'max': None,\n",
       "   'mean': None,\n",
       "   'median': None,\n",
       "   'std': None},\n",
       "  'policy_trained_times': 125,\n",
       "  'target_trained_times': 16,\n",
       "  'epoch_time': datetime.timedelta(microseconds=225629)},\n",
       " {'frame_stamp': 6000,\n",
       "  'episode_rewards': {'min': None,\n",
       "   'max': None,\n",
       "   'mean': None,\n",
       "   'median': None,\n",
       "   'std': None},\n",
       "  'episode_frames': {'min': None,\n",
       "   'max': None,\n",
       "   'mean': None,\n",
       "   'median': None,\n",
       "   'std': None},\n",
       "  'episode_losses': {'min': None,\n",
       "   'max': None,\n",
       "   'mean': None,\n",
       "   'median': None,\n",
       "   'std': None},\n",
       "  'episode_max_qs': {'min': None,\n",
       "   'max': None,\n",
       "   'mean': None,\n",
       "   'median': None,\n",
       "   'std': None},\n",
       "  'policy_trained_times': 125,\n",
       "  'target_trained_times': 12,\n",
       "  'epoch_time': datetime.timedelta(microseconds=204787)},\n",
       " {'frame_stamp': 6500,\n",
       "  'episode_rewards': {'min': None,\n",
       "   'max': None,\n",
       "   'mean': None,\n",
       "   'median': None,\n",
       "   'std': None},\n",
       "  'episode_frames': {'min': None,\n",
       "   'max': None,\n",
       "   'mean': None,\n",
       "   'median': None,\n",
       "   'std': None},\n",
       "  'episode_losses': {'min': None,\n",
       "   'max': None,\n",
       "   'mean': None,\n",
       "   'median': None,\n",
       "   'std': None},\n",
       "  'episode_max_qs': {'min': None,\n",
       "   'max': None,\n",
       "   'mean': None,\n",
       "   'median': None,\n",
       "   'std': None},\n",
       "  'policy_trained_times': 125,\n",
       "  'target_trained_times': 12,\n",
       "  'epoch_time': datetime.timedelta(microseconds=211447)},\n",
       " {'frame_stamp': 7000,\n",
       "  'episode_rewards': {'min': 1.0,\n",
       "   'max': 1.0,\n",
       "   'mean': 1.0,\n",
       "   'median': 1.0,\n",
       "   'std': 0.0},\n",
       "  'episode_frames': {'min': 2377,\n",
       "   'max': 2377,\n",
       "   'mean': 2377.0,\n",
       "   'median': 2377.0,\n",
       "   'std': 0.0},\n",
       "  'episode_losses': {'min': 5.065276642568506e-09,\n",
       "   'max': 0.02089812606573105,\n",
       "   'mean': 0.001106127699934166,\n",
       "   'median': 6.319633757811971e-05,\n",
       "   'std': 0.004005358966594918},\n",
       "  'episode_max_qs': {'min': 0.04342837631702423,\n",
       "   'max': 0.26105910539627075,\n",
       "   'mean': 0.15208882125355971,\n",
       "   'median': 0.15047013759613037,\n",
       "   'std': 0.04749840131758812},\n",
       "  'policy_trained_times': 125,\n",
       "  'target_trained_times': 12,\n",
       "  'epoch_time': datetime.timedelta(microseconds=228590)},\n",
       " {'frame_stamp': 7500,\n",
       "  'episode_rewards': {'min': None,\n",
       "   'max': None,\n",
       "   'mean': None,\n",
       "   'median': None,\n",
       "   'std': None},\n",
       "  'episode_frames': {'min': None,\n",
       "   'max': None,\n",
       "   'mean': None,\n",
       "   'median': None,\n",
       "   'std': None},\n",
       "  'episode_losses': {'min': None,\n",
       "   'max': None,\n",
       "   'mean': None,\n",
       "   'median': None,\n",
       "   'std': None},\n",
       "  'episode_max_qs': {'min': None,\n",
       "   'max': None,\n",
       "   'mean': None,\n",
       "   'median': None,\n",
       "   'std': None},\n",
       "  'policy_trained_times': 125,\n",
       "  'target_trained_times': 12,\n",
       "  'epoch_time': datetime.timedelta(microseconds=221222)},\n",
       " {'frame_stamp': 8000,\n",
       "  'episode_rewards': {'min': None,\n",
       "   'max': None,\n",
       "   'mean': None,\n",
       "   'median': None,\n",
       "   'std': None},\n",
       "  'episode_frames': {'min': None,\n",
       "   'max': None,\n",
       "   'mean': None,\n",
       "   'median': None,\n",
       "   'std': None},\n",
       "  'episode_losses': {'min': None,\n",
       "   'max': None,\n",
       "   'mean': None,\n",
       "   'median': None,\n",
       "   'std': None},\n",
       "  'episode_max_qs': {'min': None,\n",
       "   'max': None,\n",
       "   'mean': None,\n",
       "   'median': None,\n",
       "   'std': None},\n",
       "  'policy_trained_times': 125,\n",
       "  'target_trained_times': 12,\n",
       "  'epoch_time': datetime.timedelta(microseconds=215044)},\n",
       " {'frame_stamp': 8500,\n",
       "  'episode_rewards': {'min': None,\n",
       "   'max': None,\n",
       "   'mean': None,\n",
       "   'median': None,\n",
       "   'std': None},\n",
       "  'episode_frames': {'min': None,\n",
       "   'max': None,\n",
       "   'mean': None,\n",
       "   'median': None,\n",
       "   'std': None},\n",
       "  'episode_losses': {'min': None,\n",
       "   'max': None,\n",
       "   'mean': None,\n",
       "   'median': None,\n",
       "   'std': None},\n",
       "  'episode_max_qs': {'min': None,\n",
       "   'max': None,\n",
       "   'mean': None,\n",
       "   'median': None,\n",
       "   'std': None},\n",
       "  'policy_trained_times': 125,\n",
       "  'target_trained_times': 12,\n",
       "  'epoch_time': datetime.timedelta(microseconds=210686)},\n",
       " {'frame_stamp': 9000,\n",
       "  'episode_rewards': {'min': None,\n",
       "   'max': None,\n",
       "   'mean': None,\n",
       "   'median': None,\n",
       "   'std': None},\n",
       "  'episode_frames': {'min': None,\n",
       "   'max': None,\n",
       "   'mean': None,\n",
       "   'median': None,\n",
       "   'std': None},\n",
       "  'episode_losses': {'min': None,\n",
       "   'max': None,\n",
       "   'mean': None,\n",
       "   'median': None,\n",
       "   'std': None},\n",
       "  'episode_max_qs': {'min': None,\n",
       "   'max': None,\n",
       "   'mean': None,\n",
       "   'median': None,\n",
       "   'std': None},\n",
       "  'policy_trained_times': 125,\n",
       "  'target_trained_times': 12,\n",
       "  'epoch_time': datetime.timedelta(microseconds=205328)},\n",
       " {'frame_stamp': 9500,\n",
       "  'episode_rewards': {'min': 1.0,\n",
       "   'max': 1.0,\n",
       "   'mean': 1.0,\n",
       "   'median': 1.0,\n",
       "   'std': 0.0},\n",
       "  'episode_frames': {'min': 2579,\n",
       "   'max': 2579,\n",
       "   'mean': 2579.0,\n",
       "   'median': 2579.0,\n",
       "   'std': 0.0},\n",
       "  'episode_losses': {'min': 5.554201152335736e-07,\n",
       "   'max': 0.024791745468974113,\n",
       "   'mean': 0.0002627935221752093,\n",
       "   'median': 3.221581573598087e-05,\n",
       "   'std': 0.0017747590544374189},\n",
       "  'episode_max_qs': {'min': 0.04117347300052643,\n",
       "   'max': 0.22414422035217285,\n",
       "   'mean': 0.1472938348969629,\n",
       "   'median': 0.143271803855896,\n",
       "   'std': 0.03485509112356409},\n",
       "  'policy_trained_times': 125,\n",
       "  'target_trained_times': 16,\n",
       "  'epoch_time': datetime.timedelta(microseconds=212917)}]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.training_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rb_buffer = agent.replay_buffer\n",
    "# buffer = rb_buffer.buffer\n",
    "\n",
    "# examples = [(transition[0], transition[1]) for transition in buffer]\n",
    "# example_strings = [f\"{state}_{action}\" for state, action in examples]\n",
    "# unique_examples, counts = np.unique(example_strings, return_counts=True)\n",
    "# example_entropy = entropy(counts, base=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# len(unique_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
       "         1,   1,   1,   1,   1,   1,   1,   1,   2,   2,   2,   3,   3,\n",
       "         3,   3,   4,   6,   7,   9,  10,  11,  11,  12,  13,  17,  17,\n",
       "        18,  18,  18,  93, 199, 235, 263], dtype=int64)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# counts.sort()\n",
    "# counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.21142517505006"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# normalized_rb = rb_buffer.normalize_replay_buffer()\n",
    "# normalized_rb_entropy = normalized_rb.calculate_buffer_entropy()\n",
    "# buffer_normed = normalized_rb.buffer\n",
    "\n",
    "\n",
    "# examples_normalized = [(transition[0], transition[1]) for transition in buffer_normed]\n",
    "# example_strings_normalized = [f\"{state}_{action}\" for state, action in examples_normalized]\n",
    "# len(example_strings_normalized)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# unique_examples, counts = np.unique(example_strings_normalized, return_counts=True)\n",
    "# len(unique_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([22, 21, 22, 22, 22, 21, 22, 22, 21, 22, 22, 22, 22, 22, 22, 22, 22,\n",
       "       22, 21, 22, 21, 22, 22, 22, 22, 22, 22, 22, 21, 22, 21, 21, 22, 22,\n",
       "       22, 22, 22, 21, 21, 21, 22, 22, 22, 22, 22, 21], dtype=int64)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.523265443381141"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example_entropy_normed = entropy(counts, base=2)\n",
    "# example_entropy_normed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.523265443381141"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# normalized_rb_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_env' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[41], line 33\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m recorded_states\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# Example usage:\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# Assuming `train_env` is your environment instance\u001b[39;00m\n\u001b[1;32m---> 33\u001b[0m randomly_step_through_env(\u001b[43mtrain_env\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_env' is not defined"
     ]
    }
   ],
   "source": [
    "# def randomly_step_through_env(env):\n",
    "#     is_terminated = False\n",
    "#     truncated = False\n",
    "#     visited_states = set()\n",
    "#     recorded_states = []\n",
    "\n",
    "#     while not is_terminated and not truncated:\n",
    "#         # Sample a random action from the action space\n",
    "#         action = env.action_space.sample()\n",
    "\n",
    "#         # Take a step in the environment\n",
    "#         s_prime, reward, is_terminated, truncated, info = env.step(action)\n",
    "\n",
    "#         # Convert state to a hashable type (e.g., tuple) if it's not already\n",
    "#         s_prime_hashable = (\n",
    "#             tuple(s_prime) if isinstance(s_prime, (list, np.ndarray)) else s_prime\n",
    "#         )\n",
    "\n",
    "#         # Check if the state is new\n",
    "#         if s_prime_hashable not in visited_states:\n",
    "#             visited_states.add(s_prime_hashable)\n",
    "#             recorded_states.append(s_prime)\n",
    "#             print(\n",
    "#                 f\"New State: {s_prime}, Action: {action}, Reward: {reward}, Terminated: {is_terminated}, Truncated: {truncated}, Info: {info}\"\n",
    "#             )\n",
    "\n",
    "#     print(\"Reached terminal state or truncated.\")\n",
    "#     return recorded_states\n",
    "\n",
    "\n",
    "# # Example usage:\n",
    "# # Assuming `train_env` is your environment instance\n",
    "# randomly_step_through_env(train_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss_records, bm_error = run_distribution_correction_experiment(\n",
    "#         tau=opts.tau,\n",
    "#         seed=opts.seed,\n",
    "#         run_id=opts.run_id,\n",
    "#         rows=opts.rows,\n",
    "#         cols=opts.cols,\n",
    "#         start_state=opts.start_state,\n",
    "#         p_success=opts.p_success,\n",
    "#         terminal_states=opts.terminal_states,\n",
    "#         num_steps=opts.num_steps,\n",
    "#         gamma=opts.gamma,\n",
    "#         min_samples=opts.min_samples,\n",
    "#         batch_size=opts.batch_size,\n",
    "#         train_max_iterations=opts.train_max_iterations,\n",
    "#         neural_fit_mode=opts.neural_fit_mode,\n",
    "#         algorithm=opts.algorithm,\n",
    "#         logger=logger,\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss_records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "general",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
